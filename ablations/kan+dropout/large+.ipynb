{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9715a90-f39c-4964-9193-5ee44431250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import kan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77d11873-35d1-466e-af7e-424c5607439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/S&P500.csv\n",
      "shape =  (5031, 7)\n"
     ]
    }
   ],
   "source": [
    "data_names = [\"S&P500\",\"SSE\",\"IBM\",\"MSFT\",\"PAICC\"]\n",
    "data_name = data_names[0]\n",
    "data_path=\"./datasets/S&P500.csv\"\n",
    "print(data_path)\n",
    "dataframe = pd.read_csv(data_path)\n",
    "dataframe.describe()\n",
    "print(\"shape = \",dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a805dde-5d75-41f4-8fe8-8796e074b81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999-01-11</td>\n",
       "      <td>1275.089966</td>\n",
       "      <td>1276.219971</td>\n",
       "      <td>1253.339966</td>\n",
       "      <td>1263.880005</td>\n",
       "      <td>1263.880005</td>\n",
       "      <td>818000000</td>\n",
       "      <td>1258.007983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1999-01-12</td>\n",
       "      <td>1263.880005</td>\n",
       "      <td>1264.449951</td>\n",
       "      <td>1238.290039</td>\n",
       "      <td>1239.510010</td>\n",
       "      <td>1239.510010</td>\n",
       "      <td>800200000</td>\n",
       "      <td>1265.163989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1999-01-13</td>\n",
       "      <td>1239.510010</td>\n",
       "      <td>1247.750000</td>\n",
       "      <td>1205.459961</td>\n",
       "      <td>1234.400024</td>\n",
       "      <td>1234.400024</td>\n",
       "      <td>931500000</td>\n",
       "      <td>1264.109985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1999-01-14</td>\n",
       "      <td>1234.400024</td>\n",
       "      <td>1236.810059</td>\n",
       "      <td>1209.540039</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>797200000</td>\n",
       "      <td>1256.521997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1999-01-15</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>1243.260010</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>1243.260010</td>\n",
       "      <td>1243.260010</td>\n",
       "      <td>798100000</td>\n",
       "      <td>1245.013989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         Open         High          Low        Close  \\\n",
       "5  1999-01-11  1275.089966  1276.219971  1253.339966  1263.880005   \n",
       "6  1999-01-12  1263.880005  1264.449951  1238.290039  1239.510010   \n",
       "7  1999-01-13  1239.510010  1247.750000  1205.459961  1234.400024   \n",
       "8  1999-01-14  1234.400024  1236.810059  1209.540039  1212.189941   \n",
       "9  1999-01-15  1212.189941  1243.260010  1212.189941  1243.260010   \n",
       "\n",
       "     Adj Close     Volume           Ma  \n",
       "5  1263.880005  818000000  1258.007983  \n",
       "6  1239.510010  800200000  1265.163989  \n",
       "7  1234.400024  931500000  1264.109985  \n",
       "8  1212.189941  797200000  1256.521997  \n",
       "9  1243.260010  798100000  1245.013989  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_Ma(dataframe):\n",
    "  Ma_window=5\n",
    "  for i in range(0,dataframe.shape[0]-Ma_window):\n",
    "    dataframe.loc[dataframe.index[i+Ma_window],'Ma'] = np.round(((dataframe.iloc[i,4]+ dataframe.iloc[i+1,4] +dataframe.iloc[i+2,4] + dataframe.iloc[i+3,4]+ dataframe.iloc[i+4,4])/5),6)\n",
    "  return dataframe[5:-5]\n",
    "\n",
    "dataframe=add_Ma(dataframe)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7331a555-0b19-4c1e-8b75-f2323f80746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class GeneratorModel(nn.Module):\n",
    "    def __init__(self, n_sequence, n_features):\n",
    "        super(GeneratorModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=n_features, hidden_size=10, batch_first=True)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(10)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.3)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(input_size=10, hidden_size=10, batch_first=True)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(10)  \n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.output_dense = nn.Linear(10, n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.batch_norm1(x.permute(0, 2, 1)).permute(0, 2, 1) \n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        _, (x, _) = self.lstm2(x)\n",
    "        x=x.permute(1, 0, 2)\n",
    "        x = self.batch_norm2(x.permute(0, 2, 1)).permute(0, 2, 1)  \n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.output_dense(x)\n",
    "        x = self.leaky_relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "n_sequence = 5  # Sequence length\n",
    "n_features = 7   # Number of features\n",
    "\n",
    "\n",
    "class KAN_discriminator(torch.nn.Module):\n",
    "    def __init__(self, n_sequence, n_features):\n",
    "        super(KAN_discriminator, self).__init__()\n",
    "        input_dim = (n_sequence + 1) * n_features\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            kan.KAN([42,72,100,10,1]),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "530f7259-5fdf-4575-ae9f-374cb66617e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=8)\n",
    "class Standarized_TimeseriesGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets, length, batch_size=1, stride=1):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.length = length\n",
    "        self.batch_size = batch_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        samples = [self.data[i:i+self.length] for i in range(index, len(self.data)-self.length, self.stride)]\n",
    "        targets = [self.targets[i+self.length] for i in range(index, len(self.data)-self.length, self.stride)]\n",
    "        # Pack sequences into tensor\n",
    "        samples = torch.tensor(samples[0])\n",
    "        targets = torch.tensor(targets[0])\n",
    "        samples= samples.to(torch.float64)\n",
    "        targets= targets.to(torch.float64)\n",
    "        # shape : (n_batch, n_sequence, n_features)\n",
    "        mean = samples.mean(dim=0)\n",
    "        std = samples.std(dim=0,correction=0)\n",
    "        samples = (samples - mean)/std  # standardize along each feature\n",
    "\n",
    "\n",
    "        # targets = (targets - mean[..., 3])/std[..., 3]  # The close value is our target\n",
    "        targets = (targets - mean)/std  # The close value is our target\n",
    "        return samples, targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b687e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sequence = 5\n",
    "n_features = 7\n",
    "n_batch = 32\n",
    "\n",
    "def get_gen_train_test(dataframe):\n",
    "  data = dataframe.drop(columns='Date').to_numpy()\n",
    "  #targets = data[:,3, None] #add none to have same number of dimensions as data\n",
    "  targets = data\n",
    "  n_samples = data.shape[0]\n",
    "  train_test_split=int(n_samples*0.9)\n",
    "  train_data = data[:train_test_split]\n",
    "  test_data = data[train_test_split:]\n",
    "  train_target = targets[:train_test_split]\n",
    "  test_target = targets[train_test_split:]\n",
    "  data_train = Standarized_TimeseriesGenerator(train_data, train_target,\n",
    "                                length=n_sequence, \n",
    "                                stride=1)\n",
    "  data_test = Standarized_TimeseriesGenerator(test_data, test_target,\n",
    "                                length=n_sequence, \n",
    "                                stride=1)\n",
    "  \n",
    "  train_loader = DataLoader(data_train, batch_size=n_batch, shuffle=True)\n",
    "  test_loader = DataLoader(data_test, batch_size=n_batch, shuffle=False)\n",
    "  return train_loader, test_loader\n",
    "\n",
    "data_gen_train, data_gen_test = get_gen_train_test(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2ab17e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 72\n",
      "72 100\n",
      "100 10\n",
      "finished\n",
      "[0/200][141/142]\tLoss_D: 1.3798\tLoss_G: 0.7172 \tMSE_loss: 2.6887 \tTime: 0.0632\n",
      "Validation \tLoss_D: 1.3745\tLoss_G: 0.7460 \tMSE_loss: 5.5196 \tBest_loss: 5.5196\n",
      "[1/200][141/142]\tLoss_D: 1.3569\tLoss_G: 0.7425 \tMSE_loss: 4.8012 \tTime: 0.0603\n",
      "Validation \tLoss_D: 1.3551\tLoss_G: 0.7517 \tMSE_loss: 5.4562 \tBest_loss: 5.4562\n",
      "[2/200][141/142]\tLoss_D: 1.3430\tLoss_G: 0.7539 \tMSE_loss: 4.8761 \tTime: 0.0629\n",
      "Validation \tLoss_D: 1.3218\tLoss_G: 0.7622 \tMSE_loss: 5.3926 \tBest_loss: 5.3926\n",
      "[3/200][141/142]\tLoss_D: 1.3012\tLoss_G: 0.7668 \tMSE_loss: 4.1453 \tTime: 0.0619\n",
      "Validation \tLoss_D: 1.2696\tLoss_G: 0.7862 \tMSE_loss: 5.3225 \tBest_loss: 5.3225\n",
      "[4/200][141/142]\tLoss_D: 1.2366\tLoss_G: 0.8133 \tMSE_loss: 4.7068 \tTime: 0.0589\n",
      "Validation \tLoss_D: 1.2012\tLoss_G: 0.8268 \tMSE_loss: 5.2353 \tBest_loss: 5.2353\n",
      "[5/200][141/142]\tLoss_D: 1.1955\tLoss_G: 0.8452 \tMSE_loss: 4.2864 \tTime: 0.0708\n",
      "Validation \tLoss_D: 1.1283\tLoss_G: 0.8877 \tMSE_loss: 5.1718 \tBest_loss: 5.1718\n",
      "[6/200][141/142]\tLoss_D: 1.1256\tLoss_G: 0.9397 \tMSE_loss: 4.1773 \tTime: 0.0597\n",
      "Validation \tLoss_D: 1.0596\tLoss_G: 0.9717 \tMSE_loss: 5.1060 \tBest_loss: 5.1060\n",
      "[7/200][141/142]\tLoss_D: 1.0062\tLoss_G: 0.9581 \tMSE_loss: 4.3624 \tTime: 0.0588\n",
      "Validation \tLoss_D: 1.0045\tLoss_G: 1.0686 \tMSE_loss: 5.0658 \tBest_loss: 5.0658\n",
      "[8/200][141/142]\tLoss_D: 1.0846\tLoss_G: 1.0516 \tMSE_loss: 3.8449 \tTime: 0.0591\n",
      "Validation \tLoss_D: 0.9607\tLoss_G: 1.1371 \tMSE_loss: 5.0173 \tBest_loss: 5.0173\n",
      "[9/200][141/142]\tLoss_D: 1.0832\tLoss_G: 0.9907 \tMSE_loss: 3.4525 \tTime: 0.0667\n",
      "Validation \tLoss_D: 0.9403\tLoss_G: 1.2059 \tMSE_loss: 4.9578 \tBest_loss: 4.9578\n",
      "[10/200][141/142]\tLoss_D: 0.9385\tLoss_G: 1.2082 \tMSE_loss: 4.1345 \tTime: 0.0607\n",
      "Validation \tLoss_D: 0.9004\tLoss_G: 1.3040 \tMSE_loss: 4.9092 \tBest_loss: 4.9092\n",
      "[11/200][141/142]\tLoss_D: 0.7436\tLoss_G: 1.5247 \tMSE_loss: 4.0214 \tTime: 0.0638\n",
      "Validation \tLoss_D: 0.8551\tLoss_G: 1.4108 \tMSE_loss: 4.8757 \tBest_loss: 4.8757\n",
      "[12/200][141/142]\tLoss_D: 0.7107\tLoss_G: 1.4109 \tMSE_loss: 7.0068 \tTime: 0.0629\n",
      "Validation \tLoss_D: 0.8154\tLoss_G: 1.4984 \tMSE_loss: 4.8308 \tBest_loss: 4.8308\n",
      "[13/200][141/142]\tLoss_D: 0.8273\tLoss_G: 1.4057 \tMSE_loss: 6.7104 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.8060\tLoss_G: 1.5127 \tMSE_loss: 4.7998 \tBest_loss: 4.7998\n",
      "[14/200][141/142]\tLoss_D: 0.9857\tLoss_G: 1.2721 \tMSE_loss: 6.8288 \tTime: 0.0576\n",
      "Validation \tLoss_D: 0.7651\tLoss_G: 1.6126 \tMSE_loss: 4.7676 \tBest_loss: 4.7676\n",
      "[15/200][141/142]\tLoss_D: 0.8772\tLoss_G: 1.2642 \tMSE_loss: 3.8747 \tTime: 0.0591\n",
      "Validation \tLoss_D: 0.7220\tLoss_G: 1.6785 \tMSE_loss: 4.7382 \tBest_loss: 4.7382\n",
      "[16/200][141/142]\tLoss_D: 0.6375\tLoss_G: 1.4100 \tMSE_loss: 4.1184 \tTime: 0.0585\n",
      "Validation \tLoss_D: 0.6786\tLoss_G: 1.8019 \tMSE_loss: 4.7190 \tBest_loss: 4.7190\n",
      "[17/200][141/142]\tLoss_D: 0.6781\tLoss_G: 1.3497 \tMSE_loss: 7.3136 \tTime: 0.0613\n",
      "Validation \tLoss_D: 0.6678\tLoss_G: 1.8382 \tMSE_loss: 4.7001 \tBest_loss: 4.7001\n",
      "[18/200][141/142]\tLoss_D: 0.8670\tLoss_G: 1.6987 \tMSE_loss: 6.7790 \tTime: 0.0669\n",
      "Validation \tLoss_D: 0.6459\tLoss_G: 1.8863 \tMSE_loss: 4.6813 \tBest_loss: 4.6813\n",
      "[19/200][141/142]\tLoss_D: 0.6631\tLoss_G: 1.5774 \tMSE_loss: 5.1559 \tTime: 0.0534\n",
      "Validation \tLoss_D: 0.6160\tLoss_G: 1.9949 \tMSE_loss: 4.6823 \tBest_loss: 4.6813\n",
      "[20/200][141/142]\tLoss_D: 0.8499\tLoss_G: 1.6331 \tMSE_loss: 3.2846 \tTime: 0.0665\n",
      "Validation \tLoss_D: 0.6034\tLoss_G: 1.9804 \tMSE_loss: 4.6910 \tBest_loss: 4.6813\n",
      "[21/200][141/142]\tLoss_D: 0.6585\tLoss_G: 1.4573 \tMSE_loss: 3.9050 \tTime: 0.0593\n",
      "Validation \tLoss_D: 0.5959\tLoss_G: 2.0629 \tMSE_loss: 4.6800 \tBest_loss: 4.6800\n",
      "[22/200][141/142]\tLoss_D: 0.4794\tLoss_G: 1.7220 \tMSE_loss: 4.8699 \tTime: 0.0576\n",
      "Validation \tLoss_D: 0.5912\tLoss_G: 2.0810 \tMSE_loss: 4.6979 \tBest_loss: 4.6800\n",
      "[23/200][141/142]\tLoss_D: 0.8407\tLoss_G: 1.7688 \tMSE_loss: 3.7318 \tTime: 0.0597\n",
      "Validation \tLoss_D: 0.5750\tLoss_G: 2.2050 \tMSE_loss: 4.7060 \tBest_loss: 4.6800\n",
      "[24/200][141/142]\tLoss_D: 0.6930\tLoss_G: 1.9768 \tMSE_loss: 3.9012 \tTime: 0.0678\n",
      "Validation \tLoss_D: 0.5831\tLoss_G: 2.2717 \tMSE_loss: 4.7144 \tBest_loss: 4.6800\n",
      "[25/200][141/142]\tLoss_D: 0.6399\tLoss_G: 1.8460 \tMSE_loss: 4.2530 \tTime: 0.0640\n",
      "Validation \tLoss_D: 0.5468\tLoss_G: 2.3227 \tMSE_loss: 4.6906 \tBest_loss: 4.6800\n",
      "[26/200][141/142]\tLoss_D: 0.6211\tLoss_G: 1.8125 \tMSE_loss: 3.4806 \tTime: 0.0588\n",
      "Validation \tLoss_D: 0.5545\tLoss_G: 2.3582 \tMSE_loss: 4.6668 \tBest_loss: 4.6668\n",
      "[27/200][141/142]\tLoss_D: 0.6649\tLoss_G: 1.7649 \tMSE_loss: 4.9353 \tTime: 0.0638\n",
      "Validation \tLoss_D: 0.5476\tLoss_G: 2.3793 \tMSE_loss: 4.6382 \tBest_loss: 4.6382\n",
      "[28/200][141/142]\tLoss_D: 0.5784\tLoss_G: 1.9615 \tMSE_loss: 4.6532 \tTime: 0.0664\n",
      "Validation \tLoss_D: 0.5655\tLoss_G: 2.4891 \tMSE_loss: 4.6661 \tBest_loss: 4.6382\n",
      "[29/200][141/142]\tLoss_D: 0.4339\tLoss_G: 2.0985 \tMSE_loss: 4.3157 \tTime: 0.0658\n",
      "Validation \tLoss_D: 0.5600\tLoss_G: 2.4910 \tMSE_loss: 4.6102 \tBest_loss: 4.6102\n",
      "[30/200][141/142]\tLoss_D: 0.6962\tLoss_G: 1.8034 \tMSE_loss: 4.4766 \tTime: 0.0598\n",
      "Validation \tLoss_D: 0.5425\tLoss_G: 2.4350 \tMSE_loss: 4.6165 \tBest_loss: 4.6102\n",
      "[31/200][141/142]\tLoss_D: 0.6062\tLoss_G: 2.0449 \tMSE_loss: 6.0202 \tTime: 0.0640\n",
      "Validation \tLoss_D: 0.5505\tLoss_G: 2.5054 \tMSE_loss: 4.5886 \tBest_loss: 4.5886\n",
      "[32/200][141/142]\tLoss_D: 0.6940\tLoss_G: 1.9149 \tMSE_loss: 2.9298 \tTime: 0.0606\n",
      "Validation \tLoss_D: 0.5516\tLoss_G: 2.5070 \tMSE_loss: 4.5519 \tBest_loss: 4.5519\n",
      "[33/200][141/142]\tLoss_D: 0.9797\tLoss_G: 2.3499 \tMSE_loss: 3.2348 \tTime: 0.0667\n",
      "Validation \tLoss_D: 0.5588\tLoss_G: 2.5212 \tMSE_loss: 4.5698 \tBest_loss: 4.5519\n",
      "[34/200][141/142]\tLoss_D: 0.7869\tLoss_G: 2.3657 \tMSE_loss: 3.4354 \tTime: 0.0576\n",
      "Validation \tLoss_D: 0.5609\tLoss_G: 2.5616 \tMSE_loss: 4.5502 \tBest_loss: 4.5502\n",
      "[35/200][141/142]\tLoss_D: 0.7576\tLoss_G: 2.4122 \tMSE_loss: 2.8850 \tTime: 0.0552\n",
      "Validation \tLoss_D: 0.5641\tLoss_G: 2.5765 \tMSE_loss: 4.5295 \tBest_loss: 4.5295\n",
      "[36/200][141/142]\tLoss_D: 0.6203\tLoss_G: 2.0101 \tMSE_loss: 4.1538 \tTime: 0.0643\n",
      "Validation \tLoss_D: 0.5711\tLoss_G: 2.5689 \tMSE_loss: 4.4735 \tBest_loss: 4.4735\n",
      "[37/200][141/142]\tLoss_D: 0.6583\tLoss_G: 2.3056 \tMSE_loss: 3.2958 \tTime: 0.0664\n",
      "Validation \tLoss_D: 0.5722\tLoss_G: 2.5872 \tMSE_loss: 4.5012 \tBest_loss: 4.4735\n",
      "[38/200][141/142]\tLoss_D: 0.7140\tLoss_G: 2.3260 \tMSE_loss: 3.0638 \tTime: 0.0625\n",
      "Validation \tLoss_D: 0.5818\tLoss_G: 2.6414 \tMSE_loss: 4.4867 \tBest_loss: 4.4735\n",
      "[39/200][141/142]\tLoss_D: 0.7546\tLoss_G: 2.0786 \tMSE_loss: 3.7780 \tTime: 0.0640\n",
      "Validation \tLoss_D: 0.5864\tLoss_G: 2.6421 \tMSE_loss: 4.4945 \tBest_loss: 4.4735\n",
      "[40/200][141/142]\tLoss_D: 0.5443\tLoss_G: 2.1973 \tMSE_loss: 5.8562 \tTime: 0.0694\n",
      "Validation \tLoss_D: 0.5946\tLoss_G: 2.6463 \tMSE_loss: 4.4560 \tBest_loss: 4.4560\n",
      "[41/200][141/142]\tLoss_D: 0.4720\tLoss_G: 2.4127 \tMSE_loss: 3.7993 \tTime: 0.0622\n",
      "Validation \tLoss_D: 0.5900\tLoss_G: 2.7583 \tMSE_loss: 4.5296 \tBest_loss: 4.4560\n",
      "[42/200][141/142]\tLoss_D: 0.6473\tLoss_G: 2.4217 \tMSE_loss: 8.1168 \tTime: 0.0644\n",
      "Validation \tLoss_D: 0.6097\tLoss_G: 2.7435 \tMSE_loss: 4.4393 \tBest_loss: 4.4393\n",
      "[43/200][141/142]\tLoss_D: 0.6791\tLoss_G: 2.1989 \tMSE_loss: 3.9628 \tTime: 0.0578\n",
      "Validation \tLoss_D: 0.6022\tLoss_G: 2.7007 \tMSE_loss: 4.4540 \tBest_loss: 4.4393\n",
      "[44/200][141/142]\tLoss_D: 0.8119\tLoss_G: 2.2045 \tMSE_loss: 3.2171 \tTime: 0.0687\n",
      "Validation \tLoss_D: 0.5975\tLoss_G: 2.6633 \tMSE_loss: 4.4350 \tBest_loss: 4.4350\n",
      "[45/200][141/142]\tLoss_D: 0.7903\tLoss_G: 1.9067 \tMSE_loss: 3.2841 \tTime: 0.0591\n",
      "Validation \tLoss_D: 0.6041\tLoss_G: 2.6436 \tMSE_loss: 4.4312 \tBest_loss: 4.4312\n",
      "[46/200][141/142]\tLoss_D: 0.5707\tLoss_G: 2.1755 \tMSE_loss: 5.3118 \tTime: 0.0578\n",
      "Validation \tLoss_D: 0.6348\tLoss_G: 2.7567 \tMSE_loss: 4.4351 \tBest_loss: 4.4312\n",
      "[47/200][141/142]\tLoss_D: 0.6055\tLoss_G: 2.2925 \tMSE_loss: 3.7088 \tTime: 0.0579\n",
      "Validation \tLoss_D: 0.6012\tLoss_G: 2.6957 \tMSE_loss: 4.4572 \tBest_loss: 4.4312\n",
      "[48/200][141/142]\tLoss_D: 0.6340\tLoss_G: 2.3343 \tMSE_loss: 4.8814 \tTime: 0.0557\n",
      "Validation \tLoss_D: 0.6312\tLoss_G: 2.7565 \tMSE_loss: 4.4316 \tBest_loss: 4.4312\n",
      "[49/200][141/142]\tLoss_D: 0.7454\tLoss_G: 1.7686 \tMSE_loss: 2.7645 \tTime: 0.0636\n",
      "Validation \tLoss_D: 0.6342\tLoss_G: 2.6586 \tMSE_loss: 4.4056 \tBest_loss: 4.4056\n",
      "[50/200][141/142]\tLoss_D: 0.8542\tLoss_G: 2.1332 \tMSE_loss: 3.4501 \tTime: 0.0600\n",
      "Validation \tLoss_D: 0.6257\tLoss_G: 2.6901 \tMSE_loss: 4.4239 \tBest_loss: 4.4056\n",
      "[51/200][141/142]\tLoss_D: 0.4067\tLoss_G: 2.0516 \tMSE_loss: 3.4047 \tTime: 0.0603\n",
      "Validation \tLoss_D: 0.6271\tLoss_G: 2.7146 \tMSE_loss: 4.4428 \tBest_loss: 4.4056\n",
      "[52/200][141/142]\tLoss_D: 0.5386\tLoss_G: 2.3166 \tMSE_loss: 3.6250 \tTime: 0.0612\n",
      "Validation \tLoss_D: 0.6261\tLoss_G: 2.5933 \tMSE_loss: 4.4398 \tBest_loss: 4.4056\n",
      "[53/200][141/142]\tLoss_D: 0.7137\tLoss_G: 2.3745 \tMSE_loss: 3.3843 \tTime: 0.0603\n",
      "Validation \tLoss_D: 0.6406\tLoss_G: 2.6842 \tMSE_loss: 4.4153 \tBest_loss: 4.4056\n",
      "[54/200][141/142]\tLoss_D: 0.6508\tLoss_G: 1.8700 \tMSE_loss: 3.0982 \tTime: 0.0648\n",
      "Validation \tLoss_D: 0.6354\tLoss_G: 2.5935 \tMSE_loss: 4.3962 \tBest_loss: 4.3962\n",
      "[55/200][141/142]\tLoss_D: 0.7004\tLoss_G: 2.1112 \tMSE_loss: 3.2000 \tTime: 0.0566\n",
      "Validation \tLoss_D: 0.6249\tLoss_G: 2.6495 \tMSE_loss: 4.4629 \tBest_loss: 4.3962\n",
      "[56/200][141/142]\tLoss_D: 0.3172\tLoss_G: 2.8667 \tMSE_loss: 5.1874 \tTime: 0.0653\n",
      "Validation \tLoss_D: 0.6389\tLoss_G: 2.7793 \tMSE_loss: 4.4998 \tBest_loss: 4.3962\n",
      "[57/200][141/142]\tLoss_D: 0.7094\tLoss_G: 2.6670 \tMSE_loss: 4.1017 \tTime: 0.0588\n",
      "Validation \tLoss_D: 0.6661\tLoss_G: 2.6086 \tMSE_loss: 4.3721 \tBest_loss: 4.3721\n",
      "[58/200][141/142]\tLoss_D: 0.3981\tLoss_G: 2.0000 \tMSE_loss: 4.4555 \tTime: 0.0579\n",
      "Validation \tLoss_D: 0.6443\tLoss_G: 2.5859 \tMSE_loss: 4.4092 \tBest_loss: 4.3721\n",
      "[59/200][141/142]\tLoss_D: 0.8604\tLoss_G: 2.6772 \tMSE_loss: 3.6359 \tTime: 0.0648\n",
      "Validation \tLoss_D: 0.6173\tLoss_G: 2.6921 \tMSE_loss: 4.5335 \tBest_loss: 4.3721\n",
      "[60/200][141/142]\tLoss_D: 0.6992\tLoss_G: 2.2805 \tMSE_loss: 5.7785 \tTime: 0.0635\n",
      "Validation \tLoss_D: 0.6625\tLoss_G: 2.4810 \tMSE_loss: 4.3521 \tBest_loss: 4.3521\n",
      "[61/200][141/142]\tLoss_D: 0.6716\tLoss_G: 1.8393 \tMSE_loss: 3.0259 \tTime: 0.0703\n",
      "Validation \tLoss_D: 0.6583\tLoss_G: 2.4779 \tMSE_loss: 4.3617 \tBest_loss: 4.3521\n",
      "[62/200][141/142]\tLoss_D: 0.7478\tLoss_G: 1.9638 \tMSE_loss: 2.5199 \tTime: 0.0637\n",
      "Validation \tLoss_D: 0.6528\tLoss_G: 2.5529 \tMSE_loss: 4.4226 \tBest_loss: 4.3521\n",
      "[63/200][141/142]\tLoss_D: 0.6075\tLoss_G: 1.7195 \tMSE_loss: 4.2961 \tTime: 0.0667\n",
      "Validation \tLoss_D: 0.6658\tLoss_G: 2.4182 \tMSE_loss: 4.3560 \tBest_loss: 4.3521\n",
      "[64/200][141/142]\tLoss_D: 0.5561\tLoss_G: 2.4057 \tMSE_loss: 6.5352 \tTime: 0.0663\n",
      "Validation \tLoss_D: 0.6628\tLoss_G: 2.5603 \tMSE_loss: 4.4285 \tBest_loss: 4.3521\n",
      "[65/200][141/142]\tLoss_D: 0.6221\tLoss_G: 2.2092 \tMSE_loss: 3.9871 \tTime: 0.0608\n",
      "Validation \tLoss_D: 0.6695\tLoss_G: 2.4855 \tMSE_loss: 4.3756 \tBest_loss: 4.3521\n",
      "[66/200][141/142]\tLoss_D: 0.6364\tLoss_G: 1.9662 \tMSE_loss: 3.6343 \tTime: 0.0630\n",
      "Validation \tLoss_D: 0.6630\tLoss_G: 2.4210 \tMSE_loss: 4.3858 \tBest_loss: 4.3521\n",
      "[67/200][141/142]\tLoss_D: 0.7343\tLoss_G: 2.0261 \tMSE_loss: 2.4743 \tTime: 0.0644\n",
      "Validation \tLoss_D: 0.6858\tLoss_G: 2.4891 \tMSE_loss: 4.3772 \tBest_loss: 4.3521\n",
      "[68/200][141/142]\tLoss_D: 0.3828\tLoss_G: 2.4109 \tMSE_loss: 7.2212 \tTime: 0.0609\n",
      "Validation \tLoss_D: 0.6710\tLoss_G: 2.5404 \tMSE_loss: 4.4581 \tBest_loss: 4.3521\n",
      "[69/200][141/142]\tLoss_D: 0.7006\tLoss_G: 2.0445 \tMSE_loss: 5.1242 \tTime: 0.0627\n",
      "Validation \tLoss_D: 0.6795\tLoss_G: 2.3742 \tMSE_loss: 4.3779 \tBest_loss: 4.3521\n",
      "[70/200][141/142]\tLoss_D: 0.9151\tLoss_G: 2.2322 \tMSE_loss: 3.2035 \tTime: 0.0569\n",
      "Validation \tLoss_D: 0.7039\tLoss_G: 2.3116 \tMSE_loss: 4.3126 \tBest_loss: 4.3126\n",
      "[71/200][141/142]\tLoss_D: 0.5694\tLoss_G: 2.2341 \tMSE_loss: 4.2231 \tTime: 0.0554\n",
      "Validation \tLoss_D: 0.7036\tLoss_G: 2.3822 \tMSE_loss: 4.3912 \tBest_loss: 4.3126\n",
      "[72/200][141/142]\tLoss_D: 0.6437\tLoss_G: 2.3943 \tMSE_loss: 3.7745 \tTime: 0.0678\n",
      "Validation \tLoss_D: 0.7008\tLoss_G: 2.3545 \tMSE_loss: 4.4116 \tBest_loss: 4.3126\n",
      "[73/200][141/142]\tLoss_D: 0.7276\tLoss_G: 2.1833 \tMSE_loss: 8.8348 \tTime: 0.0613\n",
      "Validation \tLoss_D: 0.7053\tLoss_G: 2.2049 \tMSE_loss: 4.3322 \tBest_loss: 4.3126\n",
      "[74/200][141/142]\tLoss_D: 0.5763\tLoss_G: 2.1479 \tMSE_loss: 4.4472 \tTime: 0.0551\n",
      "Validation \tLoss_D: 0.7012\tLoss_G: 2.2021 \tMSE_loss: 4.3611 \tBest_loss: 4.3126\n",
      "[75/200][141/142]\tLoss_D: 0.7348\tLoss_G: 2.0985 \tMSE_loss: 3.9930 \tTime: 0.0599\n",
      "Validation \tLoss_D: 0.7287\tLoss_G: 2.2177 \tMSE_loss: 4.3614 \tBest_loss: 4.3126\n",
      "[76/200][141/142]\tLoss_D: 0.8587\tLoss_G: 2.3220 \tMSE_loss: 3.0855 \tTime: 0.0606\n",
      "Validation \tLoss_D: 0.7368\tLoss_G: 2.1227 \tMSE_loss: 4.3035 \tBest_loss: 4.3035\n",
      "[77/200][141/142]\tLoss_D: 0.7062\tLoss_G: 2.0178 \tMSE_loss: 7.0770 \tTime: 0.0676\n",
      "Validation \tLoss_D: 0.7135\tLoss_G: 2.1463 \tMSE_loss: 4.3767 \tBest_loss: 4.3035\n",
      "[78/200][141/142]\tLoss_D: 0.8177\tLoss_G: 1.7234 \tMSE_loss: 5.3404 \tTime: 0.0676\n",
      "Validation \tLoss_D: 0.7304\tLoss_G: 2.0742 \tMSE_loss: 4.3569 \tBest_loss: 4.3035\n",
      "[79/200][141/142]\tLoss_D: 0.6448\tLoss_G: 2.3142 \tMSE_loss: 3.8454 \tTime: 0.0646\n",
      "Validation \tLoss_D: 0.7185\tLoss_G: 2.1371 \tMSE_loss: 4.4490 \tBest_loss: 4.3035\n",
      "[80/200][141/142]\tLoss_D: 0.7524\tLoss_G: 2.0874 \tMSE_loss: 4.1507 \tTime: 0.0542\n",
      "Validation \tLoss_D: 0.7484\tLoss_G: 2.0292 \tMSE_loss: 4.3383 \tBest_loss: 4.3035\n",
      "[81/200][141/142]\tLoss_D: 0.8766\tLoss_G: 1.7538 \tMSE_loss: 5.2117 \tTime: 0.0635\n",
      "Validation \tLoss_D: 0.7277\tLoss_G: 2.0735 \tMSE_loss: 4.4203 \tBest_loss: 4.3035\n",
      "[82/200][141/142]\tLoss_D: 0.6855\tLoss_G: 1.6395 \tMSE_loss: 4.5944 \tTime: 0.0658\n",
      "Validation \tLoss_D: 0.7437\tLoss_G: 2.0221 \tMSE_loss: 4.4081 \tBest_loss: 4.3035\n",
      "[83/200][141/142]\tLoss_D: 0.4945\tLoss_G: 1.8423 \tMSE_loss: 3.0803 \tTime: 0.0592\n",
      "Validation \tLoss_D: 0.7150\tLoss_G: 2.0773 \tMSE_loss: 4.4844 \tBest_loss: 4.3035\n",
      "[84/200][141/142]\tLoss_D: 0.7557\tLoss_G: 1.6857 \tMSE_loss: 4.4683 \tTime: 0.0643\n",
      "Validation \tLoss_D: 0.7505\tLoss_G: 1.9678 \tMSE_loss: 4.3083 \tBest_loss: 4.3035\n",
      "[85/200][141/142]\tLoss_D: 0.8408\tLoss_G: 2.1537 \tMSE_loss: 3.1681 \tTime: 0.0590\n",
      "Validation \tLoss_D: 0.7318\tLoss_G: 2.0353 \tMSE_loss: 4.4432 \tBest_loss: 4.3035\n",
      "[86/200][141/142]\tLoss_D: 0.8275\tLoss_G: 1.6672 \tMSE_loss: 6.9484 \tTime: 0.0598\n",
      "Validation \tLoss_D: 0.7305\tLoss_G: 1.9727 \tMSE_loss: 4.4053 \tBest_loss: 4.3035\n",
      "[87/200][141/142]\tLoss_D: 0.5962\tLoss_G: 2.3559 \tMSE_loss: 4.6335 \tTime: 0.0655\n",
      "Validation \tLoss_D: 0.7438\tLoss_G: 1.8320 \tMSE_loss: 4.3419 \tBest_loss: 4.3035\n",
      "[88/200][141/142]\tLoss_D: 0.7593\tLoss_G: 2.0075 \tMSE_loss: 3.9906 \tTime: 0.0593\n",
      "Validation \tLoss_D: 0.7199\tLoss_G: 1.9677 \tMSE_loss: 4.4079 \tBest_loss: 4.3035\n",
      "[89/200][141/142]\tLoss_D: 0.6870\tLoss_G: 1.9033 \tMSE_loss: 3.1624 \tTime: 0.0677\n",
      "Validation \tLoss_D: 0.7104\tLoss_G: 1.9503 \tMSE_loss: 4.4323 \tBest_loss: 4.3035\n",
      "[90/200][141/142]\tLoss_D: 0.6187\tLoss_G: 2.2602 \tMSE_loss: 3.5781 \tTime: 0.0583\n",
      "Validation \tLoss_D: 0.7294\tLoss_G: 1.9395 \tMSE_loss: 4.4126 \tBest_loss: 4.3035\n",
      "[91/200][141/142]\tLoss_D: 0.6246\tLoss_G: 2.0385 \tMSE_loss: 4.4407 \tTime: 0.0631\n",
      "Validation \tLoss_D: 0.7139\tLoss_G: 1.9142 \tMSE_loss: 4.3869 \tBest_loss: 4.3035\n",
      "[92/200][141/142]\tLoss_D: 0.6367\tLoss_G: 1.9558 \tMSE_loss: 6.1875 \tTime: 0.0610\n",
      "Validation \tLoss_D: 0.7210\tLoss_G: 1.9539 \tMSE_loss: 4.3993 \tBest_loss: 4.3035\n",
      "[93/200][141/142]\tLoss_D: 0.7993\tLoss_G: 1.6571 \tMSE_loss: 3.8662 \tTime: 0.0630\n",
      "Validation \tLoss_D: 0.7264\tLoss_G: 1.8549 \tMSE_loss: 4.3628 \tBest_loss: 4.3035\n",
      "[94/200][141/142]\tLoss_D: 0.8122\tLoss_G: 1.9132 \tMSE_loss: 3.2984 \tTime: 0.0618\n",
      "Validation \tLoss_D: 0.7091\tLoss_G: 1.9055 \tMSE_loss: 4.3950 \tBest_loss: 4.3035\n",
      "[95/200][141/142]\tLoss_D: 1.0912\tLoss_G: 2.0251 \tMSE_loss: 3.9572 \tTime: 0.0681\n",
      "Validation \tLoss_D: 0.7202\tLoss_G: 1.8786 \tMSE_loss: 4.3544 \tBest_loss: 4.3035\n",
      "[96/200][141/142]\tLoss_D: 0.5799\tLoss_G: 1.8013 \tMSE_loss: 3.4277 \tTime: 0.0586\n",
      "Validation \tLoss_D: 0.7085\tLoss_G: 1.9524 \tMSE_loss: 4.4744 \tBest_loss: 4.3035\n",
      "[97/200][141/142]\tLoss_D: 0.4813\tLoss_G: 2.1975 \tMSE_loss: 5.0602 \tTime: 0.0611\n",
      "Validation \tLoss_D: 0.7048\tLoss_G: 1.9139 \tMSE_loss: 4.4260 \tBest_loss: 4.3035\n",
      "[98/200][141/142]\tLoss_D: 1.0122\tLoss_G: 2.1935 \tMSE_loss: 3.4121 \tTime: 0.0608\n",
      "Validation \tLoss_D: 0.7172\tLoss_G: 1.7396 \tMSE_loss: 4.3059 \tBest_loss: 4.3035\n",
      "[99/200][141/142]\tLoss_D: 0.7674\tLoss_G: 2.1271 \tMSE_loss: 3.4485 \tTime: 0.0575\n",
      "Validation \tLoss_D: 0.7032\tLoss_G: 1.8941 \tMSE_loss: 4.3637 \tBest_loss: 4.3035\n",
      "[100/200][141/142]\tLoss_D: 0.4404\tLoss_G: 2.4055 \tMSE_loss: 3.7580 \tTime: 0.0579\n",
      "Validation \tLoss_D: 0.6996\tLoss_G: 1.8613 \tMSE_loss: 4.3716 \tBest_loss: 4.3035\n",
      "[101/200][141/142]\tLoss_D: 0.6954\tLoss_G: 1.8359 \tMSE_loss: 4.6336 \tTime: 0.0574\n",
      "Validation \tLoss_D: 0.6986\tLoss_G: 1.8525 \tMSE_loss: 4.3265 \tBest_loss: 4.3035\n",
      "[102/200][141/142]\tLoss_D: 0.6157\tLoss_G: 1.9278 \tMSE_loss: 10.6510 \tTime: 0.0549\n",
      "Validation \tLoss_D: 0.6924\tLoss_G: 1.9008 \tMSE_loss: 4.4155 \tBest_loss: 4.3035\n",
      "[103/200][141/142]\tLoss_D: 0.6981\tLoss_G: 2.0178 \tMSE_loss: 4.4001 \tTime: 0.0633\n",
      "Validation \tLoss_D: 0.7099\tLoss_G: 1.7931 \tMSE_loss: 4.3344 \tBest_loss: 4.3035\n",
      "[104/200][141/142]\tLoss_D: 0.6125\tLoss_G: 1.9681 \tMSE_loss: 4.5640 \tTime: 0.0662\n",
      "Validation \tLoss_D: 0.7024\tLoss_G: 1.8491 \tMSE_loss: 4.3073 \tBest_loss: 4.3035\n",
      "[105/200][141/142]\tLoss_D: 0.7609\tLoss_G: 1.9796 \tMSE_loss: 5.0368 \tTime: 0.0659\n",
      "Validation \tLoss_D: 0.7020\tLoss_G: 1.7861 \tMSE_loss: 4.3429 \tBest_loss: 4.3035\n",
      "[106/200][141/142]\tLoss_D: 0.5747\tLoss_G: 2.3215 \tMSE_loss: 3.5910 \tTime: 0.0587\n",
      "Validation \tLoss_D: 0.6795\tLoss_G: 1.8984 \tMSE_loss: 4.4878 \tBest_loss: 4.3035\n",
      "[107/200][141/142]\tLoss_D: 0.6223\tLoss_G: 2.1050 \tMSE_loss: 3.7899 \tTime: 0.0612\n",
      "Validation \tLoss_D: 0.6746\tLoss_G: 1.8432 \tMSE_loss: 4.3428 \tBest_loss: 4.3035\n",
      "[108/200][141/142]\tLoss_D: 0.6362\tLoss_G: 2.4143 \tMSE_loss: 5.8454 \tTime: 0.0606\n",
      "Validation \tLoss_D: 0.6950\tLoss_G: 1.8432 \tMSE_loss: 4.2823 \tBest_loss: 4.2823\n",
      "[109/200][141/142]\tLoss_D: 0.4240\tLoss_G: 2.6358 \tMSE_loss: 6.3865 \tTime: 0.0614\n",
      "Validation \tLoss_D: 0.6978\tLoss_G: 1.9292 \tMSE_loss: 4.4014 \tBest_loss: 4.2823\n",
      "[110/200][141/142]\tLoss_D: 0.6825\tLoss_G: 2.4519 \tMSE_loss: 3.2027 \tTime: 0.0698\n",
      "Validation \tLoss_D: 0.6895\tLoss_G: 1.9482 \tMSE_loss: 4.3236 \tBest_loss: 4.2823\n",
      "[111/200][141/142]\tLoss_D: 0.8071\tLoss_G: 2.0107 \tMSE_loss: 4.6429 \tTime: 0.0582\n",
      "Validation \tLoss_D: 0.6935\tLoss_G: 1.9032 \tMSE_loss: 4.3406 \tBest_loss: 4.2823\n",
      "[112/200][141/142]\tLoss_D: 0.6097\tLoss_G: 2.4006 \tMSE_loss: 3.6374 \tTime: 0.0670\n",
      "Validation \tLoss_D: 0.6857\tLoss_G: 1.9160 \tMSE_loss: 4.3539 \tBest_loss: 4.2823\n",
      "[113/200][141/142]\tLoss_D: 0.6500\tLoss_G: 2.1797 \tMSE_loss: 3.1753 \tTime: 0.0667\n",
      "Validation \tLoss_D: 0.7138\tLoss_G: 1.7965 \tMSE_loss: 4.2474 \tBest_loss: 4.2474\n",
      "[114/200][141/142]\tLoss_D: 0.6509\tLoss_G: 1.8251 \tMSE_loss: 2.9945 \tTime: 0.0573\n",
      "Validation \tLoss_D: 0.7005\tLoss_G: 1.8139 \tMSE_loss: 4.2349 \tBest_loss: 4.2349\n",
      "[115/200][141/142]\tLoss_D: 0.6970\tLoss_G: 2.0294 \tMSE_loss: 2.5634 \tTime: 0.0598\n",
      "Validation \tLoss_D: 0.6967\tLoss_G: 1.8900 \tMSE_loss: 4.3101 \tBest_loss: 4.2349\n",
      "[116/200][141/142]\tLoss_D: 0.8516\tLoss_G: 1.9346 \tMSE_loss: 6.8440 \tTime: 0.0572\n",
      "Validation \tLoss_D: 0.7094\tLoss_G: 1.8878 \tMSE_loss: 4.2977 \tBest_loss: 4.2349\n",
      "[117/200][141/142]\tLoss_D: 0.7146\tLoss_G: 2.0464 \tMSE_loss: 5.0470 \tTime: 0.0645\n",
      "Validation \tLoss_D: 0.7036\tLoss_G: 1.9060 \tMSE_loss: 4.2803 \tBest_loss: 4.2349\n",
      "[118/200][141/142]\tLoss_D: 0.7277\tLoss_G: 1.8825 \tMSE_loss: 2.7366 \tTime: 0.0597\n",
      "Validation \tLoss_D: 0.6991\tLoss_G: 1.9320 \tMSE_loss: 4.3520 \tBest_loss: 4.2349\n",
      "[119/200][141/142]\tLoss_D: 0.8750\tLoss_G: 2.0123 \tMSE_loss: 4.8362 \tTime: 0.0676\n",
      "Validation \tLoss_D: 0.7153\tLoss_G: 1.8495 \tMSE_loss: 4.3003 \tBest_loss: 4.2349\n",
      "[120/200][141/142]\tLoss_D: 0.8274\tLoss_G: 1.9277 \tMSE_loss: 4.8116 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.7312\tLoss_G: 1.8747 \tMSE_loss: 4.2317 \tBest_loss: 4.2317\n",
      "[121/200][141/142]\tLoss_D: 0.6792\tLoss_G: 2.0192 \tMSE_loss: 3.1678 \tTime: 0.0606\n",
      "Validation \tLoss_D: 0.7312\tLoss_G: 1.7480 \tMSE_loss: 4.2031 \tBest_loss: 4.2031\n",
      "[122/200][141/142]\tLoss_D: 0.6518\tLoss_G: 2.3501 \tMSE_loss: 4.0567 \tTime: 0.0624\n",
      "Validation \tLoss_D: 0.6818\tLoss_G: 2.0027 \tMSE_loss: 4.4442 \tBest_loss: 4.2031\n",
      "[123/200][141/142]\tLoss_D: 0.7254\tLoss_G: 2.0301 \tMSE_loss: 3.8552 \tTime: 0.0592\n",
      "Validation \tLoss_D: 0.7020\tLoss_G: 1.9305 \tMSE_loss: 4.3811 \tBest_loss: 4.2031\n",
      "[124/200][141/142]\tLoss_D: 0.6152\tLoss_G: 2.1953 \tMSE_loss: 4.4234 \tTime: 0.0605\n",
      "Validation \tLoss_D: 0.6924\tLoss_G: 1.9244 \tMSE_loss: 4.3386 \tBest_loss: 4.2031\n",
      "[125/200][141/142]\tLoss_D: 0.7509\tLoss_G: 2.4362 \tMSE_loss: 4.4010 \tTime: 0.0597\n",
      "Validation \tLoss_D: 0.7093\tLoss_G: 1.8792 \tMSE_loss: 4.2870 \tBest_loss: 4.2031\n",
      "[126/200][141/142]\tLoss_D: 0.7280\tLoss_G: 2.6300 \tMSE_loss: 5.8146 \tTime: 0.0577\n",
      "Validation \tLoss_D: 0.7187\tLoss_G: 1.8857 \tMSE_loss: 4.2699 \tBest_loss: 4.2031\n",
      "[127/200][141/142]\tLoss_D: 0.8098\tLoss_G: 2.2146 \tMSE_loss: 3.7201 \tTime: 0.0691\n",
      "Validation \tLoss_D: 0.7306\tLoss_G: 1.8270 \tMSE_loss: 4.2163 \tBest_loss: 4.2031\n",
      "[128/200][141/142]\tLoss_D: 0.6554\tLoss_G: 2.6234 \tMSE_loss: 3.5843 \tTime: 0.0576\n",
      "Validation \tLoss_D: 0.7454\tLoss_G: 1.8330 \tMSE_loss: 4.1835 \tBest_loss: 4.1835\n",
      "[129/200][141/142]\tLoss_D: 0.6235\tLoss_G: 2.3491 \tMSE_loss: 3.4300 \tTime: 0.0639\n",
      "Validation \tLoss_D: 0.7335\tLoss_G: 1.8531 \tMSE_loss: 4.2623 \tBest_loss: 4.1835\n",
      "[130/200][141/142]\tLoss_D: 0.7228\tLoss_G: 1.8298 \tMSE_loss: 4.9859 \tTime: 0.0671\n",
      "Validation \tLoss_D: 0.7636\tLoss_G: 1.7642 \tMSE_loss: 4.1393 \tBest_loss: 4.1393\n",
      "[131/200][141/142]\tLoss_D: 0.6316\tLoss_G: 1.4645 \tMSE_loss: 3.3126 \tTime: 0.0531\n",
      "Validation \tLoss_D: 0.7363\tLoss_G: 1.8563 \tMSE_loss: 4.2144 \tBest_loss: 4.1393\n",
      "[132/200][141/142]\tLoss_D: 0.8089\tLoss_G: 2.4315 \tMSE_loss: 4.6059 \tTime: 0.0590\n",
      "Validation \tLoss_D: 0.7262\tLoss_G: 1.9007 \tMSE_loss: 4.3416 \tBest_loss: 4.1393\n",
      "[133/200][141/142]\tLoss_D: 0.6355\tLoss_G: 2.2503 \tMSE_loss: 5.7254 \tTime: 0.0647\n",
      "Validation \tLoss_D: 0.7545\tLoss_G: 1.7848 \tMSE_loss: 4.2393 \tBest_loss: 4.1393\n",
      "[134/200][141/142]\tLoss_D: 0.6344\tLoss_G: 2.4346 \tMSE_loss: 6.0523 \tTime: 0.0534\n",
      "Validation \tLoss_D: 0.7066\tLoss_G: 1.8755 \tMSE_loss: 4.2926 \tBest_loss: 4.1393\n",
      "[135/200][141/142]\tLoss_D: 0.7732\tLoss_G: 1.8783 \tMSE_loss: 9.1067 \tTime: 0.0667\n",
      "Validation \tLoss_D: 0.7094\tLoss_G: 1.8418 \tMSE_loss: 4.3587 \tBest_loss: 4.1393\n",
      "[136/200][141/142]\tLoss_D: 0.7880\tLoss_G: 1.9475 \tMSE_loss: 2.6506 \tTime: 0.0627\n",
      "Validation \tLoss_D: 0.7188\tLoss_G: 1.8884 \tMSE_loss: 4.3310 \tBest_loss: 4.1393\n",
      "[137/200][141/142]\tLoss_D: 0.6709\tLoss_G: 1.5768 \tMSE_loss: 5.1984 \tTime: 0.0580\n",
      "Validation \tLoss_D: 0.7430\tLoss_G: 1.8448 \tMSE_loss: 4.2613 \tBest_loss: 4.1393\n",
      "[138/200][141/142]\tLoss_D: 0.6764\tLoss_G: 2.7280 \tMSE_loss: 4.2344 \tTime: 0.0615\n",
      "Validation \tLoss_D: 0.7322\tLoss_G: 1.8976 \tMSE_loss: 4.2607 \tBest_loss: 4.1393\n",
      "[139/200][141/142]\tLoss_D: 0.9785\tLoss_G: 1.5831 \tMSE_loss: 3.2289 \tTime: 0.0633\n",
      "Validation \tLoss_D: 0.7608\tLoss_G: 1.7929 \tMSE_loss: 4.2268 \tBest_loss: 4.1393\n",
      "[140/200][141/142]\tLoss_D: 0.6780\tLoss_G: 1.9646 \tMSE_loss: 5.0209 \tTime: 0.0669\n",
      "Validation \tLoss_D: 0.7394\tLoss_G: 1.9174 \tMSE_loss: 4.3584 \tBest_loss: 4.1393\n",
      "[141/200][141/142]\tLoss_D: 0.5170\tLoss_G: 1.8689 \tMSE_loss: 6.0909 \tTime: 0.0631\n",
      "Validation \tLoss_D: 0.7269\tLoss_G: 1.8470 \tMSE_loss: 4.3470 \tBest_loss: 4.1393\n",
      "[142/200][141/142]\tLoss_D: 0.6974\tLoss_G: 2.2531 \tMSE_loss: 5.0497 \tTime: 0.0607\n",
      "Validation \tLoss_D: 0.7197\tLoss_G: 1.9170 \tMSE_loss: 4.2978 \tBest_loss: 4.1393\n",
      "[143/200][141/142]\tLoss_D: 0.7829\tLoss_G: 2.4007 \tMSE_loss: 6.0271 \tTime: 0.0682\n",
      "Validation \tLoss_D: 0.7362\tLoss_G: 1.8838 \tMSE_loss: 4.2324 \tBest_loss: 4.1393\n",
      "[144/200][141/142]\tLoss_D: 0.7621\tLoss_G: 2.2871 \tMSE_loss: 7.6195 \tTime: 0.0594\n",
      "Validation \tLoss_D: 0.7555\tLoss_G: 1.7915 \tMSE_loss: 4.2234 \tBest_loss: 4.1393\n",
      "[145/200][141/142]\tLoss_D: 0.4662\tLoss_G: 2.4741 \tMSE_loss: 2.9493 \tTime: 0.0646\n",
      "Validation \tLoss_D: 0.7896\tLoss_G: 1.6791 \tMSE_loss: 4.0892 \tBest_loss: 4.0892\n",
      "[146/200][141/142]\tLoss_D: 0.7508\tLoss_G: 2.0711 \tMSE_loss: 4.3519 \tTime: 0.0626\n",
      "Validation \tLoss_D: 0.7759\tLoss_G: 1.7752 \tMSE_loss: 4.1608 \tBest_loss: 4.0892\n",
      "[147/200][141/142]\tLoss_D: 0.9042\tLoss_G: 2.0384 \tMSE_loss: 2.3254 \tTime: 0.0604\n",
      "Validation \tLoss_D: 0.7564\tLoss_G: 1.8577 \tMSE_loss: 4.2748 \tBest_loss: 4.0892\n",
      "[148/200][141/142]\tLoss_D: 0.8322\tLoss_G: 2.0509 \tMSE_loss: 2.4864 \tTime: 0.0662\n",
      "Validation \tLoss_D: 0.7668\tLoss_G: 1.7568 \tMSE_loss: 4.1682 \tBest_loss: 4.0892\n",
      "[149/200][141/142]\tLoss_D: 0.9292\tLoss_G: 2.2527 \tMSE_loss: 3.8016 \tTime: 0.0648\n",
      "Validation \tLoss_D: 0.8011\tLoss_G: 1.7218 \tMSE_loss: 4.1643 \tBest_loss: 4.0892\n",
      "[150/200][141/142]\tLoss_D: 0.8208\tLoss_G: 2.1104 \tMSE_loss: 2.2041 \tTime: 0.0643\n",
      "Validation \tLoss_D: 0.7903\tLoss_G: 1.7381 \tMSE_loss: 4.2227 \tBest_loss: 4.0892\n",
      "[151/200][141/142]\tLoss_D: 0.7357\tLoss_G: 1.9558 \tMSE_loss: 5.0624 \tTime: 0.0600\n",
      "Validation \tLoss_D: 0.7670\tLoss_G: 1.8063 \tMSE_loss: 4.2652 \tBest_loss: 4.0892\n",
      "[152/200][141/142]\tLoss_D: 0.6236\tLoss_G: 2.0407 \tMSE_loss: 4.9973 \tTime: 0.0663\n",
      "Validation \tLoss_D: 0.7585\tLoss_G: 1.8616 \tMSE_loss: 4.2958 \tBest_loss: 4.0892\n",
      "[153/200][141/142]\tLoss_D: 0.9071\tLoss_G: 1.7878 \tMSE_loss: 3.0009 \tTime: 0.0649\n",
      "Validation \tLoss_D: 0.8145\tLoss_G: 1.7569 \tMSE_loss: 4.1514 \tBest_loss: 4.0892\n",
      "[154/200][141/142]\tLoss_D: 0.6816\tLoss_G: 2.1308 \tMSE_loss: 4.1540 \tTime: 0.0529\n",
      "Validation \tLoss_D: 0.7803\tLoss_G: 1.7870 \tMSE_loss: 4.2427 \tBest_loss: 4.0892\n",
      "[155/200][141/142]\tLoss_D: 0.9621\tLoss_G: 2.3465 \tMSE_loss: 4.0592 \tTime: 0.0595\n",
      "Validation \tLoss_D: 0.7718\tLoss_G: 1.8094 \tMSE_loss: 4.2443 \tBest_loss: 4.0892\n",
      "[156/200][141/142]\tLoss_D: 0.6908\tLoss_G: 2.0906 \tMSE_loss: 3.9972 \tTime: 0.0557\n",
      "Validation \tLoss_D: 0.7877\tLoss_G: 1.7590 \tMSE_loss: 4.2288 \tBest_loss: 4.0892\n",
      "[157/200][141/142]\tLoss_D: 0.8130\tLoss_G: 1.7627 \tMSE_loss: 4.3968 \tTime: 0.0573\n",
      "Validation \tLoss_D: 0.8174\tLoss_G: 1.6837 \tMSE_loss: 4.1601 \tBest_loss: 4.0892\n",
      "[158/200][141/142]\tLoss_D: 0.8070\tLoss_G: 2.2901 \tMSE_loss: 4.4048 \tTime: 0.0600\n",
      "Validation \tLoss_D: 0.8427\tLoss_G: 1.5634 \tMSE_loss: 4.0730 \tBest_loss: 4.0730\n",
      "[159/200][141/142]\tLoss_D: 0.7450\tLoss_G: 1.6916 \tMSE_loss: 5.6145 \tTime: 0.0646\n",
      "Validation \tLoss_D: 0.8107\tLoss_G: 1.6910 \tMSE_loss: 4.2038 \tBest_loss: 4.0730\n",
      "[160/200][141/142]\tLoss_D: 0.7570\tLoss_G: 1.8788 \tMSE_loss: 4.5033 \tTime: 0.0612\n",
      "Validation \tLoss_D: 0.8704\tLoss_G: 1.5194 \tMSE_loss: 4.1001 \tBest_loss: 4.0730\n",
      "[161/200][141/142]\tLoss_D: 1.0883\tLoss_G: 1.4541 \tMSE_loss: 3.8597 \tTime: 0.0628\n",
      "Validation \tLoss_D: 0.8157\tLoss_G: 1.6903 \tMSE_loss: 4.1782 \tBest_loss: 4.0730\n",
      "[162/200][141/142]\tLoss_D: 0.6568\tLoss_G: 2.3208 \tMSE_loss: 4.2156 \tTime: 0.0589\n",
      "Validation \tLoss_D: 0.8014\tLoss_G: 1.7252 \tMSE_loss: 4.2343 \tBest_loss: 4.0730\n",
      "[163/200][141/142]\tLoss_D: 0.7173\tLoss_G: 1.7896 \tMSE_loss: 2.6064 \tTime: 0.0595\n",
      "Validation \tLoss_D: 0.7901\tLoss_G: 1.7120 \tMSE_loss: 4.2544 \tBest_loss: 4.0730\n",
      "[164/200][141/142]\tLoss_D: 0.7792\tLoss_G: 1.8258 \tMSE_loss: 3.5715 \tTime: 0.0635\n",
      "Validation \tLoss_D: 0.8161\tLoss_G: 1.7058 \tMSE_loss: 4.2892 \tBest_loss: 4.0730\n",
      "[165/200][141/142]\tLoss_D: 0.6905\tLoss_G: 1.8439 \tMSE_loss: 5.6302 \tTime: 0.0575\n",
      "Validation \tLoss_D: 0.8642\tLoss_G: 1.5525 \tMSE_loss: 4.1083 \tBest_loss: 4.0730\n",
      "[166/200][141/142]\tLoss_D: 0.8965\tLoss_G: 1.5509 \tMSE_loss: 3.3002 \tTime: 0.0637\n",
      "Validation \tLoss_D: 0.8586\tLoss_G: 1.5222 \tMSE_loss: 4.1003 \tBest_loss: 4.0730\n",
      "[167/200][141/142]\tLoss_D: 0.9943\tLoss_G: 1.7862 \tMSE_loss: 4.3597 \tTime: 0.0636\n",
      "Validation \tLoss_D: 0.8503\tLoss_G: 1.5778 \tMSE_loss: 4.1887 \tBest_loss: 4.0730\n",
      "[168/200][141/142]\tLoss_D: 0.6947\tLoss_G: 2.1850 \tMSE_loss: 3.9637 \tTime: 0.0637\n",
      "Validation \tLoss_D: 0.8884\tLoss_G: 1.5182 \tMSE_loss: 4.0935 \tBest_loss: 4.0730\n",
      "[169/200][141/142]\tLoss_D: 0.8237\tLoss_G: 2.1182 \tMSE_loss: 3.9149 \tTime: 0.0594\n",
      "Validation \tLoss_D: 0.8282\tLoss_G: 1.6387 \tMSE_loss: 4.2086 \tBest_loss: 4.0730\n",
      "[170/200][141/142]\tLoss_D: 0.6645\tLoss_G: 2.1750 \tMSE_loss: 3.4555 \tTime: 0.0668\n",
      "Validation \tLoss_D: 0.9376\tLoss_G: 1.4138 \tMSE_loss: 4.0329 \tBest_loss: 4.0329\n",
      "[171/200][141/142]\tLoss_D: 0.9118\tLoss_G: 2.0935 \tMSE_loss: 5.6577 \tTime: 0.0647\n",
      "Validation \tLoss_D: 0.9299\tLoss_G: 1.4411 \tMSE_loss: 4.0526 \tBest_loss: 4.0329\n",
      "[172/200][141/142]\tLoss_D: 1.0935\tLoss_G: 1.8236 \tMSE_loss: 3.5447 \tTime: 0.0572\n",
      "Validation \tLoss_D: 0.8500\tLoss_G: 1.5848 \tMSE_loss: 4.1609 \tBest_loss: 4.0329\n",
      "[173/200][141/142]\tLoss_D: 0.7093\tLoss_G: 2.2272 \tMSE_loss: 4.3464 \tTime: 0.0616\n",
      "Validation \tLoss_D: 0.8872\tLoss_G: 1.4501 \tMSE_loss: 4.1102 \tBest_loss: 4.0329\n",
      "[174/200][141/142]\tLoss_D: 0.8211\tLoss_G: 2.0792 \tMSE_loss: 2.7977 \tTime: 0.0630\n",
      "Validation \tLoss_D: 0.9144\tLoss_G: 1.4312 \tMSE_loss: 4.0274 \tBest_loss: 4.0274\n",
      "[175/200][141/142]\tLoss_D: 1.0675\tLoss_G: 2.1931 \tMSE_loss: 6.4474 \tTime: 0.0585\n",
      "Validation \tLoss_D: 0.9349\tLoss_G: 1.4248 \tMSE_loss: 4.1506 \tBest_loss: 4.0274\n",
      "[176/200][141/142]\tLoss_D: 0.6810\tLoss_G: 2.0637 \tMSE_loss: 6.4202 \tTime: 0.0661\n",
      "Validation \tLoss_D: 0.8874\tLoss_G: 1.5126 \tMSE_loss: 4.1771 \tBest_loss: 4.0274\n",
      "[177/200][141/142]\tLoss_D: 0.8106\tLoss_G: 2.1999 \tMSE_loss: 2.8349 \tTime: 0.0644\n",
      "Validation \tLoss_D: 0.9093\tLoss_G: 1.4539 \tMSE_loss: 4.1133 \tBest_loss: 4.0274\n",
      "[178/200][141/142]\tLoss_D: 0.6134\tLoss_G: 2.2572 \tMSE_loss: 3.2981 \tTime: 0.0585\n",
      "Validation \tLoss_D: 0.9326\tLoss_G: 1.3977 \tMSE_loss: 4.0713 \tBest_loss: 4.0274\n",
      "[179/200][141/142]\tLoss_D: 0.5880\tLoss_G: 2.3092 \tMSE_loss: 4.1750 \tTime: 0.0629\n",
      "Validation \tLoss_D: 0.8198\tLoss_G: 1.6205 \tMSE_loss: 4.2421 \tBest_loss: 4.0274\n",
      "[180/200][141/142]\tLoss_D: 0.6692\tLoss_G: 2.3748 \tMSE_loss: 6.2628 \tTime: 0.0590\n",
      "Validation \tLoss_D: 0.9280\tLoss_G: 1.4284 \tMSE_loss: 4.0889 \tBest_loss: 4.0274\n",
      "[181/200][141/142]\tLoss_D: 0.6219\tLoss_G: 2.0710 \tMSE_loss: 4.9451 \tTime: 0.0614\n",
      "Validation \tLoss_D: 0.9058\tLoss_G: 1.5091 \tMSE_loss: 4.1685 \tBest_loss: 4.0274\n",
      "[182/200][141/142]\tLoss_D: 0.8347\tLoss_G: 1.6675 \tMSE_loss: 3.6277 \tTime: 0.0584\n",
      "Validation \tLoss_D: 0.8865\tLoss_G: 1.5042 \tMSE_loss: 4.1402 \tBest_loss: 4.0274\n",
      "[183/200][141/142]\tLoss_D: 1.1589\tLoss_G: 1.8837 \tMSE_loss: 2.7446 \tTime: 0.0620\n",
      "Validation \tLoss_D: 0.9304\tLoss_G: 1.4151 \tMSE_loss: 4.1222 \tBest_loss: 4.0274\n",
      "[184/200][141/142]\tLoss_D: 0.7603\tLoss_G: 1.5529 \tMSE_loss: 2.3788 \tTime: 0.0615\n",
      "Validation \tLoss_D: 0.9256\tLoss_G: 1.4065 \tMSE_loss: 4.0904 \tBest_loss: 4.0274\n",
      "[185/200][141/142]\tLoss_D: 0.8332\tLoss_G: 2.0589 \tMSE_loss: 6.2118 \tTime: 0.0693\n",
      "Validation \tLoss_D: 0.9174\tLoss_G: 1.4168 \tMSE_loss: 4.0868 \tBest_loss: 4.0274\n",
      "[186/200][141/142]\tLoss_D: 0.8663\tLoss_G: 1.6266 \tMSE_loss: 3.8077 \tTime: 0.0545\n",
      "Validation \tLoss_D: 0.9147\tLoss_G: 1.3705 \tMSE_loss: 4.0589 \tBest_loss: 4.0274\n",
      "[187/200][141/142]\tLoss_D: 0.8305\tLoss_G: 2.1921 \tMSE_loss: 4.7636 \tTime: 0.0602\n",
      "Validation \tLoss_D: 0.9506\tLoss_G: 1.3464 \tMSE_loss: 4.0443 \tBest_loss: 4.0274\n",
      "[188/200][141/142]\tLoss_D: 0.7435\tLoss_G: 1.8590 \tMSE_loss: 4.6669 \tTime: 0.0633\n",
      "Validation \tLoss_D: 0.9920\tLoss_G: 1.2861 \tMSE_loss: 4.0140 \tBest_loss: 4.0140\n",
      "[189/200][141/142]\tLoss_D: 1.0084\tLoss_G: 1.8649 \tMSE_loss: 5.5695 \tTime: 0.0670\n",
      "Validation \tLoss_D: 0.9080\tLoss_G: 1.4778 \tMSE_loss: 4.1846 \tBest_loss: 4.0140\n",
      "[190/200][141/142]\tLoss_D: 0.9230\tLoss_G: 2.3257 \tMSE_loss: 3.8757 \tTime: 0.0592\n",
      "Validation \tLoss_D: 0.9360\tLoss_G: 1.4022 \tMSE_loss: 4.0853 \tBest_loss: 4.0140\n",
      "[191/200][141/142]\tLoss_D: 0.9041\tLoss_G: 2.2072 \tMSE_loss: 6.0711 \tTime: 0.0649\n",
      "Validation \tLoss_D: 0.9593\tLoss_G: 1.3436 \tMSE_loss: 4.0641 \tBest_loss: 4.0140\n",
      "[192/200][141/142]\tLoss_D: 0.6768\tLoss_G: 2.4721 \tMSE_loss: 5.4924 \tTime: 0.0508\n",
      "Validation \tLoss_D: 0.9643\tLoss_G: 1.3452 \tMSE_loss: 4.0929 \tBest_loss: 4.0140\n",
      "[193/200][141/142]\tLoss_D: 0.7005\tLoss_G: 2.1276 \tMSE_loss: 4.0487 \tTime: 0.0694\n",
      "Validation \tLoss_D: 0.9853\tLoss_G: 1.3223 \tMSE_loss: 3.9971 \tBest_loss: 3.9971\n",
      "[194/200][141/142]\tLoss_D: 0.9614\tLoss_G: 1.5351 \tMSE_loss: 4.5885 \tTime: 0.0634\n",
      "Validation \tLoss_D: 0.9460\tLoss_G: 1.3689 \tMSE_loss: 4.0181 \tBest_loss: 3.9971\n",
      "[195/200][141/142]\tLoss_D: 0.8243\tLoss_G: 1.8883 \tMSE_loss: 3.8785 \tTime: 0.0646\n",
      "Validation \tLoss_D: 0.9832\tLoss_G: 1.2819 \tMSE_loss: 4.0275 \tBest_loss: 3.9971\n",
      "[196/200][141/142]\tLoss_D: 0.8959\tLoss_G: 1.9255 \tMSE_loss: 3.3041 \tTime: 0.0610\n",
      "Validation \tLoss_D: 0.9883\tLoss_G: 1.2554 \tMSE_loss: 4.0157 \tBest_loss: 3.9971\n",
      "[197/200][141/142]\tLoss_D: 1.1460\tLoss_G: 1.7066 \tMSE_loss: 3.7683 \tTime: 0.0648\n",
      "Validation \tLoss_D: 0.9951\tLoss_G: 1.2576 \tMSE_loss: 3.9914 \tBest_loss: 3.9914\n",
      "[198/200][141/142]\tLoss_D: 0.9907\tLoss_G: 1.8278 \tMSE_loss: 3.9649 \tTime: 0.0571\n",
      "Validation \tLoss_D: 0.9834\tLoss_G: 1.3552 \tMSE_loss: 4.0927 \tBest_loss: 3.9914\n",
      "[199/200][141/142]\tLoss_D: 1.0200\tLoss_G: 1.9713 \tMSE_loss: 3.4809 \tTime: 0.0619\n",
      "Validation \tLoss_D: 0.9434\tLoss_G: 1.3740 \tMSE_loss: 4.0625 \tBest_loss: 3.9914\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "torch.manual_seed(8)\n",
    "\n",
    "def train_GAN(G, D, optim_G, optim_D, loss_f, train_loader, test_loader, num_epochs, device):\n",
    "    test_size = len(test_loader)\n",
    "    best = np.inf \n",
    "    for epoch in range(num_epochs):\n",
    "        for i,data in enumerate(train_loader):\n",
    "            if i<140:\n",
    "                generator.train()\n",
    "                discriminator.train()   \n",
    "                starting_time = time.time()\n",
    "                sequence , target = data\n",
    "                sequence = sequence.to(device)\n",
    "                target = target.to(device)\n",
    "                generator_fake = G(sequence)\n",
    "                true_seq = torch.concat((sequence,target.reshape(-1,1,7)),dim=1)\n",
    "                fake_seq = torch.concat((sequence,generator_fake),dim=1)\n",
    "                # ========================\n",
    "                #   Train Discriminator\n",
    "                # ========================\n",
    "                # train with real data\n",
    "                \n",
    "                prediction = D(true_seq)\n",
    "\n",
    "                # train with fake data\n",
    "                \n",
    "                fake_predection = D(fake_seq)\n",
    "                d_loss = descriminator_loss(prediction, fake_predection)\n",
    "                # update D\n",
    "                \n",
    "                D.zero_grad()\n",
    "                d_loss.backward()\n",
    "                optim_D.step()\n",
    "\n",
    "                # ========================\n",
    "                #   Train Generator\n",
    "                # ========================\n",
    "                # train with fake data  \n",
    "                        \n",
    "                sequence , target = data\n",
    "                sequence = sequence.to(device)\n",
    "                target = target.to(device)\n",
    "                generator_fake = G(sequence)\n",
    "                fake_seq = torch.concat((sequence,generator_fake),dim=1)\n",
    "                fake_predection = D(fake_seq)\n",
    "                g_loss, mse_loss = generator_loss(generator_fake,target,fake_predection)\n",
    "                # update G\n",
    "                G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                optim_G.step()   \n",
    "        print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f \\tMSE_loss: %.4f \\tTime: %.4f'% (epoch, num_epochs, i, len(train_loader), d_loss.item(), g_loss.item(),mse_loss.item(),time.time()-starting_time))\n",
    "        #evaluate \n",
    "        dis_loss = 0\n",
    "        gen_loss= 0\n",
    "        mse_loss = 0\n",
    "        diss_losses = []\n",
    "        gen_losses = []\n",
    "        mse_losses = []\n",
    "\n",
    "        for i,data in enumerate(test_loader):\n",
    "            generator.eval()\n",
    "            discriminator.eval()\n",
    "            with torch.no_grad():\n",
    "                sequence , target = data\n",
    "                sequence = sequence.to(device)\n",
    "                target = target.to(device)\n",
    "                generator_fake = G(sequence)\n",
    "                fake_seq = torch.concat((sequence,generator_fake),dim=1)\n",
    "                true_seq = torch.concat((sequence,target.reshape(-1,1,7)),dim=1)\n",
    "                fake_predection = D(fake_seq)\n",
    "                g_loss, mse = generator_loss(generator_fake,target,fake_predection)\n",
    "                prediction = D(true_seq)\n",
    "                d_loss = descriminator_loss(prediction, fake_predection)\n",
    "                dis_loss += d_loss.item()/test_size\n",
    "                gen_loss += g_loss.item()/test_size\n",
    "                mse_loss += mse.item()/test_size\n",
    "        diss_losses.append(dis_loss)\n",
    "        gen_losses.append(gen_loss)\n",
    "        mse_losses.append(mse_loss)\n",
    "\n",
    "        if mse_loss < best:\n",
    "            best = mse_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': G.state_dict(),\n",
    "                'optimizer_state_dict': optim_G.state_dict(),\n",
    "            }, 'Kan_gan.pth') \n",
    "        print('Validation \\tLoss_D: %.4f\\tLoss_G: %.4f \\tMSE_loss: %.4f \\tBest_loss: %.4f'% (dis_loss, gen_loss,mse_loss,best))\n",
    "    return diss_losses, gen_losses, mse_losses\n",
    "\n",
    "\n",
    "    \n",
    "loss_fn = nn.BCELoss()\n",
    "mse_fn = nn.MSELoss()\n",
    "\n",
    "a1 = 0.01\n",
    "def descriminator_loss(real_output, fake_output):\n",
    "    real_loss = loss_fn(real_output, torch.ones_like(real_output))\n",
    "    fake_loss = loss_fn(fake_output, torch.zeros_like(fake_output))\n",
    "    return real_loss + fake_loss\n",
    "def generator_loss(x,y,fake_output):\n",
    "    loss = loss_fn(fake_output, torch.ones_like(fake_output))\n",
    "    mse_loss = mse_fn(x,y.reshape(-1,1,7))\n",
    "    return a1*mse_loss + (1-a1)*loss , mse_loss\n",
    "\n",
    "epochs = 200\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = GeneratorModel(n_sequence, n_features).to(torch.float64)\n",
    "discriminator = KAN_discriminator(n_sequence,n_features).to(torch.float64)\n",
    "generator , discriminator = generator.to(device), discriminator.to(device)\n",
    "\n",
    "learning_rate1 = 0.00003\n",
    "learning_rate2 = 0.00003\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate1, betas=(0.5, 0.999))\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate2, betas=(0.5, 0.999))\n",
    "checkpoint_path = \"./train_checkpoints\"\n",
    "\n",
    "result = train_GAN(generator, discriminator, generator_optimizer, discriminator_optimizer, loss_fn, data_gen_train, data_gen_test, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe0038ef-c00e-4b2a-84dc-3bddc2d65d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/200][141/142]\tLoss_D: 0.8506\tLoss_G: 2.1091 \tMSE_loss: 5.8328 \tTime: 0.0645\n",
      "Validation \tLoss_D: 0.9913\tLoss_G: 1.3309 \tMSE_loss: 3.9991 \tBest_loss: 3.9991\n",
      "[1/200][141/142]\tLoss_D: 0.9270\tLoss_G: 2.2501 \tMSE_loss: 2.9251 \tTime: 0.0593\n",
      "Validation \tLoss_D: 0.9889\tLoss_G: 1.3140 \tMSE_loss: 4.0509 \tBest_loss: 3.9991\n",
      "[2/200][141/142]\tLoss_D: 0.8462\tLoss_G: 2.3363 \tMSE_loss: 2.9431 \tTime: 0.0578\n",
      "Validation \tLoss_D: 1.0225\tLoss_G: 1.2423 \tMSE_loss: 3.9714 \tBest_loss: 3.9714\n",
      "[3/200][141/142]\tLoss_D: 0.7071\tLoss_G: 2.0792 \tMSE_loss: 4.1527 \tTime: 0.0533\n",
      "Validation \tLoss_D: 1.0106\tLoss_G: 1.2666 \tMSE_loss: 3.9857 \tBest_loss: 3.9714\n",
      "[4/200][141/142]\tLoss_D: 1.0966\tLoss_G: 1.8984 \tMSE_loss: 2.5710 \tTime: 0.0625\n",
      "Validation \tLoss_D: 1.0296\tLoss_G: 1.2640 \tMSE_loss: 3.9921 \tBest_loss: 3.9714\n",
      "[5/200][141/142]\tLoss_D: 0.8103\tLoss_G: 1.8567 \tMSE_loss: 2.8546 \tTime: 0.0621\n",
      "Validation \tLoss_D: 1.0331\tLoss_G: 1.2532 \tMSE_loss: 3.9942 \tBest_loss: 3.9714\n",
      "[6/200][141/142]\tLoss_D: 1.0591\tLoss_G: 1.9432 \tMSE_loss: 5.3829 \tTime: 0.0667\n",
      "Validation \tLoss_D: 0.9916\tLoss_G: 1.3057 \tMSE_loss: 4.0191 \tBest_loss: 3.9714\n",
      "[7/200][141/142]\tLoss_D: 0.7500\tLoss_G: 1.6122 \tMSE_loss: 4.4485 \tTime: 0.0614\n",
      "Validation \tLoss_D: 0.9997\tLoss_G: 1.2930 \tMSE_loss: 4.0608 \tBest_loss: 3.9714\n",
      "[8/200][141/142]\tLoss_D: 0.8593\tLoss_G: 2.0327 \tMSE_loss: 3.0570 \tTime: 0.0729\n",
      "Validation \tLoss_D: 1.0251\tLoss_G: 1.2410 \tMSE_loss: 3.9955 \tBest_loss: 3.9714\n",
      "[9/200][141/142]\tLoss_D: 0.9229\tLoss_G: 2.0863 \tMSE_loss: 5.3136 \tTime: 0.0643\n",
      "Validation \tLoss_D: 1.0151\tLoss_G: 1.2796 \tMSE_loss: 4.0282 \tBest_loss: 3.9714\n",
      "[10/200][141/142]\tLoss_D: 0.7404\tLoss_G: 1.4092 \tMSE_loss: 2.3910 \tTime: 0.0568\n",
      "Validation \tLoss_D: 1.0571\tLoss_G: 1.1925 \tMSE_loss: 3.9348 \tBest_loss: 3.9348\n",
      "[11/200][141/142]\tLoss_D: 0.7530\tLoss_G: 1.8325 \tMSE_loss: 5.4115 \tTime: 0.0579\n",
      "Validation \tLoss_D: 0.9894\tLoss_G: 1.3690 \tMSE_loss: 4.0609 \tBest_loss: 3.9348\n",
      "[12/200][141/142]\tLoss_D: 0.8661\tLoss_G: 1.6319 \tMSE_loss: 2.8460 \tTime: 0.0590\n",
      "Validation \tLoss_D: 1.0330\tLoss_G: 1.2526 \tMSE_loss: 3.9348 \tBest_loss: 3.9348\n",
      "[13/200][141/142]\tLoss_D: 0.8397\tLoss_G: 2.0829 \tMSE_loss: 4.0467 \tTime: 0.0578\n",
      "Validation \tLoss_D: 1.0308\tLoss_G: 1.2649 \tMSE_loss: 3.9671 \tBest_loss: 3.9348\n",
      "[14/200][141/142]\tLoss_D: 0.8426\tLoss_G: 2.0723 \tMSE_loss: 3.1833 \tTime: 0.0631\n",
      "Validation \tLoss_D: 1.0547\tLoss_G: 1.2043 \tMSE_loss: 3.9420 \tBest_loss: 3.9348\n",
      "[15/200][141/142]\tLoss_D: 0.6447\tLoss_G: 2.0475 \tMSE_loss: 2.7679 \tTime: 0.0639\n",
      "Validation \tLoss_D: 1.0633\tLoss_G: 1.1899 \tMSE_loss: 3.9043 \tBest_loss: 3.9043\n",
      "[16/200][141/142]\tLoss_D: 0.6813\tLoss_G: 1.6978 \tMSE_loss: 3.0198 \tTime: 0.0642\n",
      "Validation \tLoss_D: 1.0498\tLoss_G: 1.2065 \tMSE_loss: 3.9780 \tBest_loss: 3.9043\n",
      "[17/200][141/142]\tLoss_D: 0.6531\tLoss_G: 1.9107 \tMSE_loss: 3.7595 \tTime: 0.0607\n",
      "Validation \tLoss_D: 1.0661\tLoss_G: 1.2029 \tMSE_loss: 3.9401 \tBest_loss: 3.9043\n",
      "[18/200][141/142]\tLoss_D: 0.8818\tLoss_G: 2.0059 \tMSE_loss: 3.9127 \tTime: 0.0550\n",
      "Validation \tLoss_D: 1.0520\tLoss_G: 1.2336 \tMSE_loss: 3.9873 \tBest_loss: 3.9043\n",
      "[19/200][141/142]\tLoss_D: 0.9158\tLoss_G: 1.9080 \tMSE_loss: 4.8996 \tTime: 0.0566\n",
      "Validation \tLoss_D: 1.0632\tLoss_G: 1.2111 \tMSE_loss: 3.9788 \tBest_loss: 3.9043\n",
      "[20/200][141/142]\tLoss_D: 0.8779\tLoss_G: 1.9460 \tMSE_loss: 4.0807 \tTime: 0.0504\n",
      "Validation \tLoss_D: 1.0526\tLoss_G: 1.1778 \tMSE_loss: 3.9488 \tBest_loss: 3.9043\n",
      "[21/200][141/142]\tLoss_D: 1.1295\tLoss_G: 1.8213 \tMSE_loss: 2.4124 \tTime: 0.0573\n",
      "Validation \tLoss_D: 1.0366\tLoss_G: 1.2572 \tMSE_loss: 3.9712 \tBest_loss: 3.9043\n",
      "[22/200][141/142]\tLoss_D: 0.9795\tLoss_G: 1.5552 \tMSE_loss: 4.2521 \tTime: 0.0655\n",
      "Validation \tLoss_D: 1.1063\tLoss_G: 1.1337 \tMSE_loss: 3.9496 \tBest_loss: 3.9043\n",
      "[23/200][141/142]\tLoss_D: 0.9026\tLoss_G: 1.9355 \tMSE_loss: 3.6104 \tTime: 0.0614\n",
      "Validation \tLoss_D: 1.0245\tLoss_G: 1.3068 \tMSE_loss: 4.0428 \tBest_loss: 3.9043\n",
      "[24/200][141/142]\tLoss_D: 1.1260\tLoss_G: 1.7260 \tMSE_loss: 4.3483 \tTime: 0.0661\n",
      "Validation \tLoss_D: 1.0703\tLoss_G: 1.2109 \tMSE_loss: 3.9498 \tBest_loss: 3.9043\n",
      "[25/200][141/142]\tLoss_D: 0.8176\tLoss_G: 2.1038 \tMSE_loss: 5.1784 \tTime: 0.0584\n",
      "Validation \tLoss_D: 1.0670\tLoss_G: 1.1735 \tMSE_loss: 3.9066 \tBest_loss: 3.9043\n",
      "[26/200][141/142]\tLoss_D: 0.8982\tLoss_G: 1.8147 \tMSE_loss: 4.0471 \tTime: 0.0563\n",
      "Validation \tLoss_D: 1.1158\tLoss_G: 1.0849 \tMSE_loss: 3.8910 \tBest_loss: 3.8910\n",
      "[27/200][141/142]\tLoss_D: 0.9073\tLoss_G: 2.1026 \tMSE_loss: 3.6569 \tTime: 0.0692\n",
      "Validation \tLoss_D: 1.0801\tLoss_G: 1.2135 \tMSE_loss: 3.9210 \tBest_loss: 3.8910\n",
      "[28/200][141/142]\tLoss_D: 0.8395\tLoss_G: 2.3170 \tMSE_loss: 3.8253 \tTime: 0.0582\n",
      "Validation \tLoss_D: 1.0651\tLoss_G: 1.2042 \tMSE_loss: 3.9126 \tBest_loss: 3.8910\n",
      "[29/200][141/142]\tLoss_D: 0.8329\tLoss_G: 2.0337 \tMSE_loss: 7.2574 \tTime: 0.0600\n",
      "Validation \tLoss_D: 1.0328\tLoss_G: 1.2988 \tMSE_loss: 3.9848 \tBest_loss: 3.8910\n",
      "[30/200][141/142]\tLoss_D: 0.7047\tLoss_G: 1.7254 \tMSE_loss: 5.0440 \tTime: 0.0537\n",
      "Validation \tLoss_D: 1.0675\tLoss_G: 1.2073 \tMSE_loss: 3.9542 \tBest_loss: 3.8910\n",
      "[31/200][141/142]\tLoss_D: 0.8384\tLoss_G: 1.9136 \tMSE_loss: 3.0478 \tTime: 0.0630\n",
      "Validation \tLoss_D: 1.1200\tLoss_G: 1.0848 \tMSE_loss: 3.8822 \tBest_loss: 3.8822\n",
      "[32/200][141/142]\tLoss_D: 0.7447\tLoss_G: 1.9706 \tMSE_loss: 5.2893 \tTime: 0.0573\n",
      "Validation \tLoss_D: 1.0923\tLoss_G: 1.1647 \tMSE_loss: 3.9722 \tBest_loss: 3.8822\n",
      "[33/200][141/142]\tLoss_D: 0.8683\tLoss_G: 2.2945 \tMSE_loss: 3.5135 \tTime: 0.0642\n",
      "Validation \tLoss_D: 1.0694\tLoss_G: 1.2222 \tMSE_loss: 4.0024 \tBest_loss: 3.8822\n",
      "[34/200][141/142]\tLoss_D: 0.7344\tLoss_G: 2.8690 \tMSE_loss: 4.2258 \tTime: 0.0610\n",
      "Validation \tLoss_D: 1.1136\tLoss_G: 1.1286 \tMSE_loss: 3.9030 \tBest_loss: 3.8822\n",
      "[35/200][141/142]\tLoss_D: 0.7450\tLoss_G: 1.9512 \tMSE_loss: 4.9035 \tTime: 0.0621\n",
      "Validation \tLoss_D: 1.1090\tLoss_G: 1.1615 \tMSE_loss: 3.9282 \tBest_loss: 3.8822\n",
      "[36/200][141/142]\tLoss_D: 0.7302\tLoss_G: 2.1641 \tMSE_loss: 3.4394 \tTime: 0.0662\n",
      "Validation \tLoss_D: 1.1145\tLoss_G: 1.1353 \tMSE_loss: 3.9021 \tBest_loss: 3.8822\n",
      "[37/200][141/142]\tLoss_D: 0.7441\tLoss_G: 1.6565 \tMSE_loss: 2.9892 \tTime: 0.0607\n",
      "Validation \tLoss_D: 1.0653\tLoss_G: 1.2426 \tMSE_loss: 4.0032 \tBest_loss: 3.8822\n",
      "[38/200][141/142]\tLoss_D: 0.8035\tLoss_G: 1.8406 \tMSE_loss: 2.8546 \tTime: 0.0648\n",
      "Validation \tLoss_D: 1.0869\tLoss_G: 1.1966 \tMSE_loss: 3.9539 \tBest_loss: 3.8822\n",
      "[39/200][141/142]\tLoss_D: 0.9791\tLoss_G: 2.3122 \tMSE_loss: 4.7008 \tTime: 0.0579\n",
      "Validation \tLoss_D: 1.0852\tLoss_G: 1.2223 \tMSE_loss: 3.9603 \tBest_loss: 3.8822\n",
      "[40/200][141/142]\tLoss_D: 0.7191\tLoss_G: 1.9485 \tMSE_loss: 4.8913 \tTime: 0.0616\n",
      "Validation \tLoss_D: 1.0899\tLoss_G: 1.2068 \tMSE_loss: 3.9045 \tBest_loss: 3.8822\n",
      "[41/200][141/142]\tLoss_D: 0.9184\tLoss_G: 2.4483 \tMSE_loss: 4.5391 \tTime: 0.0635\n",
      "Validation \tLoss_D: 1.1353\tLoss_G: 1.0922 \tMSE_loss: 3.8971 \tBest_loss: 3.8822\n",
      "[42/200][141/142]\tLoss_D: 0.9517\tLoss_G: 2.0496 \tMSE_loss: 5.0646 \tTime: 0.0607\n",
      "Validation \tLoss_D: 1.1038\tLoss_G: 1.1852 \tMSE_loss: 3.9557 \tBest_loss: 3.8822\n",
      "[43/200][141/142]\tLoss_D: 0.9321\tLoss_G: 2.0603 \tMSE_loss: 4.0027 \tTime: 0.0606\n",
      "Validation \tLoss_D: 1.0955\tLoss_G: 1.2001 \tMSE_loss: 3.9329 \tBest_loss: 3.8822\n",
      "[44/200][141/142]\tLoss_D: 0.7501\tLoss_G: 2.3089 \tMSE_loss: 4.9088 \tTime: 0.0599\n",
      "Validation \tLoss_D: 1.1286\tLoss_G: 1.1647 \tMSE_loss: 3.8898 \tBest_loss: 3.8822\n",
      "[45/200][141/142]\tLoss_D: 0.8716\tLoss_G: 1.7007 \tMSE_loss: 4.0184 \tTime: 0.0557\n",
      "Validation \tLoss_D: 1.1228\tLoss_G: 1.1689 \tMSE_loss: 3.9132 \tBest_loss: 3.8822\n",
      "[46/200][141/142]\tLoss_D: 1.1668\tLoss_G: 3.1316 \tMSE_loss: 5.1981 \tTime: 0.0623\n",
      "Validation \tLoss_D: 1.1483\tLoss_G: 1.1327 \tMSE_loss: 3.8773 \tBest_loss: 3.8773\n",
      "[47/200][141/142]\tLoss_D: 0.7297\tLoss_G: 1.7205 \tMSE_loss: 4.6083 \tTime: 0.0548\n",
      "Validation \tLoss_D: 1.1630\tLoss_G: 1.1171 \tMSE_loss: 3.8547 \tBest_loss: 3.8547\n",
      "[48/200][141/142]\tLoss_D: 0.8544\tLoss_G: 2.0370 \tMSE_loss: 5.6194 \tTime: 0.0613\n",
      "Validation \tLoss_D: 1.1193\tLoss_G: 1.1739 \tMSE_loss: 3.9254 \tBest_loss: 3.8547\n",
      "[49/200][141/142]\tLoss_D: 0.8077\tLoss_G: 2.3494 \tMSE_loss: 3.4021 \tTime: 0.0594\n",
      "Validation \tLoss_D: 1.1397\tLoss_G: 1.1662 \tMSE_loss: 3.8722 \tBest_loss: 3.8547\n",
      "[50/200][141/142]\tLoss_D: 0.7443\tLoss_G: 2.0493 \tMSE_loss: 4.5303 \tTime: 0.0606\n",
      "Validation \tLoss_D: 1.1435\tLoss_G: 1.1465 \tMSE_loss: 3.8908 \tBest_loss: 3.8547\n",
      "[51/200][141/142]\tLoss_D: 1.2093\tLoss_G: 1.8911 \tMSE_loss: 2.9570 \tTime: 0.0606\n",
      "Validation \tLoss_D: 1.1552\tLoss_G: 1.1299 \tMSE_loss: 3.9009 \tBest_loss: 3.8547\n",
      "[52/200][141/142]\tLoss_D: 0.7424\tLoss_G: 2.6753 \tMSE_loss: 3.2624 \tTime: 0.0659\n",
      "Validation \tLoss_D: 1.1400\tLoss_G: 1.1824 \tMSE_loss: 3.9717 \tBest_loss: 3.8547\n",
      "[53/200][141/142]\tLoss_D: 0.7934\tLoss_G: 1.8601 \tMSE_loss: 2.9172 \tTime: 0.0581\n",
      "Validation \tLoss_D: 1.1681\tLoss_G: 1.0967 \tMSE_loss: 3.8696 \tBest_loss: 3.8547\n",
      "[54/200][141/142]\tLoss_D: 0.6614\tLoss_G: 1.9661 \tMSE_loss: 4.5714 \tTime: 0.0582\n",
      "Validation \tLoss_D: 1.1553\tLoss_G: 1.1115 \tMSE_loss: 3.9136 \tBest_loss: 3.8547\n",
      "[55/200][141/142]\tLoss_D: 0.7312\tLoss_G: 2.0435 \tMSE_loss: 3.8974 \tTime: 0.0609\n",
      "Validation \tLoss_D: 1.1447\tLoss_G: 1.1638 \tMSE_loss: 3.9039 \tBest_loss: 3.8547\n",
      "[56/200][141/142]\tLoss_D: 1.0598\tLoss_G: 1.5267 \tMSE_loss: 2.1268 \tTime: 0.0651\n",
      "Validation \tLoss_D: 1.1562\tLoss_G: 1.1510 \tMSE_loss: 3.9302 \tBest_loss: 3.8547\n",
      "[57/200][141/142]\tLoss_D: 0.9173\tLoss_G: 1.8100 \tMSE_loss: 6.1749 \tTime: 0.0534\n",
      "Validation \tLoss_D: 1.1838\tLoss_G: 1.1057 \tMSE_loss: 3.8974 \tBest_loss: 3.8547\n",
      "[58/200][141/142]\tLoss_D: 1.0099\tLoss_G: 1.7206 \tMSE_loss: 2.3342 \tTime: 0.0595\n",
      "Validation \tLoss_D: 1.1601\tLoss_G: 1.1321 \tMSE_loss: 3.9082 \tBest_loss: 3.8547\n",
      "[59/200][141/142]\tLoss_D: 1.0085\tLoss_G: 2.4257 \tMSE_loss: 3.3898 \tTime: 0.0649\n",
      "Validation \tLoss_D: 1.1855\tLoss_G: 1.0885 \tMSE_loss: 3.8805 \tBest_loss: 3.8547\n",
      "[60/200][141/142]\tLoss_D: 0.8617\tLoss_G: 1.8895 \tMSE_loss: 5.1643 \tTime: 0.0632\n",
      "Validation \tLoss_D: 1.1733\tLoss_G: 1.1220 \tMSE_loss: 3.9022 \tBest_loss: 3.8547\n",
      "[61/200][141/142]\tLoss_D: 0.9935\tLoss_G: 2.1416 \tMSE_loss: 3.3542 \tTime: 0.0553\n",
      "Validation \tLoss_D: 1.1891\tLoss_G: 1.0973 \tMSE_loss: 3.9190 \tBest_loss: 3.8547\n",
      "[62/200][141/142]\tLoss_D: 0.8852\tLoss_G: 1.9735 \tMSE_loss: 3.2041 \tTime: 0.0581\n",
      "Validation \tLoss_D: 1.1536\tLoss_G: 1.1484 \tMSE_loss: 3.9434 \tBest_loss: 3.8547\n",
      "[63/200][141/142]\tLoss_D: 0.8406\tLoss_G: 1.8985 \tMSE_loss: 3.9305 \tTime: 0.0657\n",
      "Validation \tLoss_D: 1.1934\tLoss_G: 1.0935 \tMSE_loss: 3.8719 \tBest_loss: 3.8547\n",
      "[64/200][141/142]\tLoss_D: 0.9461\tLoss_G: 1.8644 \tMSE_loss: 7.1275 \tTime: 0.0619\n",
      "Validation \tLoss_D: 1.2127\tLoss_G: 1.0880 \tMSE_loss: 3.9214 \tBest_loss: 3.8547\n",
      "[65/200][141/142]\tLoss_D: 0.8095\tLoss_G: 2.1342 \tMSE_loss: 4.6217 \tTime: 0.0623\n",
      "Validation \tLoss_D: 1.2365\tLoss_G: 1.0371 \tMSE_loss: 3.8465 \tBest_loss: 3.8465\n",
      "[66/200][141/142]\tLoss_D: 1.0912\tLoss_G: 1.4786 \tMSE_loss: 5.5037 \tTime: 0.0659\n",
      "Validation \tLoss_D: 1.2277\tLoss_G: 1.0598 \tMSE_loss: 3.8609 \tBest_loss: 3.8465\n",
      "[67/200][141/142]\tLoss_D: 0.7829\tLoss_G: 1.9996 \tMSE_loss: 3.7552 \tTime: 0.0598\n",
      "Validation \tLoss_D: 1.1458\tLoss_G: 1.2039 \tMSE_loss: 3.9737 \tBest_loss: 3.8465\n",
      "[68/200][141/142]\tLoss_D: 0.9765\tLoss_G: 1.9543 \tMSE_loss: 4.7232 \tTime: 0.0645\n",
      "Validation \tLoss_D: 1.1400\tLoss_G: 1.2218 \tMSE_loss: 4.0153 \tBest_loss: 3.8465\n",
      "[69/200][141/142]\tLoss_D: 0.6535\tLoss_G: 1.8952 \tMSE_loss: 5.6299 \tTime: 0.0589\n",
      "Validation \tLoss_D: 1.2393\tLoss_G: 1.0628 \tMSE_loss: 3.9026 \tBest_loss: 3.8465\n",
      "[70/200][141/142]\tLoss_D: 0.7086\tLoss_G: 2.4576 \tMSE_loss: 6.5765 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.1215\tLoss_G: 1.2346 \tMSE_loss: 3.9903 \tBest_loss: 3.8465\n",
      "[71/200][141/142]\tLoss_D: 0.7588\tLoss_G: 2.1548 \tMSE_loss: 5.2148 \tTime: 0.0547\n",
      "Validation \tLoss_D: 1.2451\tLoss_G: 1.0037 \tMSE_loss: 3.8728 \tBest_loss: 3.8465\n",
      "[72/200][141/142]\tLoss_D: 1.0367\tLoss_G: 2.3797 \tMSE_loss: 3.9554 \tTime: 0.0644\n",
      "Validation \tLoss_D: 1.2061\tLoss_G: 1.1096 \tMSE_loss: 3.9100 \tBest_loss: 3.8465\n",
      "[73/200][141/142]\tLoss_D: 0.8429\tLoss_G: 2.0034 \tMSE_loss: 3.5203 \tTime: 0.0560\n",
      "Validation \tLoss_D: 1.2564\tLoss_G: 1.0512 \tMSE_loss: 3.8816 \tBest_loss: 3.8465\n",
      "[74/200][141/142]\tLoss_D: 1.0132\tLoss_G: 2.0995 \tMSE_loss: 2.3646 \tTime: 0.0624\n",
      "Validation \tLoss_D: 1.1711\tLoss_G: 1.1960 \tMSE_loss: 3.9663 \tBest_loss: 3.8465\n",
      "[75/200][141/142]\tLoss_D: 1.0676\tLoss_G: 2.3071 \tMSE_loss: 3.3801 \tTime: 0.0620\n",
      "Validation \tLoss_D: 1.2195\tLoss_G: 1.1082 \tMSE_loss: 3.8990 \tBest_loss: 3.8465\n",
      "[76/200][141/142]\tLoss_D: 0.7695\tLoss_G: 2.1351 \tMSE_loss: 4.4421 \tTime: 0.0586\n",
      "Validation \tLoss_D: 1.2230\tLoss_G: 1.1132 \tMSE_loss: 3.9328 \tBest_loss: 3.8465\n",
      "[77/200][141/142]\tLoss_D: 0.9610\tLoss_G: 1.7550 \tMSE_loss: 5.1711 \tTime: 0.0631\n",
      "Validation \tLoss_D: 1.2517\tLoss_G: 1.0667 \tMSE_loss: 3.9077 \tBest_loss: 3.8465\n",
      "[78/200][141/142]\tLoss_D: 0.7025\tLoss_G: 1.3391 \tMSE_loss: 4.2408 \tTime: 0.0621\n",
      "Validation \tLoss_D: 1.2682\tLoss_G: 1.0504 \tMSE_loss: 3.8646 \tBest_loss: 3.8465\n",
      "[79/200][141/142]\tLoss_D: 0.9738\tLoss_G: 2.0506 \tMSE_loss: 3.3303 \tTime: 0.0538\n",
      "Validation \tLoss_D: 1.2891\tLoss_G: 1.0254 \tMSE_loss: 3.8402 \tBest_loss: 3.8402\n",
      "[80/200][141/142]\tLoss_D: 0.8790\tLoss_G: 1.9069 \tMSE_loss: 4.8351 \tTime: 0.0594\n",
      "Validation \tLoss_D: 1.2749\tLoss_G: 1.0003 \tMSE_loss: 3.9476 \tBest_loss: 3.8402\n",
      "[81/200][141/142]\tLoss_D: 1.0167\tLoss_G: 1.8029 \tMSE_loss: 4.8052 \tTime: 0.0572\n",
      "Validation \tLoss_D: 1.3408\tLoss_G: 0.9298 \tMSE_loss: 3.8525 \tBest_loss: 3.8402\n",
      "[82/200][141/142]\tLoss_D: 1.0585\tLoss_G: 2.0436 \tMSE_loss: 2.5572 \tTime: 0.0587\n",
      "Validation \tLoss_D: 1.2791\tLoss_G: 1.0053 \tMSE_loss: 3.8936 \tBest_loss: 3.8402\n",
      "[83/200][141/142]\tLoss_D: 0.7065\tLoss_G: 1.8609 \tMSE_loss: 3.5536 \tTime: 0.0511\n",
      "Validation \tLoss_D: 1.2975\tLoss_G: 1.0176 \tMSE_loss: 3.8742 \tBest_loss: 3.8402\n",
      "[84/200][141/142]\tLoss_D: 0.9613\tLoss_G: 1.9170 \tMSE_loss: 6.0580 \tTime: 0.0596\n",
      "Validation \tLoss_D: 1.2873\tLoss_G: 1.0391 \tMSE_loss: 3.8871 \tBest_loss: 3.8402\n",
      "[85/200][141/142]\tLoss_D: 0.8246\tLoss_G: 1.7072 \tMSE_loss: 3.5936 \tTime: 0.0626\n",
      "Validation \tLoss_D: 1.2995\tLoss_G: 1.0314 \tMSE_loss: 3.8668 \tBest_loss: 3.8402\n",
      "[86/200][141/142]\tLoss_D: 1.1262\tLoss_G: 2.1541 \tMSE_loss: 2.7028 \tTime: 0.0633\n",
      "Validation \tLoss_D: 1.2620\tLoss_G: 1.0885 \tMSE_loss: 3.9105 \tBest_loss: 3.8402\n",
      "[87/200][141/142]\tLoss_D: 0.8618\tLoss_G: 1.8774 \tMSE_loss: 4.5633 \tTime: 0.0576\n",
      "Validation \tLoss_D: 1.2691\tLoss_G: 1.0539 \tMSE_loss: 3.9590 \tBest_loss: 3.8402\n",
      "[88/200][141/142]\tLoss_D: 0.6419\tLoss_G: 1.9950 \tMSE_loss: 2.6432 \tTime: 0.0608\n",
      "Validation \tLoss_D: 1.3178\tLoss_G: 0.9936 \tMSE_loss: 3.8969 \tBest_loss: 3.8402\n",
      "[89/200][141/142]\tLoss_D: 0.6867\tLoss_G: 2.1205 \tMSE_loss: 4.0558 \tTime: 0.0590\n",
      "Validation \tLoss_D: 1.2921\tLoss_G: 1.0260 \tMSE_loss: 3.9038 \tBest_loss: 3.8402\n",
      "[90/200][141/142]\tLoss_D: 1.0275\tLoss_G: 1.9126 \tMSE_loss: 4.0045 \tTime: 0.0635\n",
      "Validation \tLoss_D: 1.3293\tLoss_G: 1.0023 \tMSE_loss: 3.8643 \tBest_loss: 3.8402\n",
      "[91/200][141/142]\tLoss_D: 0.8767\tLoss_G: 1.7378 \tMSE_loss: 3.6698 \tTime: 0.0586\n",
      "Validation \tLoss_D: 1.3429\tLoss_G: 0.9651 \tMSE_loss: 3.8744 \tBest_loss: 3.8402\n",
      "[92/200][141/142]\tLoss_D: 0.9229\tLoss_G: 1.6841 \tMSE_loss: 4.1187 \tTime: 0.0597\n",
      "Validation \tLoss_D: 1.3008\tLoss_G: 1.0295 \tMSE_loss: 3.8827 \tBest_loss: 3.8402\n",
      "[93/200][141/142]\tLoss_D: 0.8398\tLoss_G: 2.4200 \tMSE_loss: 3.9682 \tTime: 0.0597\n",
      "Validation \tLoss_D: 1.3616\tLoss_G: 1.0033 \tMSE_loss: 3.8527 \tBest_loss: 3.8402\n",
      "[94/200][141/142]\tLoss_D: 0.7009\tLoss_G: 2.6933 \tMSE_loss: 5.0182 \tTime: 0.0562\n",
      "Validation \tLoss_D: 1.3253\tLoss_G: 1.0301 \tMSE_loss: 3.8602 \tBest_loss: 3.8402\n",
      "[95/200][141/142]\tLoss_D: 1.1340\tLoss_G: 2.5110 \tMSE_loss: 4.1540 \tTime: 0.0603\n",
      "Validation \tLoss_D: 1.3178\tLoss_G: 1.0131 \tMSE_loss: 3.8624 \tBest_loss: 3.8402\n",
      "[96/200][141/142]\tLoss_D: 0.8436\tLoss_G: 2.1526 \tMSE_loss: 2.5781 \tTime: 0.0560\n",
      "Validation \tLoss_D: 1.3336\tLoss_G: 0.9896 \tMSE_loss: 3.8852 \tBest_loss: 3.8402\n",
      "[97/200][141/142]\tLoss_D: 0.8623\tLoss_G: 2.4640 \tMSE_loss: 5.8399 \tTime: 0.0622\n",
      "Validation \tLoss_D: 1.3035\tLoss_G: 1.0608 \tMSE_loss: 3.8922 \tBest_loss: 3.8402\n",
      "[98/200][141/142]\tLoss_D: 0.9810\tLoss_G: 1.7071 \tMSE_loss: 5.3745 \tTime: 0.0647\n",
      "Validation \tLoss_D: 1.3334\tLoss_G: 1.0034 \tMSE_loss: 3.8916 \tBest_loss: 3.8402\n",
      "[99/200][141/142]\tLoss_D: 0.9801\tLoss_G: 1.8944 \tMSE_loss: 4.4412 \tTime: 0.0634\n",
      "Validation \tLoss_D: 1.3358\tLoss_G: 0.9900 \tMSE_loss: 3.9012 \tBest_loss: 3.8402\n",
      "[100/200][141/142]\tLoss_D: 0.9722\tLoss_G: 1.7033 \tMSE_loss: 3.4304 \tTime: 0.0629\n",
      "Validation \tLoss_D: 1.3578\tLoss_G: 0.9799 \tMSE_loss: 3.8976 \tBest_loss: 3.8402\n",
      "[101/200][141/142]\tLoss_D: 0.9516\tLoss_G: 1.3390 \tMSE_loss: 4.5361 \tTime: 0.0615\n",
      "Validation \tLoss_D: 1.3306\tLoss_G: 0.9758 \tMSE_loss: 3.8841 \tBest_loss: 3.8402\n",
      "[102/200][141/142]\tLoss_D: 0.8762\tLoss_G: 2.0094 \tMSE_loss: 2.8959 \tTime: 0.0545\n",
      "Validation \tLoss_D: 1.3196\tLoss_G: 1.0005 \tMSE_loss: 3.9147 \tBest_loss: 3.8402\n",
      "[103/200][141/142]\tLoss_D: 0.9157\tLoss_G: 2.3078 \tMSE_loss: 3.4629 \tTime: 0.0632\n",
      "Validation \tLoss_D: 1.2988\tLoss_G: 1.0238 \tMSE_loss: 3.9351 \tBest_loss: 3.8402\n",
      "[104/200][141/142]\tLoss_D: 0.8513\tLoss_G: 2.3552 \tMSE_loss: 3.2005 \tTime: 0.0566\n",
      "Validation \tLoss_D: 1.3682\tLoss_G: 0.9835 \tMSE_loss: 3.9032 \tBest_loss: 3.8402\n",
      "[105/200][141/142]\tLoss_D: 0.6853\tLoss_G: 1.9348 \tMSE_loss: 3.5735 \tTime: 0.0600\n",
      "Validation \tLoss_D: 1.3308\tLoss_G: 1.0141 \tMSE_loss: 3.9080 \tBest_loss: 3.8402\n",
      "[106/200][141/142]\tLoss_D: 0.7885\tLoss_G: 1.9792 \tMSE_loss: 4.1695 \tTime: 0.0534\n",
      "Validation \tLoss_D: 1.2944\tLoss_G: 1.0670 \tMSE_loss: 3.9560 \tBest_loss: 3.8402\n",
      "[107/200][141/142]\tLoss_D: 0.9836\tLoss_G: 1.2213 \tMSE_loss: 2.7498 \tTime: 0.0512\n",
      "Validation \tLoss_D: 1.3809\tLoss_G: 0.9590 \tMSE_loss: 3.8656 \tBest_loss: 3.8402\n",
      "[108/200][141/142]\tLoss_D: 1.0051\tLoss_G: 1.5501 \tMSE_loss: 3.7951 \tTime: 0.0597\n",
      "Validation \tLoss_D: 1.3595\tLoss_G: 1.0219 \tMSE_loss: 3.8622 \tBest_loss: 3.8402\n",
      "[109/200][141/142]\tLoss_D: 1.0502\tLoss_G: 2.1291 \tMSE_loss: 3.4579 \tTime: 0.0702\n",
      "Validation \tLoss_D: 1.3564\tLoss_G: 0.9831 \tMSE_loss: 3.8917 \tBest_loss: 3.8402\n",
      "[110/200][141/142]\tLoss_D: 0.8261\tLoss_G: 2.4407 \tMSE_loss: 3.9310 \tTime: 0.0648\n",
      "Validation \tLoss_D: 1.3958\tLoss_G: 0.9681 \tMSE_loss: 3.8563 \tBest_loss: 3.8402\n",
      "[111/200][141/142]\tLoss_D: 0.9306\tLoss_G: 2.1963 \tMSE_loss: 3.6539 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.4083\tLoss_G: 0.9497 \tMSE_loss: 3.8623 \tBest_loss: 3.8402\n",
      "[112/200][141/142]\tLoss_D: 1.0460\tLoss_G: 2.4754 \tMSE_loss: 3.3490 \tTime: 0.0588\n",
      "Validation \tLoss_D: 1.3949\tLoss_G: 0.9678 \tMSE_loss: 3.8481 \tBest_loss: 3.8402\n",
      "[113/200][141/142]\tLoss_D: 0.8410\tLoss_G: 2.5248 \tMSE_loss: 6.6014 \tTime: 0.0585\n",
      "Validation \tLoss_D: 1.3722\tLoss_G: 0.9773 \tMSE_loss: 3.8778 \tBest_loss: 3.8402\n",
      "[114/200][141/142]\tLoss_D: 0.8280\tLoss_G: 1.5712 \tMSE_loss: 5.5076 \tTime: 0.0586\n",
      "Validation \tLoss_D: 1.3928\tLoss_G: 0.9448 \tMSE_loss: 3.8947 \tBest_loss: 3.8402\n",
      "[115/200][141/142]\tLoss_D: 0.9102\tLoss_G: 2.0883 \tMSE_loss: 5.4449 \tTime: 0.0563\n",
      "Validation \tLoss_D: 1.3569\tLoss_G: 0.9756 \tMSE_loss: 3.9477 \tBest_loss: 3.8402\n",
      "[116/200][141/142]\tLoss_D: 0.9010\tLoss_G: 2.0461 \tMSE_loss: 3.9463 \tTime: 0.0653\n",
      "Validation \tLoss_D: 1.3891\tLoss_G: 0.9855 \tMSE_loss: 3.8736 \tBest_loss: 3.8402\n",
      "[117/200][141/142]\tLoss_D: 0.9413\tLoss_G: 2.2677 \tMSE_loss: 3.4003 \tTime: 0.0610\n",
      "Validation \tLoss_D: 1.4042\tLoss_G: 0.9584 \tMSE_loss: 3.8650 \tBest_loss: 3.8402\n",
      "[118/200][141/142]\tLoss_D: 0.6708\tLoss_G: 1.7559 \tMSE_loss: 5.6468 \tTime: 0.0640\n",
      "Validation \tLoss_D: 1.4198\tLoss_G: 0.9793 \tMSE_loss: 3.8447 \tBest_loss: 3.8402\n",
      "[119/200][141/142]\tLoss_D: 0.9129\tLoss_G: 2.4615 \tMSE_loss: 3.3093 \tTime: 0.0599\n",
      "Validation \tLoss_D: 1.4016\tLoss_G: 0.9263 \tMSE_loss: 3.9233 \tBest_loss: 3.8402\n",
      "[120/200][141/142]\tLoss_D: 0.9946\tLoss_G: 1.9586 \tMSE_loss: 4.0108 \tTime: 0.0541\n",
      "Validation \tLoss_D: 1.4267\tLoss_G: 0.9379 \tMSE_loss: 3.8619 \tBest_loss: 3.8402\n",
      "[121/200][141/142]\tLoss_D: 0.6228\tLoss_G: 1.7167 \tMSE_loss: 3.6147 \tTime: 0.0626\n",
      "Validation \tLoss_D: 1.4237\tLoss_G: 0.9465 \tMSE_loss: 3.8501 \tBest_loss: 3.8402\n",
      "[122/200][141/142]\tLoss_D: 0.7304\tLoss_G: 2.6903 \tMSE_loss: 5.7744 \tTime: 0.0626\n",
      "Validation \tLoss_D: 1.4337\tLoss_G: 0.9227 \tMSE_loss: 3.8813 \tBest_loss: 3.8402\n",
      "[123/200][141/142]\tLoss_D: 0.9744\tLoss_G: 1.9251 \tMSE_loss: 4.0790 \tTime: 0.0596\n",
      "Validation \tLoss_D: 1.4556\tLoss_G: 0.9204 \tMSE_loss: 3.8679 \tBest_loss: 3.8402\n",
      "[124/200][141/142]\tLoss_D: 0.8532\tLoss_G: 2.1647 \tMSE_loss: 2.8727 \tTime: 0.0577\n",
      "Validation \tLoss_D: 1.4843\tLoss_G: 0.9338 \tMSE_loss: 3.8470 \tBest_loss: 3.8402\n",
      "[125/200][141/142]\tLoss_D: 1.0005\tLoss_G: 2.0952 \tMSE_loss: 3.5348 \tTime: 0.0650\n",
      "Validation \tLoss_D: 1.4478\tLoss_G: 0.9157 \tMSE_loss: 3.8670 \tBest_loss: 3.8402\n",
      "[126/200][141/142]\tLoss_D: 0.8467\tLoss_G: 2.0165 \tMSE_loss: 3.5392 \tTime: 0.0603\n",
      "Validation \tLoss_D: 1.4351\tLoss_G: 0.9545 \tMSE_loss: 3.9037 \tBest_loss: 3.8402\n",
      "[127/200][141/142]\tLoss_D: 0.8004\tLoss_G: 1.9817 \tMSE_loss: 4.5970 \tTime: 0.0558\n",
      "Validation \tLoss_D: 1.4429\tLoss_G: 0.9522 \tMSE_loss: 3.8645 \tBest_loss: 3.8402\n",
      "[128/200][141/142]\tLoss_D: 0.6944\tLoss_G: 2.4536 \tMSE_loss: 5.0864 \tTime: 0.0609\n",
      "Validation \tLoss_D: 1.4302\tLoss_G: 0.9407 \tMSE_loss: 3.9176 \tBest_loss: 3.8402\n",
      "[129/200][141/142]\tLoss_D: 0.7954\tLoss_G: 2.3418 \tMSE_loss: 2.5561 \tTime: 0.0582\n",
      "Validation \tLoss_D: 1.4442\tLoss_G: 0.9237 \tMSE_loss: 3.8668 \tBest_loss: 3.8402\n",
      "[130/200][141/142]\tLoss_D: 0.8593\tLoss_G: 2.2571 \tMSE_loss: 4.2240 \tTime: 0.0546\n",
      "Validation \tLoss_D: 1.4136\tLoss_G: 0.9742 \tMSE_loss: 3.9053 \tBest_loss: 3.8402\n",
      "[131/200][141/142]\tLoss_D: 1.0903\tLoss_G: 2.2017 \tMSE_loss: 3.0793 \tTime: 0.0577\n",
      "Validation \tLoss_D: 1.4846\tLoss_G: 0.9191 \tMSE_loss: 3.8716 \tBest_loss: 3.8402\n",
      "[132/200][141/142]\tLoss_D: 0.9194\tLoss_G: 1.7672 \tMSE_loss: 4.7838 \tTime: 0.0674\n",
      "Validation \tLoss_D: 1.4941\tLoss_G: 0.8884 \tMSE_loss: 3.8586 \tBest_loss: 3.8402\n",
      "[133/200][141/142]\tLoss_D: 0.8197\tLoss_G: 1.8948 \tMSE_loss: 3.0638 \tTime: 0.0603\n",
      "Validation \tLoss_D: 1.5083\tLoss_G: 0.8954 \tMSE_loss: 3.8250 \tBest_loss: 3.8250\n",
      "[134/200][141/142]\tLoss_D: 1.1088\tLoss_G: 2.0463 \tMSE_loss: 3.7750 \tTime: 0.0597\n",
      "Validation \tLoss_D: 1.4297\tLoss_G: 0.9914 \tMSE_loss: 3.8938 \tBest_loss: 3.8250\n",
      "[135/200][141/142]\tLoss_D: 0.8803\tLoss_G: 2.4356 \tMSE_loss: 3.5046 \tTime: 0.0568\n",
      "Validation \tLoss_D: 1.4803\tLoss_G: 0.9432 \tMSE_loss: 3.8451 \tBest_loss: 3.8250\n",
      "[136/200][141/142]\tLoss_D: 0.7139\tLoss_G: 2.3657 \tMSE_loss: 4.3058 \tTime: 0.0619\n",
      "Validation \tLoss_D: 1.4568\tLoss_G: 0.9443 \tMSE_loss: 3.8706 \tBest_loss: 3.8250\n",
      "[137/200][141/142]\tLoss_D: 0.7349\tLoss_G: 1.9164 \tMSE_loss: 4.7640 \tTime: 0.0552\n",
      "Validation \tLoss_D: 1.4513\tLoss_G: 0.9450 \tMSE_loss: 3.8669 \tBest_loss: 3.8250\n",
      "[138/200][141/142]\tLoss_D: 0.8668\tLoss_G: 2.6344 \tMSE_loss: 4.4193 \tTime: 0.0625\n",
      "Validation \tLoss_D: 1.4380\tLoss_G: 0.9674 \tMSE_loss: 3.9121 \tBest_loss: 3.8250\n",
      "[139/200][141/142]\tLoss_D: 0.7236\tLoss_G: 2.0562 \tMSE_loss: 4.1171 \tTime: 0.0601\n",
      "Validation \tLoss_D: 1.4751\tLoss_G: 0.9388 \tMSE_loss: 3.8442 \tBest_loss: 3.8250\n",
      "[140/200][141/142]\tLoss_D: 1.0096\tLoss_G: 2.7362 \tMSE_loss: 3.3741 \tTime: 0.0679\n",
      "Validation \tLoss_D: 1.5166\tLoss_G: 0.8924 \tMSE_loss: 3.8488 \tBest_loss: 3.8250\n",
      "[141/200][141/142]\tLoss_D: 0.7486\tLoss_G: 2.0794 \tMSE_loss: 3.0016 \tTime: 0.0593\n",
      "Validation \tLoss_D: 1.4381\tLoss_G: 0.9625 \tMSE_loss: 3.9129 \tBest_loss: 3.8250\n",
      "[142/200][141/142]\tLoss_D: 0.9264\tLoss_G: 2.0886 \tMSE_loss: 3.5009 \tTime: 0.0626\n",
      "Validation \tLoss_D: 1.4814\tLoss_G: 0.9315 \tMSE_loss: 3.8734 \tBest_loss: 3.8250\n",
      "[143/200][141/142]\tLoss_D: 0.9574\tLoss_G: 2.4497 \tMSE_loss: 6.8473 \tTime: 0.0580\n",
      "Validation \tLoss_D: 1.4566\tLoss_G: 0.9567 \tMSE_loss: 3.9018 \tBest_loss: 3.8250\n",
      "[144/200][141/142]\tLoss_D: 0.9443\tLoss_G: 2.8575 \tMSE_loss: 4.4105 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.4363\tLoss_G: 0.9687 \tMSE_loss: 3.8963 \tBest_loss: 3.8250\n",
      "[145/200][141/142]\tLoss_D: 1.1361\tLoss_G: 2.9554 \tMSE_loss: 4.8813 \tTime: 0.0637\n",
      "Validation \tLoss_D: 1.4912\tLoss_G: 0.9538 \tMSE_loss: 3.8599 \tBest_loss: 3.8250\n",
      "[146/200][141/142]\tLoss_D: 0.8426\tLoss_G: 2.2523 \tMSE_loss: 7.0341 \tTime: 0.0598\n",
      "Validation \tLoss_D: 1.4686\tLoss_G: 0.9407 \tMSE_loss: 3.8949 \tBest_loss: 3.8250\n",
      "[147/200][141/142]\tLoss_D: 0.6713\tLoss_G: 1.7447 \tMSE_loss: 4.1153 \tTime: 0.0643\n",
      "Validation \tLoss_D: 1.4454\tLoss_G: 0.9808 \tMSE_loss: 3.9251 \tBest_loss: 3.8250\n",
      "[148/200][141/142]\tLoss_D: 0.8327\tLoss_G: 2.3511 \tMSE_loss: 4.6467 \tTime: 0.0605\n",
      "Validation \tLoss_D: 1.5519\tLoss_G: 0.8726 \tMSE_loss: 3.8714 \tBest_loss: 3.8250\n",
      "[149/200][141/142]\tLoss_D: 0.9221\tLoss_G: 2.1106 \tMSE_loss: 7.1704 \tTime: 0.0586\n",
      "Validation \tLoss_D: 1.4113\tLoss_G: 1.0209 \tMSE_loss: 3.9635 \tBest_loss: 3.8250\n",
      "[150/200][141/142]\tLoss_D: 0.9414\tLoss_G: 2.7739 \tMSE_loss: 4.9830 \tTime: 0.0611\n",
      "Validation \tLoss_D: 1.5416\tLoss_G: 0.9360 \tMSE_loss: 3.8427 \tBest_loss: 3.8250\n",
      "[151/200][141/142]\tLoss_D: 0.8522\tLoss_G: 1.9581 \tMSE_loss: 2.0833 \tTime: 0.0604\n",
      "Validation \tLoss_D: 1.4531\tLoss_G: 0.9834 \tMSE_loss: 3.8855 \tBest_loss: 3.8250\n",
      "[152/200][141/142]\tLoss_D: 0.8441\tLoss_G: 2.2134 \tMSE_loss: 4.1324 \tTime: 0.0610\n",
      "Validation \tLoss_D: 1.4996\tLoss_G: 0.9677 \tMSE_loss: 3.8641 \tBest_loss: 3.8250\n",
      "[153/200][141/142]\tLoss_D: 0.4945\tLoss_G: 1.8750 \tMSE_loss: 3.3107 \tTime: 0.0605\n",
      "Validation \tLoss_D: 1.4815\tLoss_G: 0.9452 \tMSE_loss: 3.8826 \tBest_loss: 3.8250\n",
      "[154/200][141/142]\tLoss_D: 0.8976\tLoss_G: 1.9809 \tMSE_loss: 4.0541 \tTime: 0.0540\n",
      "Validation \tLoss_D: 1.5359\tLoss_G: 0.8898 \tMSE_loss: 3.8727 \tBest_loss: 3.8250\n",
      "[155/200][141/142]\tLoss_D: 0.9747\tLoss_G: 2.1530 \tMSE_loss: 5.0238 \tTime: 0.0654\n",
      "Validation \tLoss_D: 1.5194\tLoss_G: 0.9150 \tMSE_loss: 3.8547 \tBest_loss: 3.8250\n",
      "[156/200][141/142]\tLoss_D: 0.6593\tLoss_G: 2.3868 \tMSE_loss: 3.8291 \tTime: 0.0633\n",
      "Validation \tLoss_D: 1.4838\tLoss_G: 0.9748 \tMSE_loss: 3.8699 \tBest_loss: 3.8250\n",
      "[157/200][141/142]\tLoss_D: 0.9001\tLoss_G: 2.6062 \tMSE_loss: 4.0181 \tTime: 0.0575\n",
      "Validation \tLoss_D: 1.5548\tLoss_G: 0.9054 \tMSE_loss: 3.8932 \tBest_loss: 3.8250\n",
      "[158/200][141/142]\tLoss_D: 0.8155\tLoss_G: 2.4572 \tMSE_loss: 3.5542 \tTime: 0.0596\n",
      "Validation \tLoss_D: 1.5520\tLoss_G: 0.9481 \tMSE_loss: 3.8531 \tBest_loss: 3.8250\n",
      "[159/200][141/142]\tLoss_D: 0.7860\tLoss_G: 2.5833 \tMSE_loss: 7.4863 \tTime: 0.0603\n",
      "Validation \tLoss_D: 1.4562\tLoss_G: 0.9964 \tMSE_loss: 3.9245 \tBest_loss: 3.8250\n",
      "[160/200][141/142]\tLoss_D: 0.7385\tLoss_G: 2.1830 \tMSE_loss: 3.9550 \tTime: 0.0605\n",
      "Validation \tLoss_D: 1.5282\tLoss_G: 0.9115 \tMSE_loss: 3.8856 \tBest_loss: 3.8250\n",
      "[161/200][141/142]\tLoss_D: 0.9533\tLoss_G: 2.8833 \tMSE_loss: 4.0172 \tTime: 0.0649\n",
      "Validation \tLoss_D: 1.5363\tLoss_G: 0.9632 \tMSE_loss: 3.8407 \tBest_loss: 3.8250\n",
      "[162/200][141/142]\tLoss_D: 0.7071\tLoss_G: 2.0711 \tMSE_loss: 4.1950 \tTime: 0.0631\n",
      "Validation \tLoss_D: 1.4851\tLoss_G: 1.0010 \tMSE_loss: 3.9150 \tBest_loss: 3.8250\n",
      "[163/200][141/142]\tLoss_D: 0.7833\tLoss_G: 2.1595 \tMSE_loss: 3.8578 \tTime: 0.0598\n",
      "Validation \tLoss_D: 1.5453\tLoss_G: 0.9425 \tMSE_loss: 3.8629 \tBest_loss: 3.8250\n",
      "[164/200][141/142]\tLoss_D: 0.9096\tLoss_G: 2.5703 \tMSE_loss: 3.4258 \tTime: 0.0630\n",
      "Validation \tLoss_D: 1.5165\tLoss_G: 0.9794 \tMSE_loss: 3.8769 \tBest_loss: 3.8250\n",
      "[165/200][141/142]\tLoss_D: 0.8785\tLoss_G: 2.2049 \tMSE_loss: 4.5316 \tTime: 0.0565\n",
      "Validation \tLoss_D: 1.5852\tLoss_G: 0.9013 \tMSE_loss: 3.8545 \tBest_loss: 3.8250\n",
      "[166/200][141/142]\tLoss_D: 0.9286\tLoss_G: 2.3150 \tMSE_loss: 5.1303 \tTime: 0.0543\n",
      "Validation \tLoss_D: 1.5890\tLoss_G: 0.9259 \tMSE_loss: 3.8332 \tBest_loss: 3.8250\n",
      "[167/200][141/142]\tLoss_D: 0.9541\tLoss_G: 2.2533 \tMSE_loss: 4.6140 \tTime: 0.0678\n",
      "Validation \tLoss_D: 1.5549\tLoss_G: 0.9267 \tMSE_loss: 3.8787 \tBest_loss: 3.8250\n",
      "[168/200][141/142]\tLoss_D: 0.7610\tLoss_G: 2.6208 \tMSE_loss: 8.1449 \tTime: 0.0549\n",
      "Validation \tLoss_D: 1.4722\tLoss_G: 1.0182 \tMSE_loss: 3.9229 \tBest_loss: 3.8250\n",
      "[169/200][141/142]\tLoss_D: 0.9579\tLoss_G: 2.2700 \tMSE_loss: 3.2258 \tTime: 0.0575\n",
      "Validation \tLoss_D: 1.5646\tLoss_G: 0.9253 \tMSE_loss: 3.8394 \tBest_loss: 3.8250\n",
      "[170/200][141/142]\tLoss_D: 1.2202\tLoss_G: 1.6824 \tMSE_loss: 5.0659 \tTime: 0.0598\n",
      "Validation \tLoss_D: 1.5585\tLoss_G: 0.9108 \tMSE_loss: 3.9178 \tBest_loss: 3.8250\n",
      "[171/200][141/142]\tLoss_D: 0.7224\tLoss_G: 2.4617 \tMSE_loss: 4.5450 \tTime: 0.0562\n",
      "Validation \tLoss_D: 1.4667\tLoss_G: 1.0120 \tMSE_loss: 3.9475 \tBest_loss: 3.8250\n",
      "[172/200][141/142]\tLoss_D: 0.7609\tLoss_G: 3.2175 \tMSE_loss: 5.3239 \tTime: 0.0604\n",
      "Validation \tLoss_D: 1.6183\tLoss_G: 0.9342 \tMSE_loss: 3.8281 \tBest_loss: 3.8250\n",
      "[173/200][141/142]\tLoss_D: 1.0986\tLoss_G: 2.3169 \tMSE_loss: 4.1232 \tTime: 0.0645\n",
      "Validation \tLoss_D: 1.5670\tLoss_G: 0.9666 \tMSE_loss: 3.8941 \tBest_loss: 3.8250\n",
      "[174/200][141/142]\tLoss_D: 0.7597\tLoss_G: 2.3156 \tMSE_loss: 4.7995 \tTime: 0.0637\n",
      "Validation \tLoss_D: 1.5773\tLoss_G: 0.9143 \tMSE_loss: 3.8881 \tBest_loss: 3.8250\n",
      "[175/200][141/142]\tLoss_D: 0.6445\tLoss_G: 2.4356 \tMSE_loss: 5.8988 \tTime: 0.0600\n",
      "Validation \tLoss_D: 1.5725\tLoss_G: 0.9564 \tMSE_loss: 3.8901 \tBest_loss: 3.8250\n",
      "[176/200][141/142]\tLoss_D: 0.7117\tLoss_G: 2.1115 \tMSE_loss: 3.6177 \tTime: 0.0557\n",
      "Validation \tLoss_D: 1.5454\tLoss_G: 1.0170 \tMSE_loss: 3.8726 \tBest_loss: 3.8250\n",
      "[177/200][141/142]\tLoss_D: 0.7930\tLoss_G: 1.9901 \tMSE_loss: 2.7662 \tTime: 0.0693\n",
      "Validation \tLoss_D: 1.5654\tLoss_G: 0.9572 \tMSE_loss: 3.8850 \tBest_loss: 3.8250\n",
      "[178/200][141/142]\tLoss_D: 0.5536\tLoss_G: 2.4524 \tMSE_loss: 3.8811 \tTime: 0.0626\n",
      "Validation \tLoss_D: 1.4858\tLoss_G: 1.0387 \tMSE_loss: 3.9800 \tBest_loss: 3.8250\n",
      "[179/200][141/142]\tLoss_D: 0.6753\tLoss_G: 2.4349 \tMSE_loss: 3.2400 \tTime: 0.0603\n",
      "Validation \tLoss_D: 1.5909\tLoss_G: 0.9634 \tMSE_loss: 3.8390 \tBest_loss: 3.8250\n",
      "[180/200][141/142]\tLoss_D: 0.8477\tLoss_G: 2.5670 \tMSE_loss: 2.1673 \tTime: 0.0636\n",
      "Validation \tLoss_D: 1.5936\tLoss_G: 0.9626 \tMSE_loss: 3.8482 \tBest_loss: 3.8250\n",
      "[181/200][141/142]\tLoss_D: 0.8500\tLoss_G: 2.3820 \tMSE_loss: 3.2053 \tTime: 0.0632\n",
      "Validation \tLoss_D: 1.6639\tLoss_G: 0.8744 \tMSE_loss: 3.8187 \tBest_loss: 3.8187\n",
      "[182/200][141/142]\tLoss_D: 0.6638\tLoss_G: 2.5105 \tMSE_loss: 3.2417 \tTime: 0.0618\n",
      "Validation \tLoss_D: 1.6465\tLoss_G: 0.9067 \tMSE_loss: 3.8282 \tBest_loss: 3.8187\n",
      "[183/200][141/142]\tLoss_D: 0.8599\tLoss_G: 2.5635 \tMSE_loss: 4.1492 \tTime: 0.0527\n",
      "Validation \tLoss_D: 1.6270\tLoss_G: 0.9093 \tMSE_loss: 3.8506 \tBest_loss: 3.8187\n",
      "[184/200][141/142]\tLoss_D: 0.8068\tLoss_G: 2.3065 \tMSE_loss: 4.4779 \tTime: 0.0594\n",
      "Validation \tLoss_D: 1.6569\tLoss_G: 0.9007 \tMSE_loss: 3.8432 \tBest_loss: 3.8187\n",
      "[185/200][141/142]\tLoss_D: 0.8058\tLoss_G: 1.8588 \tMSE_loss: 3.7023 \tTime: 0.0588\n",
      "Validation \tLoss_D: 1.5766\tLoss_G: 0.9577 \tMSE_loss: 3.8709 \tBest_loss: 3.8187\n",
      "[186/200][141/142]\tLoss_D: 0.9183\tLoss_G: 2.3441 \tMSE_loss: 5.1394 \tTime: 0.0524\n",
      "Validation \tLoss_D: 1.6481\tLoss_G: 0.9027 \tMSE_loss: 3.8485 \tBest_loss: 3.8187\n",
      "[187/200][141/142]\tLoss_D: 0.9521\tLoss_G: 2.5695 \tMSE_loss: 3.3719 \tTime: 0.0588\n",
      "Validation \tLoss_D: 1.6001\tLoss_G: 0.9366 \tMSE_loss: 3.8706 \tBest_loss: 3.8187\n",
      "[188/200][141/142]\tLoss_D: 0.7446\tLoss_G: 2.6623 \tMSE_loss: 3.2253 \tTime: 0.0624\n",
      "Validation \tLoss_D: 1.6851\tLoss_G: 0.8722 \tMSE_loss: 3.8456 \tBest_loss: 3.8187\n",
      "[189/200][141/142]\tLoss_D: 0.7436\tLoss_G: 2.4077 \tMSE_loss: 4.8311 \tTime: 0.0623\n",
      "Validation \tLoss_D: 1.6720\tLoss_G: 0.8838 \tMSE_loss: 3.8421 \tBest_loss: 3.8187\n",
      "[190/200][141/142]\tLoss_D: 0.9220\tLoss_G: 2.8005 \tMSE_loss: 4.1499 \tTime: 0.0580\n",
      "Validation \tLoss_D: 1.6786\tLoss_G: 0.9035 \tMSE_loss: 3.8290 \tBest_loss: 3.8187\n",
      "[191/200][141/142]\tLoss_D: 0.6505\tLoss_G: 2.8956 \tMSE_loss: 5.5328 \tTime: 0.0714\n",
      "Validation \tLoss_D: 1.5852\tLoss_G: 1.0300 \tMSE_loss: 3.8557 \tBest_loss: 3.8187\n",
      "[192/200][141/142]\tLoss_D: 0.7314\tLoss_G: 2.4415 \tMSE_loss: 4.3610 \tTime: 0.0606\n",
      "Validation \tLoss_D: 1.6633\tLoss_G: 0.9149 \tMSE_loss: 3.8666 \tBest_loss: 3.8187\n",
      "[193/200][141/142]\tLoss_D: 0.8330\tLoss_G: 2.7015 \tMSE_loss: 4.0031 \tTime: 0.0608\n",
      "Validation \tLoss_D: 1.6339\tLoss_G: 0.9489 \tMSE_loss: 3.8445 \tBest_loss: 3.8187\n",
      "[194/200][141/142]\tLoss_D: 0.8087\tLoss_G: 2.0282 \tMSE_loss: 7.8967 \tTime: 0.0587\n",
      "Validation \tLoss_D: 1.6803\tLoss_G: 0.9335 \tMSE_loss: 3.8552 \tBest_loss: 3.8187\n",
      "[195/200][141/142]\tLoss_D: 0.7943\tLoss_G: 2.6976 \tMSE_loss: 4.2381 \tTime: 0.0610\n",
      "Validation \tLoss_D: 1.6362\tLoss_G: 0.9286 \tMSE_loss: 3.8890 \tBest_loss: 3.8187\n",
      "[196/200][141/142]\tLoss_D: 0.7133\tLoss_G: 2.8174 \tMSE_loss: 5.6853 \tTime: 0.0543\n",
      "Validation \tLoss_D: 1.6664\tLoss_G: 0.9236 \tMSE_loss: 3.8350 \tBest_loss: 3.8187\n",
      "[197/200][141/142]\tLoss_D: 0.7308\tLoss_G: 1.9107 \tMSE_loss: 3.5556 \tTime: 0.0619\n",
      "Validation \tLoss_D: 1.6744\tLoss_G: 0.9138 \tMSE_loss: 3.8520 \tBest_loss: 3.8187\n",
      "[198/200][141/142]\tLoss_D: 0.9145\tLoss_G: 2.4731 \tMSE_loss: 5.7974 \tTime: 0.0659\n",
      "Validation \tLoss_D: 1.6839\tLoss_G: 0.9185 \tMSE_loss: 3.8565 \tBest_loss: 3.8187\n",
      "[199/200][141/142]\tLoss_D: 0.6159\tLoss_G: 2.5313 \tMSE_loss: 3.1246 \tTime: 0.0599\n",
      "Validation \tLoss_D: 1.7313\tLoss_G: 0.8446 \tMSE_loss: 3.8617 \tBest_loss: 3.8187\n"
     ]
    }
   ],
   "source": [
    "result = train_GAN(generator, discriminator, generator_optimizer, discriminator_optimizer, loss_fn, data_gen_train, data_gen_test, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027eb7a-ea17-436d-b680-09d4ff31df05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
