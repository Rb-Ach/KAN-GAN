{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9715a90-f39c-4964-9193-5ee44431250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import kan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77d11873-35d1-466e-af7e-424c5607439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/S&P500.csv\n",
      "shape =  (5031, 7)\n"
     ]
    }
   ],
   "source": [
    "data_names = [\"S&P500\",\"SSE\",\"IBM\",\"MSFT\",\"PAICC\"]\n",
    "data_name = data_names[0]\n",
    "data_path=\"./datasets/S&P500.csv\"\n",
    "print(data_path)\n",
    "dataframe = pd.read_csv(data_path)\n",
    "dataframe.describe()\n",
    "print(\"shape = \",dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a805dde-5d75-41f4-8fe8-8796e074b81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999-01-11</td>\n",
       "      <td>1275.089966</td>\n",
       "      <td>1276.219971</td>\n",
       "      <td>1253.339966</td>\n",
       "      <td>1263.880005</td>\n",
       "      <td>1263.880005</td>\n",
       "      <td>818000000</td>\n",
       "      <td>1258.007983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1999-01-12</td>\n",
       "      <td>1263.880005</td>\n",
       "      <td>1264.449951</td>\n",
       "      <td>1238.290039</td>\n",
       "      <td>1239.510010</td>\n",
       "      <td>1239.510010</td>\n",
       "      <td>800200000</td>\n",
       "      <td>1265.163989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1999-01-13</td>\n",
       "      <td>1239.510010</td>\n",
       "      <td>1247.750000</td>\n",
       "      <td>1205.459961</td>\n",
       "      <td>1234.400024</td>\n",
       "      <td>1234.400024</td>\n",
       "      <td>931500000</td>\n",
       "      <td>1264.109985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1999-01-14</td>\n",
       "      <td>1234.400024</td>\n",
       "      <td>1236.810059</td>\n",
       "      <td>1209.540039</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>797200000</td>\n",
       "      <td>1256.521997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1999-01-15</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>1243.260010</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>1243.260010</td>\n",
       "      <td>1243.260010</td>\n",
       "      <td>798100000</td>\n",
       "      <td>1245.013989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         Open         High          Low        Close  \\\n",
       "5  1999-01-11  1275.089966  1276.219971  1253.339966  1263.880005   \n",
       "6  1999-01-12  1263.880005  1264.449951  1238.290039  1239.510010   \n",
       "7  1999-01-13  1239.510010  1247.750000  1205.459961  1234.400024   \n",
       "8  1999-01-14  1234.400024  1236.810059  1209.540039  1212.189941   \n",
       "9  1999-01-15  1212.189941  1243.260010  1212.189941  1243.260010   \n",
       "\n",
       "     Adj Close     Volume           Ma  \n",
       "5  1263.880005  818000000  1258.007983  \n",
       "6  1239.510010  800200000  1265.163989  \n",
       "7  1234.400024  931500000  1264.109985  \n",
       "8  1212.189941  797200000  1256.521997  \n",
       "9  1243.260010  798100000  1245.013989  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_Ma(dataframe):\n",
    "  Ma_window=5\n",
    "  for i in range(0,dataframe.shape[0]-Ma_window):\n",
    "    dataframe.loc[dataframe.index[i+Ma_window],'Ma'] = np.round(((dataframe.iloc[i,4]+ dataframe.iloc[i+1,4] +dataframe.iloc[i+2,4] + dataframe.iloc[i+3,4]+ dataframe.iloc[i+4,4])/5),6)\n",
    "  return dataframe[5:-5]\n",
    "\n",
    "dataframe=add_Ma(dataframe)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7331a555-0b19-4c1e-8b75-f2323f80746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class GeneratorModel(nn.Module):\n",
    "    def __init__(self, n_sequence, n_features):\n",
    "        super(GeneratorModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=n_features, hidden_size=10, batch_first=True)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(10)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.3)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(input_size=10, hidden_size=10, batch_first=True)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(10)  \n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.output_dense = nn.Linear(10, n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.batch_norm1(x.permute(0, 2, 1)).permute(0, 2, 1) \n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        _, (x, _) = self.lstm2(x)\n",
    "        x=x.permute(1, 0, 2)\n",
    "        x = self.batch_norm2(x.permute(0, 2, 1)).permute(0, 2, 1)  \n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.output_dense(x)\n",
    "        x = self.leaky_relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "n_sequence = 5  # Sequence length\n",
    "n_features = 7   # Number of features\n",
    "\n",
    "\n",
    "class KAN_discriminator(torch.nn.Module):\n",
    "    def __init__(self, n_sequence, n_features):\n",
    "        super(KAN_discriminator, self).__init__()\n",
    "        input_dim = (n_sequence + 1) * n_features\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            kan.KAN([42,64,10,1]),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "530f7259-5fdf-4575-ae9f-374cb66617e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=8)\n",
    "class Standarized_TimeseriesGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets, length, batch_size=1, stride=1):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.length = length\n",
    "        self.batch_size = batch_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        samples = [self.data[i:i+self.length] for i in range(index, len(self.data)-self.length, self.stride)]\n",
    "        targets = [self.targets[i+self.length] for i in range(index, len(self.data)-self.length, self.stride)]\n",
    "        # Pack sequences into tensor\n",
    "        samples = torch.tensor(samples[0])\n",
    "        targets = torch.tensor(targets[0])\n",
    "        samples= samples.to(torch.float64)\n",
    "        targets= targets.to(torch.float64)\n",
    "        # shape : (n_batch, n_sequence, n_features)\n",
    "        mean = samples.mean(dim=0)\n",
    "        std = samples.std(dim=0,correction=0)\n",
    "        samples = (samples - mean)/std  # standardize along each feature\n",
    "\n",
    "\n",
    "        # targets = (targets - mean[..., 3])/std[..., 3]  # The close value is our target\n",
    "        targets = (targets - mean)/std  # The close value is our target\n",
    "        return samples, targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b687e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sequence = 5\n",
    "n_features = 7\n",
    "n_batch = 32\n",
    "\n",
    "def get_gen_train_test(dataframe):\n",
    "  data = dataframe.drop(columns='Date').to_numpy()\n",
    "  #targets = data[:,3, None] #add none to have same number of dimensions as data\n",
    "  targets = data\n",
    "  n_samples = data.shape[0]\n",
    "  train_test_split=int(n_samples*0.9)\n",
    "  train_data = data[:train_test_split]\n",
    "  test_data = data[train_test_split:]\n",
    "  train_target = targets[:train_test_split]\n",
    "  test_target = targets[train_test_split:]\n",
    "  data_train = Standarized_TimeseriesGenerator(train_data, train_target,\n",
    "                                length=n_sequence, \n",
    "                                stride=1)\n",
    "  data_test = Standarized_TimeseriesGenerator(test_data, test_target,\n",
    "                                length=n_sequence, \n",
    "                                stride=1)\n",
    "  \n",
    "  train_loader = DataLoader(data_train, batch_size=n_batch, shuffle=True)\n",
    "  test_loader = DataLoader(data_test, batch_size=n_batch, shuffle=False)\n",
    "  return train_loader, test_loader\n",
    "\n",
    "data_gen_train, data_gen_test = get_gen_train_test(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2ab17e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 64\n",
      "64 10\n",
      "finished\n",
      "[0/200][141/142]\tLoss_D: 1.3993\tLoss_G: 0.7698 \tMSE_loss: 5.9770 \tTime: 0.0556\n",
      "Validation \tLoss_D: 1.3698\tLoss_G: 0.7590 \tMSE_loss: 5.5409 \tBest_loss: 5.5409\n",
      "[1/200][141/142]\tLoss_D: 1.3666\tLoss_G: 0.7458 \tMSE_loss: 4.6481 \tTime: 0.0573\n",
      "Validation \tLoss_D: 1.3427\tLoss_G: 0.7625 \tMSE_loss: 5.5018 \tBest_loss: 5.5018\n",
      "[2/200][141/142]\tLoss_D: 1.3489\tLoss_G: 0.7602 \tMSE_loss: 5.0756 \tTime: 0.0516\n",
      "Validation \tLoss_D: 1.3155\tLoss_G: 0.7702 \tMSE_loss: 5.4310 \tBest_loss: 5.4310\n",
      "[3/200][141/142]\tLoss_D: 1.2972\tLoss_G: 0.7553 \tMSE_loss: 3.8531 \tTime: 0.0626\n",
      "Validation \tLoss_D: 1.2858\tLoss_G: 0.7819 \tMSE_loss: 5.3966 \tBest_loss: 5.3966\n",
      "[4/200][141/142]\tLoss_D: 1.2488\tLoss_G: 0.7773 \tMSE_loss: 4.4865 \tTime: 0.0552\n",
      "Validation \tLoss_D: 1.2555\tLoss_G: 0.7962 \tMSE_loss: 5.3472 \tBest_loss: 5.3472\n",
      "[5/200][141/142]\tLoss_D: 1.3231\tLoss_G: 0.7750 \tMSE_loss: 4.6449 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.2283\tLoss_G: 0.8068 \tMSE_loss: 5.2460 \tBest_loss: 5.2460\n",
      "[6/200][141/142]\tLoss_D: 1.2587\tLoss_G: 0.8116 \tMSE_loss: 5.1280 \tTime: 0.0538\n",
      "Validation \tLoss_D: 1.1928\tLoss_G: 0.8350 \tMSE_loss: 5.2395 \tBest_loss: 5.2395\n",
      "[7/200][141/142]\tLoss_D: 1.2345\tLoss_G: 0.8226 \tMSE_loss: 6.2333 \tTime: 0.0541\n",
      "Validation \tLoss_D: 1.1675\tLoss_G: 0.8542 \tMSE_loss: 5.1745 \tBest_loss: 5.1745\n",
      "[8/200][141/142]\tLoss_D: 1.2237\tLoss_G: 0.8311 \tMSE_loss: 4.1918 \tTime: 0.0594\n",
      "Validation \tLoss_D: 1.1395\tLoss_G: 0.8824 \tMSE_loss: 5.1612 \tBest_loss: 5.1612\n",
      "[9/200][141/142]\tLoss_D: 1.2389\tLoss_G: 0.8466 \tMSE_loss: 3.6057 \tTime: 0.0583\n",
      "Validation \tLoss_D: 1.1295\tLoss_G: 0.8937 \tMSE_loss: 5.0987 \tBest_loss: 5.0987\n",
      "[10/200][141/142]\tLoss_D: 1.2010\tLoss_G: 0.8495 \tMSE_loss: 4.0266 \tTime: 0.0637\n",
      "Validation \tLoss_D: 1.1018\tLoss_G: 0.9326 \tMSE_loss: 5.0759 \tBest_loss: 5.0759\n",
      "[11/200][141/142]\tLoss_D: 1.2614\tLoss_G: 0.9615 \tMSE_loss: 4.0284 \tTime: 0.0561\n",
      "Validation \tLoss_D: 1.0957\tLoss_G: 0.9418 \tMSE_loss: 5.0318 \tBest_loss: 5.0318\n",
      "[12/200][141/142]\tLoss_D: 1.0790\tLoss_G: 0.9731 \tMSE_loss: 4.4148 \tTime: 0.0523\n",
      "Validation \tLoss_D: 1.0819\tLoss_G: 0.9684 \tMSE_loss: 4.9983 \tBest_loss: 4.9983\n",
      "[13/200][141/142]\tLoss_D: 1.1826\tLoss_G: 0.7920 \tMSE_loss: 3.1252 \tTime: 0.0535\n",
      "Validation \tLoss_D: 1.0847\tLoss_G: 0.9679 \tMSE_loss: 4.9641 \tBest_loss: 4.9641\n",
      "[14/200][141/142]\tLoss_D: 1.0805\tLoss_G: 0.9534 \tMSE_loss: 4.8030 \tTime: 0.0642\n",
      "Validation \tLoss_D: 1.0696\tLoss_G: 0.9951 \tMSE_loss: 4.9724 \tBest_loss: 4.9641\n",
      "[15/200][141/142]\tLoss_D: 0.9730\tLoss_G: 1.0524 \tMSE_loss: 6.4265 \tTime: 0.0587\n",
      "Validation \tLoss_D: 1.0489\tLoss_G: 1.0335 \tMSE_loss: 4.9228 \tBest_loss: 4.9228\n",
      "[16/200][141/142]\tLoss_D: 1.2041\tLoss_G: 0.9202 \tMSE_loss: 6.7375 \tTime: 0.0547\n",
      "Validation \tLoss_D: 1.0459\tLoss_G: 1.0370 \tMSE_loss: 4.8832 \tBest_loss: 4.8832\n",
      "[17/200][141/142]\tLoss_D: 0.9760\tLoss_G: 1.1312 \tMSE_loss: 7.4167 \tTime: 0.0565\n",
      "Validation \tLoss_D: 1.0171\tLoss_G: 1.0838 \tMSE_loss: 4.8629 \tBest_loss: 4.8629\n",
      "[18/200][141/142]\tLoss_D: 1.0540\tLoss_G: 1.0078 \tMSE_loss: 4.3647 \tTime: 0.0572\n",
      "Validation \tLoss_D: 1.0138\tLoss_G: 1.0941 \tMSE_loss: 4.8309 \tBest_loss: 4.8309\n",
      "[19/200][141/142]\tLoss_D: 1.1220\tLoss_G: 1.0259 \tMSE_loss: 4.8627 \tTime: 0.0552\n",
      "Validation \tLoss_D: 1.0395\tLoss_G: 1.0524 \tMSE_loss: 4.8303 \tBest_loss: 4.8303\n",
      "[20/200][141/142]\tLoss_D: 1.0887\tLoss_G: 1.0344 \tMSE_loss: 3.7875 \tTime: 0.0508\n",
      "Validation \tLoss_D: 1.0043\tLoss_G: 1.1034 \tMSE_loss: 4.7788 \tBest_loss: 4.7788\n",
      "[21/200][141/142]\tLoss_D: 1.1159\tLoss_G: 1.0437 \tMSE_loss: 5.4314 \tTime: 0.0585\n",
      "Validation \tLoss_D: 0.9879\tLoss_G: 1.1316 \tMSE_loss: 4.7325 \tBest_loss: 4.7325\n",
      "[22/200][141/142]\tLoss_D: 1.0574\tLoss_G: 1.1448 \tMSE_loss: 11.8970 \tTime: 0.0536\n",
      "Validation \tLoss_D: 0.9676\tLoss_G: 1.1569 \tMSE_loss: 4.7068 \tBest_loss: 4.7068\n",
      "[23/200][141/142]\tLoss_D: 1.0544\tLoss_G: 1.2275 \tMSE_loss: 5.9926 \tTime: 0.0594\n",
      "Validation \tLoss_D: 0.9440\tLoss_G: 1.1984 \tMSE_loss: 4.6695 \tBest_loss: 4.6695\n",
      "[24/200][141/142]\tLoss_D: 0.9699\tLoss_G: 1.0738 \tMSE_loss: 3.6776 \tTime: 0.0561\n",
      "Validation \tLoss_D: 0.9429\tLoss_G: 1.1910 \tMSE_loss: 4.6720 \tBest_loss: 4.6695\n",
      "[25/200][141/142]\tLoss_D: 0.9739\tLoss_G: 1.0798 \tMSE_loss: 6.9274 \tTime: 0.0573\n",
      "Validation \tLoss_D: 0.9143\tLoss_G: 1.2305 \tMSE_loss: 4.6717 \tBest_loss: 4.6695\n",
      "[26/200][141/142]\tLoss_D: 1.0733\tLoss_G: 1.1916 \tMSE_loss: 2.1357 \tTime: 0.0619\n",
      "Validation \tLoss_D: 0.8731\tLoss_G: 1.2887 \tMSE_loss: 4.5879 \tBest_loss: 4.5879\n",
      "[27/200][141/142]\tLoss_D: 0.9743\tLoss_G: 1.1367 \tMSE_loss: 3.7882 \tTime: 0.0582\n",
      "Validation \tLoss_D: 0.8718\tLoss_G: 1.2651 \tMSE_loss: 4.6685 \tBest_loss: 4.5879\n",
      "[28/200][141/142]\tLoss_D: 0.9516\tLoss_G: 1.1829 \tMSE_loss: 3.5865 \tTime: 0.0568\n",
      "Validation \tLoss_D: 0.8467\tLoss_G: 1.3025 \tMSE_loss: 4.6394 \tBest_loss: 4.5879\n",
      "[29/200][141/142]\tLoss_D: 0.9775\tLoss_G: 1.2726 \tMSE_loss: 3.1894 \tTime: 0.0616\n",
      "Validation \tLoss_D: 0.8136\tLoss_G: 1.3681 \tMSE_loss: 4.5411 \tBest_loss: 4.5411\n",
      "[30/200][141/142]\tLoss_D: 0.7552\tLoss_G: 1.3105 \tMSE_loss: 7.0117 \tTime: 0.0544\n",
      "Validation \tLoss_D: 0.8042\tLoss_G: 1.3671 \tMSE_loss: 4.5537 \tBest_loss: 4.5411\n",
      "[31/200][141/142]\tLoss_D: 0.9996\tLoss_G: 1.1492 \tMSE_loss: 4.5135 \tTime: 0.0628\n",
      "Validation \tLoss_D: 0.7909\tLoss_G: 1.3868 \tMSE_loss: 4.4876 \tBest_loss: 4.4876\n",
      "[32/200][141/142]\tLoss_D: 0.7761\tLoss_G: 1.3140 \tMSE_loss: 3.8163 \tTime: 0.0584\n",
      "Validation \tLoss_D: 0.7782\tLoss_G: 1.4195 \tMSE_loss: 4.5669 \tBest_loss: 4.4876\n",
      "[33/200][141/142]\tLoss_D: 0.7476\tLoss_G: 1.3704 \tMSE_loss: 4.4326 \tTime: 0.0424\n",
      "Validation \tLoss_D: 0.7741\tLoss_G: 1.4348 \tMSE_loss: 4.4852 \tBest_loss: 4.4852\n",
      "[34/200][141/142]\tLoss_D: 0.8395\tLoss_G: 1.1941 \tMSE_loss: 3.9603 \tTime: 0.0570\n",
      "Validation \tLoss_D: 0.7652\tLoss_G: 1.4711 \tMSE_loss: 4.5222 \tBest_loss: 4.4852\n",
      "[35/200][141/142]\tLoss_D: 0.8743\tLoss_G: 1.2710 \tMSE_loss: 2.8724 \tTime: 0.0530\n",
      "Validation \tLoss_D: 0.7719\tLoss_G: 1.4593 \tMSE_loss: 4.5001 \tBest_loss: 4.4852\n",
      "[36/200][141/142]\tLoss_D: 0.7833\tLoss_G: 1.2158 \tMSE_loss: 4.5469 \tTime: 0.0594\n",
      "Validation \tLoss_D: 0.7709\tLoss_G: 1.4952 \tMSE_loss: 4.5206 \tBest_loss: 4.4852\n",
      "[37/200][141/142]\tLoss_D: 0.9024\tLoss_G: 1.3340 \tMSE_loss: 4.3376 \tTime: 0.0560\n",
      "Validation \tLoss_D: 0.7607\tLoss_G: 1.5330 \tMSE_loss: 4.5419 \tBest_loss: 4.4852\n",
      "[38/200][141/142]\tLoss_D: 0.9781\tLoss_G: 1.3341 \tMSE_loss: 3.0806 \tTime: 0.0574\n",
      "Validation \tLoss_D: 0.7621\tLoss_G: 1.5307 \tMSE_loss: 4.5542 \tBest_loss: 4.4852\n",
      "[39/200][141/142]\tLoss_D: 0.8687\tLoss_G: 1.2691 \tMSE_loss: 4.4195 \tTime: 0.0572\n",
      "Validation \tLoss_D: 0.7710\tLoss_G: 1.4951 \tMSE_loss: 4.4862 \tBest_loss: 4.4852\n",
      "[40/200][141/142]\tLoss_D: 1.1590\tLoss_G: 1.3956 \tMSE_loss: 3.6562 \tTime: 0.0535\n",
      "Validation \tLoss_D: 0.7689\tLoss_G: 1.5223 \tMSE_loss: 4.5104 \tBest_loss: 4.4852\n",
      "[41/200][141/142]\tLoss_D: 0.9023\tLoss_G: 1.5744 \tMSE_loss: 4.6838 \tTime: 0.0545\n",
      "Validation \tLoss_D: 0.7622\tLoss_G: 1.5739 \tMSE_loss: 4.5648 \tBest_loss: 4.4852\n",
      "[42/200][141/142]\tLoss_D: 0.8151\tLoss_G: 1.4142 \tMSE_loss: 3.6438 \tTime: 0.0579\n",
      "Validation \tLoss_D: 0.7581\tLoss_G: 1.5960 \tMSE_loss: 4.5742 \tBest_loss: 4.4852\n",
      "[43/200][141/142]\tLoss_D: 0.7829\tLoss_G: 1.3967 \tMSE_loss: 3.9005 \tTime: 0.0543\n",
      "Validation \tLoss_D: 0.7441\tLoss_G: 1.6243 \tMSE_loss: 4.6473 \tBest_loss: 4.4852\n",
      "[44/200][141/142]\tLoss_D: 0.9069\tLoss_G: 1.4411 \tMSE_loss: 4.6287 \tTime: 0.0586\n",
      "Validation \tLoss_D: 0.7447\tLoss_G: 1.5897 \tMSE_loss: 4.5398 \tBest_loss: 4.4852\n",
      "[45/200][141/142]\tLoss_D: 0.7747\tLoss_G: 1.4630 \tMSE_loss: 3.8213 \tTime: 0.0553\n",
      "Validation \tLoss_D: 0.7412\tLoss_G: 1.6449 \tMSE_loss: 4.5815 \tBest_loss: 4.4852\n",
      "[46/200][141/142]\tLoss_D: 0.8062\tLoss_G: 1.3927 \tMSE_loss: 3.9708 \tTime: 0.0546\n",
      "Validation \tLoss_D: 0.7525\tLoss_G: 1.5909 \tMSE_loss: 4.5425 \tBest_loss: 4.4852\n",
      "[47/200][141/142]\tLoss_D: 0.7986\tLoss_G: 1.3363 \tMSE_loss: 4.7031 \tTime: 0.0658\n",
      "Validation \tLoss_D: 0.7422\tLoss_G: 1.6544 \tMSE_loss: 4.5513 \tBest_loss: 4.4852\n",
      "[48/200][141/142]\tLoss_D: 0.9772\tLoss_G: 1.5296 \tMSE_loss: 4.8516 \tTime: 0.0572\n",
      "Validation \tLoss_D: 0.7309\tLoss_G: 1.7060 \tMSE_loss: 4.5747 \tBest_loss: 4.4852\n",
      "[49/200][141/142]\tLoss_D: 0.6487\tLoss_G: 1.5706 \tMSE_loss: 5.0497 \tTime: 0.0560\n",
      "Validation \tLoss_D: 0.7352\tLoss_G: 1.6775 \tMSE_loss: 4.5115 \tBest_loss: 4.4852\n",
      "[50/200][141/142]\tLoss_D: 0.6956\tLoss_G: 1.6875 \tMSE_loss: 5.8155 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.7382\tLoss_G: 1.6775 \tMSE_loss: 4.5613 \tBest_loss: 4.4852\n",
      "[51/200][141/142]\tLoss_D: 0.8253\tLoss_G: 1.3018 \tMSE_loss: 6.2704 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.7286\tLoss_G: 1.7106 \tMSE_loss: 4.5728 \tBest_loss: 4.4852\n",
      "[52/200][141/142]\tLoss_D: 0.8859\tLoss_G: 1.3860 \tMSE_loss: 8.3445 \tTime: 0.0473\n",
      "Validation \tLoss_D: 0.7359\tLoss_G: 1.6767 \tMSE_loss: 4.5297 \tBest_loss: 4.4852\n",
      "[53/200][141/142]\tLoss_D: 0.8422\tLoss_G: 1.5201 \tMSE_loss: 5.8987 \tTime: 0.0484\n",
      "Validation \tLoss_D: 0.7356\tLoss_G: 1.7017 \tMSE_loss: 4.5173 \tBest_loss: 4.4852\n",
      "[54/200][141/142]\tLoss_D: 0.7675\tLoss_G: 1.8177 \tMSE_loss: 5.7718 \tTime: 0.0546\n",
      "Validation \tLoss_D: 0.7265\tLoss_G: 1.7155 \tMSE_loss: 4.5415 \tBest_loss: 4.4852\n",
      "[55/200][141/142]\tLoss_D: 0.7942\tLoss_G: 1.6501 \tMSE_loss: 3.6619 \tTime: 0.0568\n",
      "Validation \tLoss_D: 0.7266\tLoss_G: 1.7311 \tMSE_loss: 4.5029 \tBest_loss: 4.4852\n",
      "[56/200][141/142]\tLoss_D: 0.7786\tLoss_G: 1.5016 \tMSE_loss: 2.9366 \tTime: 0.0506\n",
      "Validation \tLoss_D: 0.7255\tLoss_G: 1.7508 \tMSE_loss: 4.4793 \tBest_loss: 4.4793\n",
      "[57/200][141/142]\tLoss_D: 0.7554\tLoss_G: 1.8414 \tMSE_loss: 5.0272 \tTime: 0.0618\n",
      "Validation \tLoss_D: 0.7117\tLoss_G: 1.8723 \tMSE_loss: 4.6340 \tBest_loss: 4.4793\n",
      "[58/200][141/142]\tLoss_D: 0.8496\tLoss_G: 1.5365 \tMSE_loss: 5.8832 \tTime: 0.0542\n",
      "Validation \tLoss_D: 0.7241\tLoss_G: 1.7428 \tMSE_loss: 4.4830 \tBest_loss: 4.4793\n",
      "[59/200][141/142]\tLoss_D: 0.7069\tLoss_G: 1.5098 \tMSE_loss: 4.8977 \tTime: 0.0571\n",
      "Validation \tLoss_D: 0.7183\tLoss_G: 1.8063 \tMSE_loss: 4.5338 \tBest_loss: 4.4793\n",
      "[60/200][141/142]\tLoss_D: 0.8053\tLoss_G: 1.5886 \tMSE_loss: 5.2380 \tTime: 0.0501\n",
      "Validation \tLoss_D: 0.7124\tLoss_G: 1.8430 \tMSE_loss: 4.5395 \tBest_loss: 4.4793\n",
      "[61/200][141/142]\tLoss_D: 0.7223\tLoss_G: 1.8179 \tMSE_loss: 6.5568 \tTime: 0.0523\n",
      "Validation \tLoss_D: 0.7041\tLoss_G: 1.8485 \tMSE_loss: 4.5182 \tBest_loss: 4.4793\n",
      "[62/200][141/142]\tLoss_D: 0.8417\tLoss_G: 1.4695 \tMSE_loss: 4.9536 \tTime: 0.0548\n",
      "Validation \tLoss_D: 0.7097\tLoss_G: 1.8251 \tMSE_loss: 4.4638 \tBest_loss: 4.4638\n",
      "[63/200][141/142]\tLoss_D: 0.9815\tLoss_G: 1.7803 \tMSE_loss: 4.3443 \tTime: 0.0557\n",
      "Validation \tLoss_D: 0.6956\tLoss_G: 1.8930 \tMSE_loss: 4.5254 \tBest_loss: 4.4638\n",
      "[64/200][141/142]\tLoss_D: 0.6300\tLoss_G: 1.4419 \tMSE_loss: 3.4953 \tTime: 0.0589\n",
      "Validation \tLoss_D: 0.7099\tLoss_G: 1.8373 \tMSE_loss: 4.4442 \tBest_loss: 4.4442\n",
      "[65/200][141/142]\tLoss_D: 0.8012\tLoss_G: 1.4170 \tMSE_loss: 3.5109 \tTime: 0.0561\n",
      "Validation \tLoss_D: 0.7084\tLoss_G: 1.8158 \tMSE_loss: 4.4067 \tBest_loss: 4.4067\n",
      "[66/200][141/142]\tLoss_D: 0.7191\tLoss_G: 1.8320 \tMSE_loss: 5.4690 \tTime: 0.0606\n",
      "Validation \tLoss_D: 0.6741\tLoss_G: 1.9648 \tMSE_loss: 4.6448 \tBest_loss: 4.4067\n",
      "[67/200][141/142]\tLoss_D: 0.9255\tLoss_G: 1.6622 \tMSE_loss: 5.5333 \tTime: 0.0503\n",
      "Validation \tLoss_D: 0.7251\tLoss_G: 1.8005 \tMSE_loss: 4.3446 \tBest_loss: 4.3446\n",
      "[68/200][141/142]\tLoss_D: 0.8537\tLoss_G: 1.4521 \tMSE_loss: 4.9177 \tTime: 0.0581\n",
      "Validation \tLoss_D: 0.7028\tLoss_G: 1.9061 \tMSE_loss: 4.4338 \tBest_loss: 4.3446\n",
      "[69/200][141/142]\tLoss_D: 0.5199\tLoss_G: 1.6836 \tMSE_loss: 4.4909 \tTime: 0.0515\n",
      "Validation \tLoss_D: 0.6874\tLoss_G: 1.9204 \tMSE_loss: 4.5070 \tBest_loss: 4.3446\n",
      "[70/200][141/142]\tLoss_D: 0.7778\tLoss_G: 1.6122 \tMSE_loss: 8.9395 \tTime: 0.0539\n",
      "Validation \tLoss_D: 0.6902\tLoss_G: 1.9198 \tMSE_loss: 4.4374 \tBest_loss: 4.3446\n",
      "[71/200][141/142]\tLoss_D: 0.8173\tLoss_G: 1.5219 \tMSE_loss: 4.4876 \tTime: 0.0578\n",
      "Validation \tLoss_D: 0.7167\tLoss_G: 1.8476 \tMSE_loss: 4.3092 \tBest_loss: 4.3092\n",
      "[72/200][141/142]\tLoss_D: 0.8256\tLoss_G: 1.6802 \tMSE_loss: 2.4139 \tTime: 0.0581\n",
      "Validation \tLoss_D: 0.6836\tLoss_G: 2.0045 \tMSE_loss: 4.4676 \tBest_loss: 4.3092\n",
      "[73/200][141/142]\tLoss_D: 0.5128\tLoss_G: 1.8404 \tMSE_loss: 3.7569 \tTime: 0.0593\n",
      "Validation \tLoss_D: 0.6938\tLoss_G: 1.9486 \tMSE_loss: 4.3705 \tBest_loss: 4.3092\n",
      "[74/200][141/142]\tLoss_D: 0.8402\tLoss_G: 1.4714 \tMSE_loss: 3.1816 \tTime: 0.0529\n",
      "Validation \tLoss_D: 0.6775\tLoss_G: 1.9699 \tMSE_loss: 4.4569 \tBest_loss: 4.3092\n",
      "[75/200][141/142]\tLoss_D: 0.6891\tLoss_G: 1.8053 \tMSE_loss: 5.2849 \tTime: 0.0657\n",
      "Validation \tLoss_D: 0.6784\tLoss_G: 2.0393 \tMSE_loss: 4.3800 \tBest_loss: 4.3092\n",
      "[76/200][141/142]\tLoss_D: 0.7691\tLoss_G: 1.9297 \tMSE_loss: 5.1676 \tTime: 0.0581\n",
      "Validation \tLoss_D: 0.6814\tLoss_G: 1.9733 \tMSE_loss: 4.3630 \tBest_loss: 4.3092\n",
      "[77/200][141/142]\tLoss_D: 0.6864\tLoss_G: 1.8338 \tMSE_loss: 4.9505 \tTime: 0.0601\n",
      "Validation \tLoss_D: 0.6698\tLoss_G: 2.0799 \tMSE_loss: 4.4899 \tBest_loss: 4.3092\n",
      "[78/200][141/142]\tLoss_D: 0.7405\tLoss_G: 1.4867 \tMSE_loss: 3.6609 \tTime: 0.0566\n",
      "Validation \tLoss_D: 0.6783\tLoss_G: 2.0405 \tMSE_loss: 4.4060 \tBest_loss: 4.3092\n",
      "[79/200][141/142]\tLoss_D: 0.5860\tLoss_G: 1.8063 \tMSE_loss: 5.6198 \tTime: 0.0528\n",
      "Validation \tLoss_D: 0.6811\tLoss_G: 2.0354 \tMSE_loss: 4.4398 \tBest_loss: 4.3092\n",
      "[80/200][141/142]\tLoss_D: 0.7634\tLoss_G: 1.7722 \tMSE_loss: 3.6827 \tTime: 0.0616\n",
      "Validation \tLoss_D: 0.6979\tLoss_G: 1.9841 \tMSE_loss: 4.3596 \tBest_loss: 4.3092\n",
      "[81/200][141/142]\tLoss_D: 0.9627\tLoss_G: 1.7202 \tMSE_loss: 4.3181 \tTime: 0.0579\n",
      "Validation \tLoss_D: 0.7044\tLoss_G: 1.9959 \tMSE_loss: 4.3431 \tBest_loss: 4.3092\n",
      "[82/200][141/142]\tLoss_D: 0.8865\tLoss_G: 1.5693 \tMSE_loss: 4.9602 \tTime: 0.0506\n",
      "Validation \tLoss_D: 0.7229\tLoss_G: 1.9374 \tMSE_loss: 4.3329 \tBest_loss: 4.3092\n",
      "[83/200][141/142]\tLoss_D: 0.8265\tLoss_G: 1.6620 \tMSE_loss: 3.4357 \tTime: 0.0534\n",
      "Validation \tLoss_D: 0.7054\tLoss_G: 1.9970 \tMSE_loss: 4.4296 \tBest_loss: 4.3092\n",
      "[84/200][141/142]\tLoss_D: 0.7957\tLoss_G: 1.8631 \tMSE_loss: 4.2539 \tTime: 0.0573\n",
      "Validation \tLoss_D: 0.7174\tLoss_G: 1.9970 \tMSE_loss: 4.4014 \tBest_loss: 4.3092\n",
      "[85/200][141/142]\tLoss_D: 0.8915\tLoss_G: 1.7978 \tMSE_loss: 6.0518 \tTime: 0.0579\n",
      "Validation \tLoss_D: 0.7369\tLoss_G: 1.9495 \tMSE_loss: 4.4077 \tBest_loss: 4.3092\n",
      "[86/200][141/142]\tLoss_D: 0.7863\tLoss_G: 2.0096 \tMSE_loss: 4.3590 \tTime: 0.0554\n",
      "Validation \tLoss_D: 0.7258\tLoss_G: 1.9692 \tMSE_loss: 4.4414 \tBest_loss: 4.3092\n",
      "[87/200][141/142]\tLoss_D: 0.9529\tLoss_G: 1.7465 \tMSE_loss: 6.2920 \tTime: 0.0609\n",
      "Validation \tLoss_D: 0.7565\tLoss_G: 1.8713 \tMSE_loss: 4.2748 \tBest_loss: 4.2748\n",
      "[88/200][141/142]\tLoss_D: 0.8110\tLoss_G: 1.9875 \tMSE_loss: 5.3787 \tTime: 0.0531\n",
      "Validation \tLoss_D: 0.7569\tLoss_G: 1.9227 \tMSE_loss: 4.3196 \tBest_loss: 4.2748\n",
      "[89/200][141/142]\tLoss_D: 1.0171\tLoss_G: 1.9158 \tMSE_loss: 3.6015 \tTime: 0.0612\n",
      "Validation \tLoss_D: 0.7414\tLoss_G: 1.9151 \tMSE_loss: 4.3881 \tBest_loss: 4.2748\n",
      "[90/200][141/142]\tLoss_D: 0.8699\tLoss_G: 1.9969 \tMSE_loss: 4.3594 \tTime: 0.0569\n",
      "Validation \tLoss_D: 0.7537\tLoss_G: 1.9231 \tMSE_loss: 4.4790 \tBest_loss: 4.2748\n",
      "[91/200][141/142]\tLoss_D: 0.8756\tLoss_G: 1.7816 \tMSE_loss: 3.9172 \tTime: 0.0588\n",
      "Validation \tLoss_D: 0.7556\tLoss_G: 1.9264 \tMSE_loss: 4.3665 \tBest_loss: 4.2748\n",
      "[92/200][141/142]\tLoss_D: 0.8561\tLoss_G: 1.5453 \tMSE_loss: 3.8012 \tTime: 0.0572\n",
      "Validation \tLoss_D: 0.7612\tLoss_G: 1.8904 \tMSE_loss: 4.3589 \tBest_loss: 4.2748\n",
      "[93/200][141/142]\tLoss_D: 0.8335\tLoss_G: 1.6079 \tMSE_loss: 3.8490 \tTime: 0.0581\n",
      "Validation \tLoss_D: 0.7591\tLoss_G: 1.8740 \tMSE_loss: 4.3533 \tBest_loss: 4.2748\n",
      "[94/200][141/142]\tLoss_D: 0.7977\tLoss_G: 1.9063 \tMSE_loss: 5.6234 \tTime: 0.0587\n",
      "Validation \tLoss_D: 0.7720\tLoss_G: 1.8723 \tMSE_loss: 4.3309 \tBest_loss: 4.2748\n",
      "[95/200][141/142]\tLoss_D: 0.7402\tLoss_G: 1.8473 \tMSE_loss: 5.5623 \tTime: 0.0538\n",
      "Validation \tLoss_D: 0.7668\tLoss_G: 1.9166 \tMSE_loss: 4.3507 \tBest_loss: 4.2748\n",
      "[96/200][141/142]\tLoss_D: 0.6449\tLoss_G: 1.5748 \tMSE_loss: 3.0683 \tTime: 0.0583\n",
      "Validation \tLoss_D: 0.7740\tLoss_G: 1.8517 \tMSE_loss: 4.3886 \tBest_loss: 4.2748\n",
      "[97/200][141/142]\tLoss_D: 0.8179\tLoss_G: 1.9630 \tMSE_loss: 6.2149 \tTime: 0.0618\n",
      "Validation \tLoss_D: 0.7734\tLoss_G: 1.8438 \tMSE_loss: 4.3049 \tBest_loss: 4.2748\n",
      "[98/200][141/142]\tLoss_D: 0.9726\tLoss_G: 1.5679 \tMSE_loss: 3.8198 \tTime: 0.0531\n",
      "Validation \tLoss_D: 0.8027\tLoss_G: 1.7468 \tMSE_loss: 4.2306 \tBest_loss: 4.2306\n",
      "[99/200][141/142]\tLoss_D: 0.6798\tLoss_G: 2.0710 \tMSE_loss: 5.1074 \tTime: 0.0563\n",
      "Validation \tLoss_D: 0.7729\tLoss_G: 1.8602 \tMSE_loss: 4.3382 \tBest_loss: 4.2306\n",
      "[100/200][141/142]\tLoss_D: 1.1213\tLoss_G: 1.4159 \tMSE_loss: 6.3061 \tTime: 0.0644\n",
      "Validation \tLoss_D: 0.7845\tLoss_G: 1.8629 \tMSE_loss: 4.3278 \tBest_loss: 4.2306\n",
      "[101/200][141/142]\tLoss_D: 0.7415\tLoss_G: 1.8853 \tMSE_loss: 5.8054 \tTime: 0.0518\n",
      "Validation \tLoss_D: 0.7707\tLoss_G: 1.8952 \tMSE_loss: 4.3975 \tBest_loss: 4.2306\n",
      "[102/200][141/142]\tLoss_D: 0.6635\tLoss_G: 1.5132 \tMSE_loss: 2.8203 \tTime: 0.0599\n",
      "Validation \tLoss_D: 0.7817\tLoss_G: 1.7925 \tMSE_loss: 4.2636 \tBest_loss: 4.2306\n",
      "[103/200][141/142]\tLoss_D: 0.9118\tLoss_G: 1.8345 \tMSE_loss: 3.1823 \tTime: 0.0586\n",
      "Validation \tLoss_D: 0.7814\tLoss_G: 1.7785 \tMSE_loss: 4.2748 \tBest_loss: 4.2306\n",
      "[104/200][141/142]\tLoss_D: 0.9348\tLoss_G: 2.0688 \tMSE_loss: 4.7930 \tTime: 0.0604\n",
      "Validation \tLoss_D: 0.7806\tLoss_G: 1.8226 \tMSE_loss: 4.2517 \tBest_loss: 4.2306\n",
      "[105/200][141/142]\tLoss_D: 0.8904\tLoss_G: 1.5465 \tMSE_loss: 7.2755 \tTime: 0.0575\n",
      "Validation \tLoss_D: 0.7901\tLoss_G: 1.7523 \tMSE_loss: 4.1994 \tBest_loss: 4.1994\n",
      "[106/200][141/142]\tLoss_D: 0.7865\tLoss_G: 1.9202 \tMSE_loss: 3.0847 \tTime: 0.0574\n",
      "Validation \tLoss_D: 0.7862\tLoss_G: 1.7413 \tMSE_loss: 4.1818 \tBest_loss: 4.1818\n",
      "[107/200][141/142]\tLoss_D: 0.8236\tLoss_G: 1.4189 \tMSE_loss: 5.1727 \tTime: 0.0491\n",
      "Validation \tLoss_D: 0.7843\tLoss_G: 1.7986 \tMSE_loss: 4.2193 \tBest_loss: 4.1818\n",
      "[108/200][141/142]\tLoss_D: 1.0302\tLoss_G: 1.3445 \tMSE_loss: 7.7730 \tTime: 0.0570\n",
      "Validation \tLoss_D: 0.7869\tLoss_G: 1.7547 \tMSE_loss: 4.1412 \tBest_loss: 4.1412\n",
      "[109/200][141/142]\tLoss_D: 0.7192\tLoss_G: 2.2248 \tMSE_loss: 4.9835 \tTime: 0.0547\n",
      "Validation \tLoss_D: 0.7872\tLoss_G: 1.7466 \tMSE_loss: 4.1391 \tBest_loss: 4.1391\n",
      "[110/200][141/142]\tLoss_D: 0.6906\tLoss_G: 2.2578 \tMSE_loss: 4.1778 \tTime: 0.0507\n",
      "Validation \tLoss_D: 0.7855\tLoss_G: 1.7878 \tMSE_loss: 4.1325 \tBest_loss: 4.1325\n",
      "[111/200][141/142]\tLoss_D: 0.7803\tLoss_G: 1.6370 \tMSE_loss: 4.9806 \tTime: 0.0578\n",
      "Validation \tLoss_D: 0.7913\tLoss_G: 1.7679 \tMSE_loss: 4.0914 \tBest_loss: 4.0914\n",
      "[112/200][141/142]\tLoss_D: 0.7287\tLoss_G: 1.5637 \tMSE_loss: 4.5440 \tTime: 0.0523\n",
      "Validation \tLoss_D: 0.8017\tLoss_G: 1.6970 \tMSE_loss: 4.0486 \tBest_loss: 4.0486\n",
      "[113/200][141/142]\tLoss_D: 0.8108\tLoss_G: 1.7862 \tMSE_loss: 5.0019 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.7875\tLoss_G: 1.7630 \tMSE_loss: 4.0616 \tBest_loss: 4.0486\n",
      "[114/200][141/142]\tLoss_D: 0.8862\tLoss_G: 1.7947 \tMSE_loss: 4.4032 \tTime: 0.0544\n",
      "Validation \tLoss_D: 0.8031\tLoss_G: 1.6799 \tMSE_loss: 3.9982 \tBest_loss: 3.9982\n",
      "[115/200][141/142]\tLoss_D: 0.7739\tLoss_G: 1.9753 \tMSE_loss: 6.2468 \tTime: 0.0577\n",
      "Validation \tLoss_D: 0.7894\tLoss_G: 1.7005 \tMSE_loss: 4.0310 \tBest_loss: 3.9982\n",
      "[116/200][141/142]\tLoss_D: 0.6967\tLoss_G: 1.9501 \tMSE_loss: 7.5296 \tTime: 0.0626\n",
      "Validation \tLoss_D: 0.7777\tLoss_G: 1.7566 \tMSE_loss: 4.1310 \tBest_loss: 3.9982\n",
      "[117/200][141/142]\tLoss_D: 0.7551\tLoss_G: 1.8257 \tMSE_loss: 7.1584 \tTime: 0.0556\n",
      "Validation \tLoss_D: 0.7763\tLoss_G: 1.7862 \tMSE_loss: 4.1245 \tBest_loss: 3.9982\n",
      "[118/200][141/142]\tLoss_D: 0.7580\tLoss_G: 1.7308 \tMSE_loss: 5.1250 \tTime: 0.0634\n",
      "Validation \tLoss_D: 0.7935\tLoss_G: 1.7069 \tMSE_loss: 4.0037 \tBest_loss: 3.9982\n",
      "[119/200][141/142]\tLoss_D: 0.9915\tLoss_G: 2.0347 \tMSE_loss: 4.9627 \tTime: 0.0580\n",
      "Validation \tLoss_D: 0.7962\tLoss_G: 1.7139 \tMSE_loss: 4.0440 \tBest_loss: 3.9982\n",
      "[120/200][141/142]\tLoss_D: 0.7370\tLoss_G: 1.5691 \tMSE_loss: 6.1015 \tTime: 0.0525\n",
      "Validation \tLoss_D: 0.7926\tLoss_G: 1.7452 \tMSE_loss: 4.0701 \tBest_loss: 3.9982\n",
      "[121/200][141/142]\tLoss_D: 0.8465\tLoss_G: 1.6653 \tMSE_loss: 4.2897 \tTime: 0.0520\n",
      "Validation \tLoss_D: 0.8125\tLoss_G: 1.6675 \tMSE_loss: 3.9631 \tBest_loss: 3.9631\n",
      "[122/200][141/142]\tLoss_D: 0.7592\tLoss_G: 1.9190 \tMSE_loss: 7.8932 \tTime: 0.0575\n",
      "Validation \tLoss_D: 0.7605\tLoss_G: 1.8155 \tMSE_loss: 4.1442 \tBest_loss: 3.9631\n",
      "[123/200][141/142]\tLoss_D: 0.6197\tLoss_G: 1.5604 \tMSE_loss: 4.4756 \tTime: 0.0548\n",
      "Validation \tLoss_D: 0.7964\tLoss_G: 1.7482 \tMSE_loss: 4.0657 \tBest_loss: 3.9631\n",
      "[124/200][141/142]\tLoss_D: 0.7561\tLoss_G: 1.7040 \tMSE_loss: 3.1602 \tTime: 0.0556\n",
      "Validation \tLoss_D: 0.8120\tLoss_G: 1.6697 \tMSE_loss: 3.9685 \tBest_loss: 3.9631\n",
      "[125/200][141/142]\tLoss_D: 0.8565\tLoss_G: 1.4837 \tMSE_loss: 4.5654 \tTime: 0.0562\n",
      "Validation \tLoss_D: 0.8108\tLoss_G: 1.6950 \tMSE_loss: 3.9865 \tBest_loss: 3.9631\n",
      "[126/200][141/142]\tLoss_D: 0.7407\tLoss_G: 1.5061 \tMSE_loss: 2.6241 \tTime: 0.0480\n",
      "Validation \tLoss_D: 0.8026\tLoss_G: 1.6939 \tMSE_loss: 3.9972 \tBest_loss: 3.9631\n",
      "[127/200][141/142]\tLoss_D: 0.7444\tLoss_G: 1.4987 \tMSE_loss: 3.3187 \tTime: 0.0624\n",
      "Validation \tLoss_D: 0.8152\tLoss_G: 1.6550 \tMSE_loss: 3.9315 \tBest_loss: 3.9315\n",
      "[128/200][141/142]\tLoss_D: 0.7305\tLoss_G: 1.9607 \tMSE_loss: 5.3417 \tTime: 0.0553\n",
      "Validation \tLoss_D: 0.8355\tLoss_G: 1.6011 \tMSE_loss: 3.8613 \tBest_loss: 3.8613\n",
      "[129/200][141/142]\tLoss_D: 0.6596\tLoss_G: 1.7028 \tMSE_loss: 3.9835 \tTime: 0.0582\n",
      "Validation \tLoss_D: 0.8121\tLoss_G: 1.6691 \tMSE_loss: 3.9363 \tBest_loss: 3.8613\n",
      "[130/200][141/142]\tLoss_D: 0.9141\tLoss_G: 1.6514 \tMSE_loss: 3.6535 \tTime: 0.0581\n",
      "Validation \tLoss_D: 0.7996\tLoss_G: 1.7324 \tMSE_loss: 3.9397 \tBest_loss: 3.8613\n",
      "[131/200][141/142]\tLoss_D: 0.8416\tLoss_G: 1.7686 \tMSE_loss: 3.4273 \tTime: 0.0514\n",
      "Validation \tLoss_D: 0.8246\tLoss_G: 1.6332 \tMSE_loss: 3.8776 \tBest_loss: 3.8613\n",
      "[132/200][141/142]\tLoss_D: 0.8030\tLoss_G: 1.7720 \tMSE_loss: 3.6258 \tTime: 0.0515\n",
      "Validation \tLoss_D: 0.8420\tLoss_G: 1.5847 \tMSE_loss: 3.8444 \tBest_loss: 3.8444\n",
      "[133/200][141/142]\tLoss_D: 0.6230\tLoss_G: 2.0804 \tMSE_loss: 5.1990 \tTime: 0.0561\n",
      "Validation \tLoss_D: 0.8132\tLoss_G: 1.6934 \tMSE_loss: 3.9807 \tBest_loss: 3.8444\n",
      "[134/200][141/142]\tLoss_D: 0.7798\tLoss_G: 1.9738 \tMSE_loss: 3.5637 \tTime: 0.0525\n",
      "Validation \tLoss_D: 0.8217\tLoss_G: 1.6907 \tMSE_loss: 3.9258 \tBest_loss: 3.8444\n",
      "[135/200][141/142]\tLoss_D: 0.7717\tLoss_G: 1.5453 \tMSE_loss: 4.7913 \tTime: 0.0573\n",
      "Validation \tLoss_D: 0.8386\tLoss_G: 1.6529 \tMSE_loss: 3.8800 \tBest_loss: 3.8444\n",
      "[136/200][141/142]\tLoss_D: 0.7192\tLoss_G: 1.9061 \tMSE_loss: 4.6368 \tTime: 0.0584\n",
      "Validation \tLoss_D: 0.8390\tLoss_G: 1.6815 \tMSE_loss: 3.8601 \tBest_loss: 3.8444\n",
      "[137/200][141/142]\tLoss_D: 0.8350\tLoss_G: 1.4125 \tMSE_loss: 3.8370 \tTime: 0.0502\n",
      "Validation \tLoss_D: 0.8237\tLoss_G: 1.6952 \tMSE_loss: 3.9340 \tBest_loss: 3.8444\n",
      "[138/200][141/142]\tLoss_D: 0.9412\tLoss_G: 1.5278 \tMSE_loss: 2.5466 \tTime: 0.0621\n",
      "Validation \tLoss_D: 0.8268\tLoss_G: 1.6885 \tMSE_loss: 3.9357 \tBest_loss: 3.8444\n",
      "[139/200][141/142]\tLoss_D: 0.7869\tLoss_G: 1.4952 \tMSE_loss: 4.4325 \tTime: 0.0552\n",
      "Validation \tLoss_D: 0.8300\tLoss_G: 1.7072 \tMSE_loss: 3.9857 \tBest_loss: 3.8444\n",
      "[140/200][141/142]\tLoss_D: 1.0324\tLoss_G: 1.6596 \tMSE_loss: 5.3002 \tTime: 0.0593\n",
      "Validation \tLoss_D: 0.8396\tLoss_G: 1.6705 \tMSE_loss: 3.8988 \tBest_loss: 3.8444\n",
      "[141/200][141/142]\tLoss_D: 0.9703\tLoss_G: 1.7949 \tMSE_loss: 2.5491 \tTime: 0.0588\n",
      "Validation \tLoss_D: 0.8539\tLoss_G: 1.6583 \tMSE_loss: 3.8940 \tBest_loss: 3.8444\n",
      "[142/200][141/142]\tLoss_D: 0.6759\tLoss_G: 1.5046 \tMSE_loss: 5.4844 \tTime: 0.0573\n",
      "Validation \tLoss_D: 0.8621\tLoss_G: 1.6276 \tMSE_loss: 3.8549 \tBest_loss: 3.8444\n",
      "[143/200][141/142]\tLoss_D: 0.7040\tLoss_G: 1.7835 \tMSE_loss: 3.8553 \tTime: 0.0625\n",
      "Validation \tLoss_D: 0.8682\tLoss_G: 1.6286 \tMSE_loss: 3.8715 \tBest_loss: 3.8444\n",
      "[144/200][141/142]\tLoss_D: 0.5760\tLoss_G: 1.9179 \tMSE_loss: 3.7201 \tTime: 0.0618\n",
      "Validation \tLoss_D: 0.8696\tLoss_G: 1.6734 \tMSE_loss: 3.9062 \tBest_loss: 3.8444\n",
      "[145/200][141/142]\tLoss_D: 0.9045\tLoss_G: 1.9613 \tMSE_loss: 3.0909 \tTime: 0.0514\n",
      "Validation \tLoss_D: 0.8846\tLoss_G: 1.5916 \tMSE_loss: 3.8760 \tBest_loss: 3.8444\n",
      "[146/200][141/142]\tLoss_D: 0.9412\tLoss_G: 1.5916 \tMSE_loss: 2.6710 \tTime: 0.0527\n",
      "Validation \tLoss_D: 0.8928\tLoss_G: 1.6381 \tMSE_loss: 3.8650 \tBest_loss: 3.8444\n",
      "[147/200][141/142]\tLoss_D: 0.5368\tLoss_G: 2.4635 \tMSE_loss: 5.0424 \tTime: 0.0535\n",
      "Validation \tLoss_D: 0.8795\tLoss_G: 1.6492 \tMSE_loss: 3.8844 \tBest_loss: 3.8444\n",
      "[148/200][141/142]\tLoss_D: 0.8533\tLoss_G: 1.6234 \tMSE_loss: 4.1109 \tTime: 0.0586\n",
      "Validation \tLoss_D: 0.8922\tLoss_G: 1.6129 \tMSE_loss: 3.8100 \tBest_loss: 3.8100\n",
      "[149/200][141/142]\tLoss_D: 0.7511\tLoss_G: 1.7838 \tMSE_loss: 3.9204 \tTime: 0.0494\n",
      "Validation \tLoss_D: 0.9063\tLoss_G: 1.6328 \tMSE_loss: 3.8250 \tBest_loss: 3.8100\n",
      "[150/200][141/142]\tLoss_D: 0.8069\tLoss_G: 2.2183 \tMSE_loss: 4.2556 \tTime: 0.0554\n",
      "Validation \tLoss_D: 0.9036\tLoss_G: 1.6522 \tMSE_loss: 3.8841 \tBest_loss: 3.8100\n",
      "[151/200][141/142]\tLoss_D: 1.0491\tLoss_G: 1.5636 \tMSE_loss: 3.7609 \tTime: 0.0554\n",
      "Validation \tLoss_D: 0.9084\tLoss_G: 1.6038 \tMSE_loss: 3.8415 \tBest_loss: 3.8100\n",
      "[152/200][141/142]\tLoss_D: 0.7151\tLoss_G: 1.4907 \tMSE_loss: 4.6096 \tTime: 0.0542\n",
      "Validation \tLoss_D: 0.9180\tLoss_G: 1.6534 \tMSE_loss: 3.8606 \tBest_loss: 3.8100\n",
      "[153/200][141/142]\tLoss_D: 1.0790\tLoss_G: 1.4351 \tMSE_loss: 2.7315 \tTime: 0.0572\n",
      "Validation \tLoss_D: 0.9112\tLoss_G: 1.6282 \tMSE_loss: 3.8315 \tBest_loss: 3.8100\n",
      "[154/200][141/142]\tLoss_D: 0.9049\tLoss_G: 1.6106 \tMSE_loss: 3.9211 \tTime: 0.0604\n",
      "Validation \tLoss_D: 0.9163\tLoss_G: 1.6256 \tMSE_loss: 3.8721 \tBest_loss: 3.8100\n",
      "[155/200][141/142]\tLoss_D: 0.8458\tLoss_G: 1.7679 \tMSE_loss: 5.0999 \tTime: 0.0517\n",
      "Validation \tLoss_D: 0.9315\tLoss_G: 1.5871 \tMSE_loss: 3.8353 \tBest_loss: 3.8100\n",
      "[156/200][141/142]\tLoss_D: 0.7299\tLoss_G: 1.7782 \tMSE_loss: 3.9036 \tTime: 0.0522\n",
      "Validation \tLoss_D: 0.9367\tLoss_G: 1.5891 \tMSE_loss: 3.8070 \tBest_loss: 3.8070\n",
      "[157/200][141/142]\tLoss_D: 0.9193\tLoss_G: 1.7902 \tMSE_loss: 4.4254 \tTime: 0.0490\n",
      "Validation \tLoss_D: 0.9191\tLoss_G: 1.6316 \tMSE_loss: 3.9033 \tBest_loss: 3.8070\n",
      "[158/200][141/142]\tLoss_D: 0.7689\tLoss_G: 1.4772 \tMSE_loss: 2.7089 \tTime: 0.0487\n",
      "Validation \tLoss_D: 0.9436\tLoss_G: 1.5528 \tMSE_loss: 3.8130 \tBest_loss: 3.8070\n",
      "[159/200][141/142]\tLoss_D: 1.0132\tLoss_G: 1.9621 \tMSE_loss: 4.4868 \tTime: 0.0591\n",
      "Validation \tLoss_D: 0.9674\tLoss_G: 1.5152 \tMSE_loss: 3.7633 \tBest_loss: 3.7633\n",
      "[160/200][141/142]\tLoss_D: 0.6789\tLoss_G: 1.9807 \tMSE_loss: 4.3796 \tTime: 0.0623\n",
      "Validation \tLoss_D: 0.9441\tLoss_G: 1.5973 \tMSE_loss: 3.8825 \tBest_loss: 3.7633\n",
      "[161/200][141/142]\tLoss_D: 0.9207\tLoss_G: 1.9179 \tMSE_loss: 3.2303 \tTime: 0.0613\n",
      "Validation \tLoss_D: 0.9558\tLoss_G: 1.5919 \tMSE_loss: 3.8124 \tBest_loss: 3.7633\n",
      "[162/200][141/142]\tLoss_D: 0.8128\tLoss_G: 1.4914 \tMSE_loss: 2.8058 \tTime: 0.0567\n",
      "Validation \tLoss_D: 0.9445\tLoss_G: 1.5827 \tMSE_loss: 3.8333 \tBest_loss: 3.7633\n",
      "[163/200][141/142]\tLoss_D: 0.8408\tLoss_G: 1.6439 \tMSE_loss: 4.2160 \tTime: 0.0543\n",
      "Validation \tLoss_D: 0.9726\tLoss_G: 1.4938 \tMSE_loss: 3.7943 \tBest_loss: 3.7633\n",
      "[164/200][141/142]\tLoss_D: 0.9760\tLoss_G: 1.9932 \tMSE_loss: 2.8562 \tTime: 0.0527\n",
      "Validation \tLoss_D: 0.9708\tLoss_G: 1.4973 \tMSE_loss: 3.7856 \tBest_loss: 3.7633\n",
      "[165/200][141/142]\tLoss_D: 0.9116\tLoss_G: 2.2710 \tMSE_loss: 5.7007 \tTime: 0.0564\n",
      "Validation \tLoss_D: 0.9625\tLoss_G: 1.5621 \tMSE_loss: 3.7989 \tBest_loss: 3.7633\n",
      "[166/200][141/142]\tLoss_D: 0.8153\tLoss_G: 1.7990 \tMSE_loss: 3.5665 \tTime: 0.0548\n",
      "Validation \tLoss_D: 0.9425\tLoss_G: 1.5958 \tMSE_loss: 3.8860 \tBest_loss: 3.7633\n",
      "[167/200][141/142]\tLoss_D: 1.1555\tLoss_G: 1.5624 \tMSE_loss: 3.5072 \tTime: 0.0476\n",
      "Validation \tLoss_D: 0.9917\tLoss_G: 1.5144 \tMSE_loss: 3.8089 \tBest_loss: 3.7633\n",
      "[168/200][141/142]\tLoss_D: 0.6458\tLoss_G: 2.1782 \tMSE_loss: 4.2998 \tTime: 0.0571\n",
      "Validation \tLoss_D: 0.9974\tLoss_G: 1.4826 \tMSE_loss: 3.8058 \tBest_loss: 3.7633\n",
      "[169/200][141/142]\tLoss_D: 0.9864\tLoss_G: 1.9235 \tMSE_loss: 2.3726 \tTime: 0.0600\n",
      "Validation \tLoss_D: 0.9904\tLoss_G: 1.5285 \tMSE_loss: 3.7743 \tBest_loss: 3.7633\n",
      "[170/200][141/142]\tLoss_D: 0.7658\tLoss_G: 1.4369 \tMSE_loss: 3.2182 \tTime: 0.0584\n",
      "Validation \tLoss_D: 0.9840\tLoss_G: 1.5180 \tMSE_loss: 3.7589 \tBest_loss: 3.7589\n",
      "[171/200][141/142]\tLoss_D: 0.8298\tLoss_G: 1.4235 \tMSE_loss: 5.1605 \tTime: 0.0592\n",
      "Validation \tLoss_D: 0.9944\tLoss_G: 1.5067 \tMSE_loss: 3.7697 \tBest_loss: 3.7589\n",
      "[172/200][141/142]\tLoss_D: 1.0229\tLoss_G: 1.4963 \tMSE_loss: 3.2027 \tTime: 0.0662\n",
      "Validation \tLoss_D: 0.9799\tLoss_G: 1.5397 \tMSE_loss: 3.8341 \tBest_loss: 3.7589\n",
      "[173/200][141/142]\tLoss_D: 0.9667\tLoss_G: 1.4274 \tMSE_loss: 3.8893 \tTime: 0.0630\n",
      "Validation \tLoss_D: 0.9941\tLoss_G: 1.5113 \tMSE_loss: 3.7524 \tBest_loss: 3.7524\n",
      "[174/200][141/142]\tLoss_D: 0.8038\tLoss_G: 1.8067 \tMSE_loss: 7.4184 \tTime: 0.0547\n",
      "Validation \tLoss_D: 0.9875\tLoss_G: 1.5177 \tMSE_loss: 3.7931 \tBest_loss: 3.7524\n",
      "[175/200][141/142]\tLoss_D: 0.9860\tLoss_G: 1.8693 \tMSE_loss: 3.7518 \tTime: 0.0530\n",
      "Validation \tLoss_D: 0.9822\tLoss_G: 1.5109 \tMSE_loss: 3.8190 \tBest_loss: 3.7524\n",
      "[176/200][141/142]\tLoss_D: 0.6813\tLoss_G: 1.5742 \tMSE_loss: 6.9343 \tTime: 0.0569\n",
      "Validation \tLoss_D: 0.9903\tLoss_G: 1.5036 \tMSE_loss: 3.7642 \tBest_loss: 3.7524\n",
      "[177/200][141/142]\tLoss_D: 1.1581\tLoss_G: 1.6824 \tMSE_loss: 2.8619 \tTime: 0.0578\n",
      "Validation \tLoss_D: 1.0072\tLoss_G: 1.5398 \tMSE_loss: 3.7328 \tBest_loss: 3.7328\n",
      "[178/200][141/142]\tLoss_D: 0.8900\tLoss_G: 1.3265 \tMSE_loss: 3.7522 \tTime: 0.0647\n",
      "Validation \tLoss_D: 1.0112\tLoss_G: 1.4881 \tMSE_loss: 3.7419 \tBest_loss: 3.7328\n",
      "[179/200][141/142]\tLoss_D: 0.7913\tLoss_G: 2.0271 \tMSE_loss: 4.2509 \tTime: 0.0603\n",
      "Validation \tLoss_D: 1.0087\tLoss_G: 1.5031 \tMSE_loss: 3.7490 \tBest_loss: 3.7328\n",
      "[180/200][141/142]\tLoss_D: 1.1378\tLoss_G: 1.5743 \tMSE_loss: 3.4481 \tTime: 0.0572\n",
      "Validation \tLoss_D: 1.0109\tLoss_G: 1.4810 \tMSE_loss: 3.7510 \tBest_loss: 3.7328\n",
      "[181/200][141/142]\tLoss_D: 0.9799\tLoss_G: 1.6257 \tMSE_loss: 3.8107 \tTime: 0.0569\n",
      "Validation \tLoss_D: 1.0070\tLoss_G: 1.4659 \tMSE_loss: 3.7514 \tBest_loss: 3.7328\n",
      "[182/200][141/142]\tLoss_D: 1.2098\tLoss_G: 1.7035 \tMSE_loss: 4.1683 \tTime: 0.0574\n",
      "Validation \tLoss_D: 1.0041\tLoss_G: 1.5183 \tMSE_loss: 3.7796 \tBest_loss: 3.7328\n",
      "[183/200][141/142]\tLoss_D: 0.9619\tLoss_G: 1.7473 \tMSE_loss: 5.0460 \tTime: 0.0527\n",
      "Validation \tLoss_D: 1.0289\tLoss_G: 1.4611 \tMSE_loss: 3.7349 \tBest_loss: 3.7328\n",
      "[184/200][141/142]\tLoss_D: 0.7969\tLoss_G: 1.6436 \tMSE_loss: 3.5004 \tTime: 0.0598\n",
      "Validation \tLoss_D: 0.9970\tLoss_G: 1.4941 \tMSE_loss: 3.7719 \tBest_loss: 3.7328\n",
      "[185/200][141/142]\tLoss_D: 0.9430\tLoss_G: 1.9457 \tMSE_loss: 2.5556 \tTime: 0.0594\n",
      "Validation \tLoss_D: 1.0040\tLoss_G: 1.5204 \tMSE_loss: 3.7313 \tBest_loss: 3.7313\n",
      "[186/200][141/142]\tLoss_D: 0.5871\tLoss_G: 1.5447 \tMSE_loss: 3.3767 \tTime: 0.0557\n",
      "Validation \tLoss_D: 1.0092\tLoss_G: 1.5124 \tMSE_loss: 3.7470 \tBest_loss: 3.7313\n",
      "[187/200][141/142]\tLoss_D: 0.8553\tLoss_G: 1.8377 \tMSE_loss: 4.3725 \tTime: 0.0589\n",
      "Validation \tLoss_D: 1.0034\tLoss_G: 1.5246 \tMSE_loss: 3.7362 \tBest_loss: 3.7313\n",
      "[188/200][141/142]\tLoss_D: 0.9264\tLoss_G: 1.5824 \tMSE_loss: 3.8051 \tTime: 0.0582\n",
      "Validation \tLoss_D: 1.0018\tLoss_G: 1.5098 \tMSE_loss: 3.7382 \tBest_loss: 3.7313\n",
      "[189/200][141/142]\tLoss_D: 0.9981\tLoss_G: 1.7737 \tMSE_loss: 2.5364 \tTime: 0.0653\n",
      "Validation \tLoss_D: 1.0340\tLoss_G: 1.5040 \tMSE_loss: 3.7098 \tBest_loss: 3.7098\n",
      "[190/200][141/142]\tLoss_D: 0.9113\tLoss_G: 1.9013 \tMSE_loss: 3.6260 \tTime: 0.0589\n",
      "Validation \tLoss_D: 1.0090\tLoss_G: 1.4651 \tMSE_loss: 3.7479 \tBest_loss: 3.7098\n",
      "[191/200][141/142]\tLoss_D: 0.8653\tLoss_G: 1.4781 \tMSE_loss: 3.7820 \tTime: 0.0558\n",
      "Validation \tLoss_D: 1.0100\tLoss_G: 1.5183 \tMSE_loss: 3.7182 \tBest_loss: 3.7098\n",
      "[192/200][141/142]\tLoss_D: 0.7121\tLoss_G: 1.6266 \tMSE_loss: 2.9237 \tTime: 0.0574\n",
      "Validation \tLoss_D: 0.9953\tLoss_G: 1.5002 \tMSE_loss: 3.7632 \tBest_loss: 3.7098\n",
      "[193/200][141/142]\tLoss_D: 0.9620\tLoss_G: 1.2729 \tMSE_loss: 3.2721 \tTime: 0.0627\n",
      "Validation \tLoss_D: 1.0240\tLoss_G: 1.4796 \tMSE_loss: 3.7315 \tBest_loss: 3.7098\n",
      "[194/200][141/142]\tLoss_D: 1.0106\tLoss_G: 1.7720 \tMSE_loss: 3.3454 \tTime: 0.0647\n",
      "Validation \tLoss_D: 1.0360\tLoss_G: 1.4701 \tMSE_loss: 3.7228 \tBest_loss: 3.7098\n",
      "[195/200][141/142]\tLoss_D: 0.9174\tLoss_G: 1.4982 \tMSE_loss: 2.8378 \tTime: 0.0637\n",
      "Validation \tLoss_D: 1.0231\tLoss_G: 1.5069 \tMSE_loss: 3.7192 \tBest_loss: 3.7098\n",
      "[196/200][141/142]\tLoss_D: 0.8189\tLoss_G: 1.5486 \tMSE_loss: 4.3486 \tTime: 0.0573\n",
      "Validation \tLoss_D: 1.0170\tLoss_G: 1.5200 \tMSE_loss: 3.7323 \tBest_loss: 3.7098\n",
      "[197/200][141/142]\tLoss_D: 1.0503\tLoss_G: 1.7980 \tMSE_loss: 2.7822 \tTime: 0.0599\n",
      "Validation \tLoss_D: 1.0416\tLoss_G: 1.4968 \tMSE_loss: 3.7258 \tBest_loss: 3.7098\n",
      "[198/200][141/142]\tLoss_D: 0.8428\tLoss_G: 1.6119 \tMSE_loss: 4.4347 \tTime: 0.0576\n",
      "Validation \tLoss_D: 1.0240\tLoss_G: 1.4809 \tMSE_loss: 3.7228 \tBest_loss: 3.7098\n",
      "[199/200][141/142]\tLoss_D: 0.9177\tLoss_G: 1.9980 \tMSE_loss: 5.1317 \tTime: 0.0504\n",
      "Validation \tLoss_D: 1.0030\tLoss_G: 1.5305 \tMSE_loss: 3.7868 \tBest_loss: 3.7098\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "torch.manual_seed(8)\n",
    "\n",
    "def train_GAN(G, D, optim_G, optim_D, loss_f, train_loader, test_loader, num_epochs, device):\n",
    "    test_size = len(test_loader)\n",
    "    best = np.inf \n",
    "    for epoch in range(num_epochs):\n",
    "        for i,data in enumerate(train_loader):\n",
    "            if i<140:\n",
    "                generator.train()\n",
    "                discriminator.train()   \n",
    "                starting_time = time.time()\n",
    "                sequence , target = data\n",
    "                sequence = sequence.to(device)\n",
    "                target = target.to(device)\n",
    "                generator_fake = G(sequence)\n",
    "                true_seq = torch.concat((sequence,target.reshape(-1,1,7)),dim=1)\n",
    "                fake_seq = torch.concat((sequence,generator_fake),dim=1)\n",
    "                # ========================\n",
    "                #   Train Discriminator\n",
    "                # ========================\n",
    "                # train with real data\n",
    "                \n",
    "                prediction = D(true_seq)\n",
    "\n",
    "                # train with fake data\n",
    "                \n",
    "                fake_predection = D(fake_seq)\n",
    "                d_loss = descriminator_loss(prediction, fake_predection)\n",
    "                # update D\n",
    "                \n",
    "                D.zero_grad()\n",
    "                d_loss.backward()\n",
    "                optim_D.step()\n",
    "\n",
    "                # ========================\n",
    "                #   Train Generator\n",
    "                # ========================\n",
    "                # train with fake data  \n",
    "                        \n",
    "                sequence , target = data\n",
    "                sequence = sequence.to(device)\n",
    "                target = target.to(device)\n",
    "                generator_fake = G(sequence)\n",
    "                fake_seq = torch.concat((sequence,generator_fake),dim=1)\n",
    "                fake_predection = D(fake_seq)\n",
    "                g_loss, mse_loss = generator_loss(generator_fake,target,fake_predection)\n",
    "                # update G\n",
    "                G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                optim_G.step()   \n",
    "        print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f \\tMSE_loss: %.4f \\tTime: %.4f'% (epoch, num_epochs, i, len(train_loader), d_loss.item(), g_loss.item(),mse_loss.item(),time.time()-starting_time))\n",
    "        #evaluate \n",
    "        dis_loss = 0\n",
    "        gen_loss= 0\n",
    "        mse_loss = 0\n",
    "        diss_losses = []\n",
    "        gen_losses = []\n",
    "        mse_losses = []\n",
    "\n",
    "        for i,data in enumerate(test_loader):\n",
    "            generator.eval()\n",
    "            discriminator.eval()\n",
    "            with torch.no_grad():\n",
    "                sequence , target = data\n",
    "                sequence = sequence.to(device)\n",
    "                target = target.to(device)\n",
    "                generator_fake = G(sequence)\n",
    "                fake_seq = torch.concat((sequence,generator_fake),dim=1)\n",
    "                true_seq = torch.concat((sequence,target.reshape(-1,1,7)),dim=1)\n",
    "                fake_predection = D(fake_seq)\n",
    "                g_loss, mse = generator_loss(generator_fake,target,fake_predection)\n",
    "                prediction = D(true_seq)\n",
    "                d_loss = descriminator_loss(prediction, fake_predection)\n",
    "                dis_loss += d_loss.item()/test_size\n",
    "                gen_loss += g_loss.item()/test_size\n",
    "                mse_loss += mse.item()/test_size\n",
    "        diss_losses.append(dis_loss)\n",
    "        gen_losses.append(gen_loss)\n",
    "        mse_losses.append(mse_loss)\n",
    "\n",
    "        if mse_loss < best:\n",
    "            best = mse_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': G.state_dict(),\n",
    "                'optimizer_state_dict': optim_G.state_dict(),\n",
    "            }, 'Kan_gan.pth') \n",
    "        print('Validation \\tLoss_D: %.4f\\tLoss_G: %.4f \\tMSE_loss: %.4f \\tBest_loss: %.4f'% (dis_loss, gen_loss,mse_loss,best))\n",
    "    return diss_losses, gen_losses, mse_losses\n",
    "\n",
    "\n",
    "    \n",
    "loss_fn = nn.BCELoss()\n",
    "mse_fn = nn.MSELoss()\n",
    "\n",
    "a1 = 0.01\n",
    "def descriminator_loss(real_output, fake_output):\n",
    "    real_loss = loss_fn(real_output, torch.ones_like(real_output))\n",
    "    fake_loss = loss_fn(fake_output, torch.zeros_like(fake_output))\n",
    "    return real_loss + fake_loss\n",
    "def generator_loss(x,y,fake_output):\n",
    "    loss = loss_fn(fake_output, torch.ones_like(fake_output))\n",
    "    mse_loss = mse_fn(x,y.reshape(-1,1,7))\n",
    "    return a1*mse_loss + (1-a1)*loss , mse_loss\n",
    "\n",
    "epochs = 200\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = GeneratorModel(n_sequence, n_features).to(torch.float64)\n",
    "discriminator = KAN_discriminator(n_sequence,n_features).to(torch.float64)\n",
    "generator , discriminator = generator.to(device), discriminator.to(device)\n",
    "\n",
    "learning_rate1 = 0.00003\n",
    "learning_rate2 = 0.00003\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate1, betas=(0.5, 0.999))\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate2, betas=(0.5, 0.999))\n",
    "checkpoint_path = \"./train_checkpoints\"\n",
    "\n",
    "result = train_GAN(generator, discriminator, generator_optimizer, discriminator_optimizer, loss_fn, data_gen_train, data_gen_test, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "107fef76-44c1-4ffb-a52d-609d3fa10214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/200][141/142]\tLoss_D: 0.9106\tLoss_G: 1.8722 \tMSE_loss: 4.5771 \tTime: 0.0622\n",
      "Validation \tLoss_D: 1.0385\tLoss_G: 1.4600 \tMSE_loss: 3.7179 \tBest_loss: 3.7179\n",
      "[1/200][141/142]\tLoss_D: 1.2289\tLoss_G: 1.7469 \tMSE_loss: 4.5665 \tTime: 0.0575\n",
      "Validation \tLoss_D: 1.0382\tLoss_G: 1.4561 \tMSE_loss: 3.7294 \tBest_loss: 3.7179\n",
      "[2/200][141/142]\tLoss_D: 0.8072\tLoss_G: 2.0602 \tMSE_loss: 4.0434 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.0506\tLoss_G: 1.4207 \tMSE_loss: 3.7315 \tBest_loss: 3.7179\n",
      "[3/200][141/142]\tLoss_D: 0.7633\tLoss_G: 1.6446 \tMSE_loss: 6.3960 \tTime: 0.0607\n",
      "Validation \tLoss_D: 1.0053\tLoss_G: 1.5097 \tMSE_loss: 3.7797 \tBest_loss: 3.7179\n",
      "[4/200][141/142]\tLoss_D: 0.9397\tLoss_G: 1.6017 \tMSE_loss: 3.3865 \tTime: 0.0496\n",
      "Validation \tLoss_D: 1.0393\tLoss_G: 1.4185 \tMSE_loss: 3.7604 \tBest_loss: 3.7179\n",
      "[5/200][141/142]\tLoss_D: 0.9730\tLoss_G: 1.2528 \tMSE_loss: 2.9248 \tTime: 0.0505\n",
      "Validation \tLoss_D: 1.0189\tLoss_G: 1.4819 \tMSE_loss: 3.7388 \tBest_loss: 3.7179\n",
      "[6/200][141/142]\tLoss_D: 1.0749\tLoss_G: 1.6898 \tMSE_loss: 2.8230 \tTime: 0.0550\n",
      "Validation \tLoss_D: 1.0461\tLoss_G: 1.4846 \tMSE_loss: 3.7182 \tBest_loss: 3.7179\n",
      "[7/200][141/142]\tLoss_D: 0.8289\tLoss_G: 1.4477 \tMSE_loss: 3.3605 \tTime: 0.0534\n",
      "Validation \tLoss_D: 1.0487\tLoss_G: 1.3995 \tMSE_loss: 3.7404 \tBest_loss: 3.7179\n",
      "[8/200][141/142]\tLoss_D: 0.8482\tLoss_G: 1.7488 \tMSE_loss: 4.6200 \tTime: 0.0586\n",
      "Validation \tLoss_D: 1.0410\tLoss_G: 1.4860 \tMSE_loss: 3.7515 \tBest_loss: 3.7179\n",
      "[9/200][141/142]\tLoss_D: 0.8050\tLoss_G: 1.7299 \tMSE_loss: 3.3878 \tTime: 0.0580\n",
      "Validation \tLoss_D: 1.0704\tLoss_G: 1.3770 \tMSE_loss: 3.7122 \tBest_loss: 3.7122\n",
      "[10/200][141/142]\tLoss_D: 0.9425\tLoss_G: 1.9013 \tMSE_loss: 4.4318 \tTime: 0.0595\n",
      "Validation \tLoss_D: 1.0588\tLoss_G: 1.4444 \tMSE_loss: 3.7149 \tBest_loss: 3.7122\n",
      "[11/200][141/142]\tLoss_D: 0.8683\tLoss_G: 1.8847 \tMSE_loss: 5.7198 \tTime: 0.0563\n",
      "Validation \tLoss_D: 1.0249\tLoss_G: 1.4641 \tMSE_loss: 3.7675 \tBest_loss: 3.7122\n",
      "[12/200][141/142]\tLoss_D: 0.8358\tLoss_G: 1.7875 \tMSE_loss: 3.7284 \tTime: 0.0530\n",
      "Validation \tLoss_D: 1.0543\tLoss_G: 1.3673 \tMSE_loss: 3.7196 \tBest_loss: 3.7122\n",
      "[13/200][141/142]\tLoss_D: 0.9246\tLoss_G: 2.0125 \tMSE_loss: 4.5314 \tTime: 0.0567\n",
      "Validation \tLoss_D: 1.0678\tLoss_G: 1.3608 \tMSE_loss: 3.7072 \tBest_loss: 3.7072\n",
      "[14/200][141/142]\tLoss_D: 0.9527\tLoss_G: 1.4120 \tMSE_loss: 2.2099 \tTime: 0.0581\n",
      "Validation \tLoss_D: 1.0526\tLoss_G: 1.3936 \tMSE_loss: 3.7328 \tBest_loss: 3.7072\n",
      "[15/200][141/142]\tLoss_D: 0.9741\tLoss_G: 1.7438 \tMSE_loss: 4.6488 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.0639\tLoss_G: 1.4065 \tMSE_loss: 3.7345 \tBest_loss: 3.7072\n",
      "[16/200][141/142]\tLoss_D: 0.9475\tLoss_G: 1.6931 \tMSE_loss: 3.0258 \tTime: 0.0563\n",
      "Validation \tLoss_D: 1.0645\tLoss_G: 1.3771 \tMSE_loss: 3.7164 \tBest_loss: 3.7072\n",
      "[17/200][141/142]\tLoss_D: 0.9018\tLoss_G: 1.5688 \tMSE_loss: 3.8923 \tTime: 0.0501\n",
      "Validation \tLoss_D: 1.0882\tLoss_G: 1.3272 \tMSE_loss: 3.7131 \tBest_loss: 3.7072\n",
      "[18/200][141/142]\tLoss_D: 0.9442\tLoss_G: 1.4041 \tMSE_loss: 3.7456 \tTime: 0.0607\n",
      "Validation \tLoss_D: 1.0508\tLoss_G: 1.4247 \tMSE_loss: 3.7314 \tBest_loss: 3.7072\n",
      "[19/200][141/142]\tLoss_D: 1.0245\tLoss_G: 1.6314 \tMSE_loss: 6.2228 \tTime: 0.0585\n",
      "Validation \tLoss_D: 1.0683\tLoss_G: 1.4254 \tMSE_loss: 3.7094 \tBest_loss: 3.7072\n",
      "[20/200][141/142]\tLoss_D: 0.8458\tLoss_G: 2.1896 \tMSE_loss: 4.2284 \tTime: 0.0539\n",
      "Validation \tLoss_D: 1.0557\tLoss_G: 1.3768 \tMSE_loss: 3.7485 \tBest_loss: 3.7072\n",
      "[21/200][141/142]\tLoss_D: 0.9431\tLoss_G: 1.6790 \tMSE_loss: 5.1632 \tTime: 0.0605\n",
      "Validation \tLoss_D: 1.0850\tLoss_G: 1.3582 \tMSE_loss: 3.7055 \tBest_loss: 3.7055\n",
      "[22/200][141/142]\tLoss_D: 0.8096\tLoss_G: 1.7541 \tMSE_loss: 3.5348 \tTime: 0.0489\n",
      "Validation \tLoss_D: 1.0809\tLoss_G: 1.4343 \tMSE_loss: 3.7034 \tBest_loss: 3.7034\n",
      "[23/200][141/142]\tLoss_D: 0.8854\tLoss_G: 1.9447 \tMSE_loss: 3.7308 \tTime: 0.0530\n",
      "Validation \tLoss_D: 1.0753\tLoss_G: 1.3939 \tMSE_loss: 3.7041 \tBest_loss: 3.7034\n",
      "[24/200][141/142]\tLoss_D: 0.9812\tLoss_G: 1.3536 \tMSE_loss: 3.3732 \tTime: 0.0594\n",
      "Validation \tLoss_D: 1.0768\tLoss_G: 1.3782 \tMSE_loss: 3.7215 \tBest_loss: 3.7034\n",
      "[25/200][141/142]\tLoss_D: 0.9687\tLoss_G: 1.4918 \tMSE_loss: 8.2336 \tTime: 0.0626\n",
      "Validation \tLoss_D: 1.0704\tLoss_G: 1.3794 \tMSE_loss: 3.7311 \tBest_loss: 3.7034\n",
      "[26/200][141/142]\tLoss_D: 0.8343\tLoss_G: 1.6806 \tMSE_loss: 6.4879 \tTime: 0.0492\n",
      "Validation \tLoss_D: 1.0517\tLoss_G: 1.4307 \tMSE_loss: 3.7606 \tBest_loss: 3.7034\n",
      "[27/200][141/142]\tLoss_D: 1.2101\tLoss_G: 1.6799 \tMSE_loss: 3.6038 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.0923\tLoss_G: 1.3232 \tMSE_loss: 3.7149 \tBest_loss: 3.7034\n",
      "[28/200][141/142]\tLoss_D: 0.8490\tLoss_G: 1.5494 \tMSE_loss: 3.3603 \tTime: 0.0637\n",
      "Validation \tLoss_D: 1.0810\tLoss_G: 1.4072 \tMSE_loss: 3.7341 \tBest_loss: 3.7034\n",
      "[29/200][141/142]\tLoss_D: 0.8878\tLoss_G: 1.4593 \tMSE_loss: 5.7695 \tTime: 0.0539\n",
      "Validation \tLoss_D: 1.0851\tLoss_G: 1.3573 \tMSE_loss: 3.7506 \tBest_loss: 3.7034\n",
      "[30/200][141/142]\tLoss_D: 1.2852\tLoss_G: 1.7037 \tMSE_loss: 4.8764 \tTime: 0.0614\n",
      "Validation \tLoss_D: 1.0924\tLoss_G: 1.3550 \tMSE_loss: 3.7231 \tBest_loss: 3.7034\n",
      "[31/200][141/142]\tLoss_D: 0.7867\tLoss_G: 1.4380 \tMSE_loss: 3.7525 \tTime: 0.0585\n",
      "Validation \tLoss_D: 1.0872\tLoss_G: 1.3594 \tMSE_loss: 3.7399 \tBest_loss: 3.7034\n",
      "[32/200][141/142]\tLoss_D: 0.8310\tLoss_G: 1.4731 \tMSE_loss: 3.5302 \tTime: 0.0594\n",
      "Validation \tLoss_D: 1.0862\tLoss_G: 1.3708 \tMSE_loss: 3.7424 \tBest_loss: 3.7034\n",
      "[33/200][141/142]\tLoss_D: 0.9184\tLoss_G: 1.7018 \tMSE_loss: 6.1110 \tTime: 0.0424\n",
      "Validation \tLoss_D: 1.1284\tLoss_G: 1.2982 \tMSE_loss: 3.7212 \tBest_loss: 3.7034\n",
      "[34/200][141/142]\tLoss_D: 0.8175\tLoss_G: 1.4247 \tMSE_loss: 3.5642 \tTime: 0.0570\n",
      "Validation \tLoss_D: 1.0937\tLoss_G: 1.3392 \tMSE_loss: 3.7317 \tBest_loss: 3.7034\n",
      "[35/200][141/142]\tLoss_D: 0.9421\tLoss_G: 1.6912 \tMSE_loss: 3.2488 \tTime: 0.0544\n",
      "Validation \tLoss_D: 1.0618\tLoss_G: 1.3998 \tMSE_loss: 3.8330 \tBest_loss: 3.7034\n",
      "[36/200][141/142]\tLoss_D: 0.9430\tLoss_G: 1.6281 \tMSE_loss: 3.5346 \tTime: 0.0568\n",
      "Validation \tLoss_D: 1.0944\tLoss_G: 1.3345 \tMSE_loss: 3.7580 \tBest_loss: 3.7034\n",
      "[37/200][141/142]\tLoss_D: 0.8997\tLoss_G: 1.8033 \tMSE_loss: 3.4678 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.1065\tLoss_G: 1.3651 \tMSE_loss: 3.7279 \tBest_loss: 3.7034\n",
      "[38/200][141/142]\tLoss_D: 1.0410\tLoss_G: 1.5926 \tMSE_loss: 4.3866 \tTime: 0.0608\n",
      "Validation \tLoss_D: 1.0899\tLoss_G: 1.3479 \tMSE_loss: 3.7233 \tBest_loss: 3.7034\n",
      "[39/200][141/142]\tLoss_D: 0.9201\tLoss_G: 1.6533 \tMSE_loss: 4.6049 \tTime: 0.0513\n",
      "Validation \tLoss_D: 1.0838\tLoss_G: 1.3587 \tMSE_loss: 3.7489 \tBest_loss: 3.7034\n",
      "[40/200][141/142]\tLoss_D: 0.8842\tLoss_G: 1.5448 \tMSE_loss: 3.3432 \tTime: 0.0498\n",
      "Validation \tLoss_D: 1.0927\tLoss_G: 1.3655 \tMSE_loss: 3.7308 \tBest_loss: 3.7034\n",
      "[41/200][141/142]\tLoss_D: 1.0146\tLoss_G: 1.3632 \tMSE_loss: 5.2558 \tTime: 0.0602\n",
      "Validation \tLoss_D: 1.0994\tLoss_G: 1.3663 \tMSE_loss: 3.7371 \tBest_loss: 3.7034\n",
      "[42/200][141/142]\tLoss_D: 0.9760\tLoss_G: 1.5081 \tMSE_loss: 4.1255 \tTime: 0.0630\n",
      "Validation \tLoss_D: 1.1181\tLoss_G: 1.2924 \tMSE_loss: 3.7328 \tBest_loss: 3.7034\n",
      "[43/200][141/142]\tLoss_D: 0.9453\tLoss_G: 1.9014 \tMSE_loss: 3.7811 \tTime: 0.0585\n",
      "Validation \tLoss_D: 1.1175\tLoss_G: 1.3111 \tMSE_loss: 3.7289 \tBest_loss: 3.7034\n",
      "[44/200][141/142]\tLoss_D: 0.6988\tLoss_G: 1.6666 \tMSE_loss: 4.0684 \tTime: 0.0616\n",
      "Validation \tLoss_D: 1.1195\tLoss_G: 1.3003 \tMSE_loss: 3.7322 \tBest_loss: 3.7034\n",
      "[45/200][141/142]\tLoss_D: 0.9070\tLoss_G: 1.2154 \tMSE_loss: 2.3898 \tTime: 0.0467\n",
      "Validation \tLoss_D: 1.1481\tLoss_G: 1.2351 \tMSE_loss: 3.7233 \tBest_loss: 3.7034\n",
      "[46/200][141/142]\tLoss_D: 0.9568\tLoss_G: 1.8973 \tMSE_loss: 3.0466 \tTime: 0.0545\n",
      "Validation \tLoss_D: 1.1389\tLoss_G: 1.2712 \tMSE_loss: 3.7131 \tBest_loss: 3.7034\n",
      "[47/200][141/142]\tLoss_D: 1.1560\tLoss_G: 1.2313 \tMSE_loss: 5.1706 \tTime: 0.0524\n",
      "Validation \tLoss_D: 1.1309\tLoss_G: 1.2638 \tMSE_loss: 3.7637 \tBest_loss: 3.7034\n",
      "[48/200][141/142]\tLoss_D: 0.8460\tLoss_G: 2.0728 \tMSE_loss: 5.3309 \tTime: 0.0556\n",
      "Validation \tLoss_D: 1.1421\tLoss_G: 1.3041 \tMSE_loss: 3.7242 \tBest_loss: 3.7034\n",
      "[49/200][141/142]\tLoss_D: 0.9668\tLoss_G: 2.0051 \tMSE_loss: 5.5336 \tTime: 0.0552\n",
      "Validation \tLoss_D: 1.0843\tLoss_G: 1.4243 \tMSE_loss: 3.8068 \tBest_loss: 3.7034\n",
      "[50/200][141/142]\tLoss_D: 0.8717\tLoss_G: 1.5123 \tMSE_loss: 5.1836 \tTime: 0.0534\n",
      "Validation \tLoss_D: 1.1314\tLoss_G: 1.2902 \tMSE_loss: 3.7567 \tBest_loss: 3.7034\n",
      "[51/200][141/142]\tLoss_D: 0.9569\tLoss_G: 1.4328 \tMSE_loss: 2.3271 \tTime: 0.0521\n",
      "Validation \tLoss_D: 1.1295\tLoss_G: 1.3214 \tMSE_loss: 3.7414 \tBest_loss: 3.7034\n",
      "[52/200][141/142]\tLoss_D: 1.0409\tLoss_G: 1.5242 \tMSE_loss: 4.7411 \tTime: 0.0638\n",
      "Validation \tLoss_D: 1.1316\tLoss_G: 1.2911 \tMSE_loss: 3.7530 \tBest_loss: 3.7034\n",
      "[53/200][141/142]\tLoss_D: 0.9930\tLoss_G: 1.9069 \tMSE_loss: 4.4016 \tTime: 0.0608\n",
      "Validation \tLoss_D: 1.1033\tLoss_G: 1.3462 \tMSE_loss: 3.7818 \tBest_loss: 3.7034\n",
      "[54/200][141/142]\tLoss_D: 0.8339\tLoss_G: 1.5817 \tMSE_loss: 3.5614 \tTime: 0.0594\n",
      "Validation \tLoss_D: 1.1224\tLoss_G: 1.2984 \tMSE_loss: 3.7744 \tBest_loss: 3.7034\n",
      "[55/200][141/142]\tLoss_D: 0.7520\tLoss_G: 1.4246 \tMSE_loss: 4.5176 \tTime: 0.0529\n",
      "Validation \tLoss_D: 1.1709\tLoss_G: 1.2461 \tMSE_loss: 3.7459 \tBest_loss: 3.7034\n",
      "[56/200][141/142]\tLoss_D: 0.8753\tLoss_G: 1.7588 \tMSE_loss: 5.1103 \tTime: 0.0544\n",
      "Validation \tLoss_D: 1.1734\tLoss_G: 1.2755 \tMSE_loss: 3.7478 \tBest_loss: 3.7034\n",
      "[57/200][141/142]\tLoss_D: 0.8908\tLoss_G: 1.6531 \tMSE_loss: 3.5574 \tTime: 0.0575\n",
      "Validation \tLoss_D: 1.1902\tLoss_G: 1.2085 \tMSE_loss: 3.7284 \tBest_loss: 3.7034\n",
      "[58/200][141/142]\tLoss_D: 1.0166\tLoss_G: 1.4539 \tMSE_loss: 3.5260 \tTime: 0.0607\n",
      "Validation \tLoss_D: 1.1696\tLoss_G: 1.1845 \tMSE_loss: 3.7312 \tBest_loss: 3.7034\n",
      "[59/200][141/142]\tLoss_D: 1.0447\tLoss_G: 1.5882 \tMSE_loss: 3.3601 \tTime: 0.0508\n",
      "Validation \tLoss_D: 1.1356\tLoss_G: 1.2663 \tMSE_loss: 3.7688 \tBest_loss: 3.7034\n",
      "[60/200][141/142]\tLoss_D: 0.8966\tLoss_G: 1.4458 \tMSE_loss: 4.2547 \tTime: 0.0564\n",
      "Validation \tLoss_D: 1.1610\tLoss_G: 1.2664 \tMSE_loss: 3.7590 \tBest_loss: 3.7034\n",
      "[61/200][141/142]\tLoss_D: 0.9490\tLoss_G: 1.9156 \tMSE_loss: 4.1448 \tTime: 0.0568\n",
      "Validation \tLoss_D: 1.1863\tLoss_G: 1.2137 \tMSE_loss: 3.7360 \tBest_loss: 3.7034\n",
      "[62/200][141/142]\tLoss_D: 0.8520\tLoss_G: 1.8853 \tMSE_loss: 7.7933 \tTime: 0.0617\n",
      "Validation \tLoss_D: 1.1268\tLoss_G: 1.2791 \tMSE_loss: 3.7958 \tBest_loss: 3.7034\n",
      "[63/200][141/142]\tLoss_D: 0.8546\tLoss_G: 1.8065 \tMSE_loss: 5.7433 \tTime: 0.0579\n",
      "Validation \tLoss_D: 1.1801\tLoss_G: 1.2112 \tMSE_loss: 3.7529 \tBest_loss: 3.7034\n",
      "[64/200][141/142]\tLoss_D: 0.9677\tLoss_G: 1.8236 \tMSE_loss: 4.5140 \tTime: 0.0570\n",
      "Validation \tLoss_D: 1.1814\tLoss_G: 1.2205 \tMSE_loss: 3.7443 \tBest_loss: 3.7034\n",
      "[65/200][141/142]\tLoss_D: 0.9046\tLoss_G: 1.4878 \tMSE_loss: 4.1363 \tTime: 0.0543\n",
      "Validation \tLoss_D: 1.1741\tLoss_G: 1.2175 \tMSE_loss: 3.7484 \tBest_loss: 3.7034\n",
      "[66/200][141/142]\tLoss_D: 0.9046\tLoss_G: 1.3295 \tMSE_loss: 3.9007 \tTime: 0.0583\n",
      "Validation \tLoss_D: 1.1894\tLoss_G: 1.1949 \tMSE_loss: 3.7666 \tBest_loss: 3.7034\n",
      "[67/200][141/142]\tLoss_D: 1.0975\tLoss_G: 1.4658 \tMSE_loss: 3.3399 \tTime: 0.0547\n",
      "Validation \tLoss_D: 1.1697\tLoss_G: 1.2195 \tMSE_loss: 3.7759 \tBest_loss: 3.7034\n",
      "[68/200][141/142]\tLoss_D: 0.9524\tLoss_G: 1.4078 \tMSE_loss: 4.7415 \tTime: 0.0558\n",
      "Validation \tLoss_D: 1.2065\tLoss_G: 1.1879 \tMSE_loss: 3.7467 \tBest_loss: 3.7034\n",
      "[69/200][141/142]\tLoss_D: 1.0980\tLoss_G: 1.8375 \tMSE_loss: 5.0593 \tTime: 0.0573\n",
      "Validation \tLoss_D: 1.1417\tLoss_G: 1.2678 \tMSE_loss: 3.7793 \tBest_loss: 3.7034\n",
      "[70/200][141/142]\tLoss_D: 0.7657\tLoss_G: 1.4787 \tMSE_loss: 3.4183 \tTime: 0.0626\n",
      "Validation \tLoss_D: 1.1823\tLoss_G: 1.2021 \tMSE_loss: 3.7561 \tBest_loss: 3.7034\n",
      "[71/200][141/142]\tLoss_D: 1.0533\tLoss_G: 1.6669 \tMSE_loss: 2.6096 \tTime: 0.0573\n",
      "Validation \tLoss_D: 1.1476\tLoss_G: 1.2650 \tMSE_loss: 3.8277 \tBest_loss: 3.7034\n",
      "[72/200][141/142]\tLoss_D: 0.7601\tLoss_G: 1.7052 \tMSE_loss: 3.1092 \tTime: 0.0646\n",
      "Validation \tLoss_D: 1.1651\tLoss_G: 1.2717 \tMSE_loss: 3.7850 \tBest_loss: 3.7034\n",
      "[73/200][141/142]\tLoss_D: 1.0042\tLoss_G: 1.6627 \tMSE_loss: 2.7249 \tTime: 0.0530\n",
      "Validation \tLoss_D: 1.1689\tLoss_G: 1.2621 \tMSE_loss: 3.7748 \tBest_loss: 3.7034\n",
      "[74/200][141/142]\tLoss_D: 1.0174\tLoss_G: 2.1073 \tMSE_loss: 4.5640 \tTime: 0.0569\n",
      "Validation \tLoss_D: 1.1966\tLoss_G: 1.2253 \tMSE_loss: 3.7807 \tBest_loss: 3.7034\n",
      "[75/200][141/142]\tLoss_D: 1.0681\tLoss_G: 1.4639 \tMSE_loss: 5.0352 \tTime: 0.0587\n",
      "Validation \tLoss_D: 1.1898\tLoss_G: 1.2287 \tMSE_loss: 3.7897 \tBest_loss: 3.7034\n",
      "[76/200][141/142]\tLoss_D: 0.9406\tLoss_G: 1.6411 \tMSE_loss: 3.2781 \tTime: 0.0597\n",
      "Validation \tLoss_D: 1.1868\tLoss_G: 1.1861 \tMSE_loss: 3.7832 \tBest_loss: 3.7034\n",
      "[77/200][141/142]\tLoss_D: 1.0425\tLoss_G: 1.4874 \tMSE_loss: 6.0791 \tTime: 0.0545\n",
      "Validation \tLoss_D: 1.1595\tLoss_G: 1.2422 \tMSE_loss: 3.8750 \tBest_loss: 3.7034\n",
      "[78/200][141/142]\tLoss_D: 0.8810\tLoss_G: 1.9027 \tMSE_loss: 6.2214 \tTime: 0.0589\n",
      "Validation \tLoss_D: 1.1697\tLoss_G: 1.2571 \tMSE_loss: 3.8229 \tBest_loss: 3.7034\n",
      "[79/200][141/142]\tLoss_D: 0.9269\tLoss_G: 1.7363 \tMSE_loss: 5.3523 \tTime: 0.0656\n",
      "Validation \tLoss_D: 1.1920\tLoss_G: 1.2266 \tMSE_loss: 3.7809 \tBest_loss: 3.7034\n",
      "[80/200][141/142]\tLoss_D: 0.7856\tLoss_G: 1.6839 \tMSE_loss: 4.3755 \tTime: 0.0473\n",
      "Validation \tLoss_D: 1.1649\tLoss_G: 1.2706 \tMSE_loss: 3.7703 \tBest_loss: 3.7034\n",
      "[81/200][141/142]\tLoss_D: 0.9082\tLoss_G: 1.7798 \tMSE_loss: 4.7632 \tTime: 0.0557\n",
      "Validation \tLoss_D: 1.1923\tLoss_G: 1.2069 \tMSE_loss: 3.8102 \tBest_loss: 3.7034\n",
      "[82/200][141/142]\tLoss_D: 0.8514\tLoss_G: 1.7320 \tMSE_loss: 2.8609 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.2087\tLoss_G: 1.1897 \tMSE_loss: 3.7898 \tBest_loss: 3.7034\n",
      "[83/200][141/142]\tLoss_D: 0.9883\tLoss_G: 1.6838 \tMSE_loss: 3.1092 \tTime: 0.0568\n",
      "Validation \tLoss_D: 1.1978\tLoss_G: 1.2031 \tMSE_loss: 3.8047 \tBest_loss: 3.7034\n",
      "[84/200][141/142]\tLoss_D: 0.7531\tLoss_G: 1.7768 \tMSE_loss: 3.4669 \tTime: 0.0492\n",
      "Validation \tLoss_D: 1.2064\tLoss_G: 1.2351 \tMSE_loss: 3.8031 \tBest_loss: 3.7034\n",
      "[85/200][141/142]\tLoss_D: 1.0936\tLoss_G: 1.5992 \tMSE_loss: 4.6622 \tTime: 0.0614\n",
      "Validation \tLoss_D: 1.2139\tLoss_G: 1.2082 \tMSE_loss: 3.7895 \tBest_loss: 3.7034\n",
      "[86/200][141/142]\tLoss_D: 0.9012\tLoss_G: 2.0843 \tMSE_loss: 5.7158 \tTime: 0.0613\n",
      "Validation \tLoss_D: 1.2269\tLoss_G: 1.2258 \tMSE_loss: 3.7842 \tBest_loss: 3.7034\n",
      "[87/200][141/142]\tLoss_D: 0.6569\tLoss_G: 1.6340 \tMSE_loss: 5.4953 \tTime: 0.0558\n",
      "Validation \tLoss_D: 1.1981\tLoss_G: 1.2017 \tMSE_loss: 3.8065 \tBest_loss: 3.7034\n",
      "[88/200][141/142]\tLoss_D: 0.8910\tLoss_G: 1.6660 \tMSE_loss: 6.8703 \tTime: 0.0508\n",
      "Validation \tLoss_D: 1.2147\tLoss_G: 1.2259 \tMSE_loss: 3.8087 \tBest_loss: 3.7034\n",
      "[89/200][141/142]\tLoss_D: 1.0705\tLoss_G: 1.7196 \tMSE_loss: 3.8349 \tTime: 0.0616\n",
      "Validation \tLoss_D: 1.2238\tLoss_G: 1.2339 \tMSE_loss: 3.8032 \tBest_loss: 3.7034\n",
      "[90/200][141/142]\tLoss_D: 0.9312\tLoss_G: 1.3644 \tMSE_loss: 4.1535 \tTime: 0.0585\n",
      "Validation \tLoss_D: 1.1953\tLoss_G: 1.2314 \tMSE_loss: 3.8047 \tBest_loss: 3.7034\n",
      "[91/200][141/142]\tLoss_D: 0.8382\tLoss_G: 1.3584 \tMSE_loss: 3.5534 \tTime: 0.0569\n",
      "Validation \tLoss_D: 1.2424\tLoss_G: 1.1655 \tMSE_loss: 3.7718 \tBest_loss: 3.7034\n",
      "[92/200][141/142]\tLoss_D: 1.0965\tLoss_G: 1.6372 \tMSE_loss: 4.3630 \tTime: 0.0566\n",
      "Validation \tLoss_D: 1.2318\tLoss_G: 1.1776 \tMSE_loss: 3.8216 \tBest_loss: 3.7034\n",
      "[93/200][141/142]\tLoss_D: 0.6257\tLoss_G: 1.8181 \tMSE_loss: 4.5432 \tTime: 0.0527\n",
      "Validation \tLoss_D: 1.2312\tLoss_G: 1.2072 \tMSE_loss: 3.8417 \tBest_loss: 3.7034\n",
      "[94/200][141/142]\tLoss_D: 0.8090\tLoss_G: 1.7423 \tMSE_loss: 4.4935 \tTime: 0.0586\n",
      "Validation \tLoss_D: 1.2048\tLoss_G: 1.2241 \tMSE_loss: 3.8248 \tBest_loss: 3.7034\n",
      "[95/200][141/142]\tLoss_D: 0.9387\tLoss_G: 1.9834 \tMSE_loss: 4.1338 \tTime: 0.0526\n",
      "Validation \tLoss_D: 1.2425\tLoss_G: 1.2165 \tMSE_loss: 3.8055 \tBest_loss: 3.7034\n",
      "[96/200][141/142]\tLoss_D: 0.9362\tLoss_G: 1.5157 \tMSE_loss: 8.9604 \tTime: 0.0580\n",
      "Validation \tLoss_D: 1.1914\tLoss_G: 1.2918 \tMSE_loss: 3.8393 \tBest_loss: 3.7034\n",
      "[97/200][141/142]\tLoss_D: 0.9898\tLoss_G: 2.0932 \tMSE_loss: 3.1007 \tTime: 0.0539\n",
      "Validation \tLoss_D: 1.2357\tLoss_G: 1.2081 \tMSE_loss: 3.7997 \tBest_loss: 3.7034\n",
      "[98/200][141/142]\tLoss_D: 1.1503\tLoss_G: 1.6578 \tMSE_loss: 3.4434 \tTime: 0.0567\n",
      "Validation \tLoss_D: 1.2403\tLoss_G: 1.1860 \tMSE_loss: 3.8362 \tBest_loss: 3.7034\n",
      "[99/200][141/142]\tLoss_D: 1.0268\tLoss_G: 1.2669 \tMSE_loss: 5.4070 \tTime: 0.0598\n",
      "Validation \tLoss_D: 1.2446\tLoss_G: 1.1921 \tMSE_loss: 3.7864 \tBest_loss: 3.7034\n",
      "[100/200][141/142]\tLoss_D: 0.6351\tLoss_G: 1.7259 \tMSE_loss: 5.6876 \tTime: 0.0561\n",
      "Validation \tLoss_D: 1.2393\tLoss_G: 1.2556 \tMSE_loss: 3.8361 \tBest_loss: 3.7034\n",
      "[101/200][141/142]\tLoss_D: 0.9119\tLoss_G: 2.0514 \tMSE_loss: 4.1984 \tTime: 0.0556\n",
      "Validation \tLoss_D: 1.2625\tLoss_G: 1.1998 \tMSE_loss: 3.8147 \tBest_loss: 3.7034\n",
      "[102/200][141/142]\tLoss_D: 1.0534\tLoss_G: 2.0651 \tMSE_loss: 3.5265 \tTime: 0.0525\n",
      "Validation \tLoss_D: 1.2652\tLoss_G: 1.1602 \tMSE_loss: 3.7819 \tBest_loss: 3.7034\n",
      "[103/200][141/142]\tLoss_D: 1.2446\tLoss_G: 1.7984 \tMSE_loss: 2.9735 \tTime: 0.0492\n",
      "Validation \tLoss_D: 1.2491\tLoss_G: 1.2136 \tMSE_loss: 3.8077 \tBest_loss: 3.7034\n",
      "[104/200][141/142]\tLoss_D: 0.9369\tLoss_G: 1.7953 \tMSE_loss: 2.4227 \tTime: 0.0572\n",
      "Validation \tLoss_D: 1.2436\tLoss_G: 1.2561 \tMSE_loss: 3.8195 \tBest_loss: 3.7034\n",
      "[105/200][141/142]\tLoss_D: 0.7255\tLoss_G: 2.0472 \tMSE_loss: 3.5752 \tTime: 0.0515\n",
      "Validation \tLoss_D: 1.2816\tLoss_G: 1.1594 \tMSE_loss: 3.8257 \tBest_loss: 3.7034\n",
      "[106/200][141/142]\tLoss_D: 0.8758\tLoss_G: 1.3353 \tMSE_loss: 3.8233 \tTime: 0.0513\n",
      "Validation \tLoss_D: 1.2254\tLoss_G: 1.2188 \tMSE_loss: 3.8772 \tBest_loss: 3.7034\n",
      "[107/200][141/142]\tLoss_D: 1.0577\tLoss_G: 1.7620 \tMSE_loss: 3.6066 \tTime: 0.0618\n",
      "Validation \tLoss_D: 1.2597\tLoss_G: 1.2177 \tMSE_loss: 3.8510 \tBest_loss: 3.7034\n",
      "[108/200][141/142]\tLoss_D: 0.8851\tLoss_G: 1.7734 \tMSE_loss: 6.8636 \tTime: 0.0485\n",
      "Validation \tLoss_D: 1.2177\tLoss_G: 1.2711 \tMSE_loss: 3.9007 \tBest_loss: 3.7034\n",
      "[109/200][141/142]\tLoss_D: 0.9897\tLoss_G: 1.7832 \tMSE_loss: 3.6628 \tTime: 0.0572\n",
      "Validation \tLoss_D: 1.2658\tLoss_G: 1.1989 \tMSE_loss: 3.8009 \tBest_loss: 3.7034\n",
      "[110/200][141/142]\tLoss_D: 0.8739\tLoss_G: 1.7418 \tMSE_loss: 3.8439 \tTime: 0.0550\n",
      "Validation \tLoss_D: 1.2660\tLoss_G: 1.2068 \tMSE_loss: 3.8285 \tBest_loss: 3.7034\n",
      "[111/200][141/142]\tLoss_D: 0.7771\tLoss_G: 1.7884 \tMSE_loss: 3.7466 \tTime: 0.0631\n",
      "Validation \tLoss_D: 1.2867\tLoss_G: 1.1777 \tMSE_loss: 3.8019 \tBest_loss: 3.7034\n",
      "[112/200][141/142]\tLoss_D: 0.7816\tLoss_G: 1.8049 \tMSE_loss: 2.9409 \tTime: 0.0563\n",
      "Validation \tLoss_D: 1.2655\tLoss_G: 1.2132 \tMSE_loss: 3.8298 \tBest_loss: 3.7034\n",
      "[113/200][141/142]\tLoss_D: 0.9098\tLoss_G: 1.9198 \tMSE_loss: 4.2955 \tTime: 0.0503\n",
      "Validation \tLoss_D: 1.2590\tLoss_G: 1.2349 \tMSE_loss: 3.8559 \tBest_loss: 3.7034\n",
      "[114/200][141/142]\tLoss_D: 0.7933\tLoss_G: 2.0304 \tMSE_loss: 4.4622 \tTime: 0.0538\n",
      "Validation \tLoss_D: 1.2460\tLoss_G: 1.2813 \tMSE_loss: 3.8398 \tBest_loss: 3.7034\n",
      "[115/200][141/142]\tLoss_D: 0.8018\tLoss_G: 1.6791 \tMSE_loss: 3.2430 \tTime: 0.0567\n",
      "Validation \tLoss_D: 1.2900\tLoss_G: 1.1996 \tMSE_loss: 3.8308 \tBest_loss: 3.7034\n",
      "[116/200][141/142]\tLoss_D: 0.7960\tLoss_G: 1.7540 \tMSE_loss: 4.1578 \tTime: 0.0516\n",
      "Validation \tLoss_D: 1.2598\tLoss_G: 1.2541 \tMSE_loss: 3.8786 \tBest_loss: 3.7034\n",
      "[117/200][141/142]\tLoss_D: 0.8376\tLoss_G: 1.7536 \tMSE_loss: 3.0660 \tTime: 0.0502\n",
      "Validation \tLoss_D: 1.3230\tLoss_G: 1.1338 \tMSE_loss: 3.8024 \tBest_loss: 3.7034\n",
      "[118/200][141/142]\tLoss_D: 0.9966\tLoss_G: 2.0648 \tMSE_loss: 6.0148 \tTime: 0.0543\n",
      "Validation \tLoss_D: 1.3061\tLoss_G: 1.1825 \tMSE_loss: 3.8229 \tBest_loss: 3.7034\n",
      "[119/200][141/142]\tLoss_D: 0.8621\tLoss_G: 1.6714 \tMSE_loss: 5.1311 \tTime: 0.0572\n",
      "Validation \tLoss_D: 1.2861\tLoss_G: 1.2440 \tMSE_loss: 3.8504 \tBest_loss: 3.7034\n",
      "[120/200][141/142]\tLoss_D: 0.9016\tLoss_G: 2.3892 \tMSE_loss: 10.6532 \tTime: 0.0505\n",
      "Validation \tLoss_D: 1.3179\tLoss_G: 1.2189 \tMSE_loss: 3.8815 \tBest_loss: 3.7034\n",
      "[121/200][141/142]\tLoss_D: 0.8550\tLoss_G: 2.1650 \tMSE_loss: 4.4818 \tTime: 0.0519\n",
      "Validation \tLoss_D: 1.2853\tLoss_G: 1.2455 \tMSE_loss: 3.8435 \tBest_loss: 3.7034\n",
      "[122/200][141/142]\tLoss_D: 0.8381\tLoss_G: 2.1440 \tMSE_loss: 3.6248 \tTime: 0.0622\n",
      "Validation \tLoss_D: 1.3432\tLoss_G: 1.1816 \tMSE_loss: 3.8225 \tBest_loss: 3.7034\n",
      "[123/200][141/142]\tLoss_D: 0.9141\tLoss_G: 1.8119 \tMSE_loss: 5.2526 \tTime: 0.0551\n",
      "Validation \tLoss_D: 1.2765\tLoss_G: 1.2625 \tMSE_loss: 3.9067 \tBest_loss: 3.7034\n",
      "[124/200][141/142]\tLoss_D: 0.8366\tLoss_G: 1.5641 \tMSE_loss: 4.6045 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.3481\tLoss_G: 1.1756 \tMSE_loss: 3.8313 \tBest_loss: 3.7034\n",
      "[125/200][141/142]\tLoss_D: 0.8051\tLoss_G: 1.6905 \tMSE_loss: 3.1163 \tTime: 0.0617\n",
      "Validation \tLoss_D: 1.2947\tLoss_G: 1.2420 \tMSE_loss: 3.8410 \tBest_loss: 3.7034\n",
      "[126/200][141/142]\tLoss_D: 0.8210\tLoss_G: 1.6779 \tMSE_loss: 4.8009 \tTime: 0.0589\n",
      "Validation \tLoss_D: 1.3158\tLoss_G: 1.1956 \tMSE_loss: 3.8450 \tBest_loss: 3.7034\n",
      "[127/200][141/142]\tLoss_D: 0.5956\tLoss_G: 1.9288 \tMSE_loss: 5.5439 \tTime: 0.0589\n",
      "Validation \tLoss_D: 1.3694\tLoss_G: 1.1384 \tMSE_loss: 3.8115 \tBest_loss: 3.7034\n",
      "[128/200][141/142]\tLoss_D: 1.0901\tLoss_G: 2.1351 \tMSE_loss: 3.9823 \tTime: 0.0496\n",
      "Validation \tLoss_D: 1.3374\tLoss_G: 1.1845 \tMSE_loss: 3.8342 \tBest_loss: 3.7034\n",
      "[129/200][141/142]\tLoss_D: 0.8507\tLoss_G: 1.6802 \tMSE_loss: 3.8549 \tTime: 0.0609\n",
      "Validation \tLoss_D: 1.3292\tLoss_G: 1.2151 \tMSE_loss: 3.8306 \tBest_loss: 3.7034\n",
      "[130/200][141/142]\tLoss_D: 0.8338\tLoss_G: 1.5220 \tMSE_loss: 3.5603 \tTime: 0.0542\n",
      "Validation \tLoss_D: 1.3368\tLoss_G: 1.1675 \tMSE_loss: 3.8749 \tBest_loss: 3.7034\n",
      "[131/200][141/142]\tLoss_D: 1.0169\tLoss_G: 1.4863 \tMSE_loss: 3.4817 \tTime: 0.0548\n",
      "Validation \tLoss_D: 1.3574\tLoss_G: 1.1527 \tMSE_loss: 3.8269 \tBest_loss: 3.7034\n",
      "[132/200][141/142]\tLoss_D: 0.8495\tLoss_G: 2.4502 \tMSE_loss: 3.0256 \tTime: 0.0543\n",
      "Validation \tLoss_D: 1.3255\tLoss_G: 1.2442 \tMSE_loss: 3.8785 \tBest_loss: 3.7034\n",
      "[133/200][141/142]\tLoss_D: 1.0864\tLoss_G: 1.7366 \tMSE_loss: 3.0200 \tTime: 0.0549\n",
      "Validation \tLoss_D: 1.3621\tLoss_G: 1.1531 \tMSE_loss: 3.8241 \tBest_loss: 3.7034\n",
      "[134/200][141/142]\tLoss_D: 0.9127\tLoss_G: 1.8912 \tMSE_loss: 3.3946 \tTime: 0.0588\n",
      "Validation \tLoss_D: 1.3593\tLoss_G: 1.1647 \tMSE_loss: 3.8321 \tBest_loss: 3.7034\n",
      "[135/200][141/142]\tLoss_D: 0.9079\tLoss_G: 1.9741 \tMSE_loss: 5.5400 \tTime: 0.0632\n",
      "Validation \tLoss_D: 1.3481\tLoss_G: 1.1686 \tMSE_loss: 3.9143 \tBest_loss: 3.7034\n",
      "[136/200][141/142]\tLoss_D: 0.6564\tLoss_G: 2.9379 \tMSE_loss: 5.0663 \tTime: 0.0552\n",
      "Validation \tLoss_D: 1.3200\tLoss_G: 1.2190 \tMSE_loss: 3.8514 \tBest_loss: 3.7034\n",
      "[137/200][141/142]\tLoss_D: 1.0268\tLoss_G: 1.6074 \tMSE_loss: 3.4385 \tTime: 0.0583\n",
      "Validation \tLoss_D: 1.3278\tLoss_G: 1.1803 \tMSE_loss: 3.8772 \tBest_loss: 3.7034\n",
      "[138/200][141/142]\tLoss_D: 0.8855\tLoss_G: 1.7592 \tMSE_loss: 3.2747 \tTime: 0.0578\n",
      "Validation \tLoss_D: 1.3596\tLoss_G: 1.1791 \tMSE_loss: 3.8503 \tBest_loss: 3.7034\n",
      "[139/200][141/142]\tLoss_D: 1.0687\tLoss_G: 2.1017 \tMSE_loss: 8.6061 \tTime: 0.0564\n",
      "Validation \tLoss_D: 1.3660\tLoss_G: 1.1627 \tMSE_loss: 3.8434 \tBest_loss: 3.7034\n",
      "[140/200][141/142]\tLoss_D: 0.7967\tLoss_G: 1.8783 \tMSE_loss: 2.8764 \tTime: 0.0529\n",
      "Validation \tLoss_D: 1.3251\tLoss_G: 1.2566 \tMSE_loss: 3.8939 \tBest_loss: 3.7034\n",
      "[141/200][141/142]\tLoss_D: 0.7668\tLoss_G: 2.4947 \tMSE_loss: 5.9512 \tTime: 0.0475\n",
      "Validation \tLoss_D: 1.3372\tLoss_G: 1.1810 \tMSE_loss: 3.8857 \tBest_loss: 3.7034\n",
      "[142/200][141/142]\tLoss_D: 0.9301\tLoss_G: 1.7505 \tMSE_loss: 2.6680 \tTime: 0.0581\n",
      "Validation \tLoss_D: 1.3553\tLoss_G: 1.1688 \tMSE_loss: 3.8855 \tBest_loss: 3.7034\n",
      "[143/200][141/142]\tLoss_D: 0.8664\tLoss_G: 1.7824 \tMSE_loss: 5.5100 \tTime: 0.0619\n",
      "Validation \tLoss_D: 1.3433\tLoss_G: 1.2805 \tMSE_loss: 3.9020 \tBest_loss: 3.7034\n",
      "[144/200][141/142]\tLoss_D: 0.8217\tLoss_G: 2.3219 \tMSE_loss: 3.4956 \tTime: 0.0546\n",
      "Validation \tLoss_D: 1.3968\tLoss_G: 1.1145 \tMSE_loss: 3.8259 \tBest_loss: 3.7034\n",
      "[145/200][141/142]\tLoss_D: 0.8654\tLoss_G: 1.8413 \tMSE_loss: 5.5817 \tTime: 0.0575\n",
      "Validation \tLoss_D: 1.3925\tLoss_G: 1.1791 \tMSE_loss: 3.8194 \tBest_loss: 3.7034\n",
      "[146/200][141/142]\tLoss_D: 0.9282\tLoss_G: 1.6549 \tMSE_loss: 3.3492 \tTime: 0.0578\n",
      "Validation \tLoss_D: 1.3770\tLoss_G: 1.1666 \tMSE_loss: 3.8449 \tBest_loss: 3.7034\n",
      "[147/200][141/142]\tLoss_D: 0.6981\tLoss_G: 1.8949 \tMSE_loss: 3.4994 \tTime: 0.0540\n",
      "Validation \tLoss_D: 1.3725\tLoss_G: 1.2071 \tMSE_loss: 3.8868 \tBest_loss: 3.7034\n",
      "[148/200][141/142]\tLoss_D: 0.9077\tLoss_G: 1.8733 \tMSE_loss: 2.6011 \tTime: 0.0566\n",
      "Validation \tLoss_D: 1.4156\tLoss_G: 1.1495 \tMSE_loss: 3.8595 \tBest_loss: 3.7034\n",
      "[149/200][141/142]\tLoss_D: 0.9037\tLoss_G: 1.9756 \tMSE_loss: 5.1206 \tTime: 0.0545\n",
      "Validation \tLoss_D: 1.3893\tLoss_G: 1.1340 \tMSE_loss: 3.8474 \tBest_loss: 3.7034\n",
      "[150/200][141/142]\tLoss_D: 0.7751\tLoss_G: 1.6359 \tMSE_loss: 3.7319 \tTime: 0.0546\n",
      "Validation \tLoss_D: 1.3703\tLoss_G: 1.1885 \tMSE_loss: 3.8780 \tBest_loss: 3.7034\n",
      "[151/200][141/142]\tLoss_D: 0.8935\tLoss_G: 1.7753 \tMSE_loss: 3.1009 \tTime: 0.0564\n",
      "Validation \tLoss_D: 1.4085\tLoss_G: 1.1708 \tMSE_loss: 3.8824 \tBest_loss: 3.7034\n",
      "[152/200][141/142]\tLoss_D: 0.9077\tLoss_G: 1.8081 \tMSE_loss: 6.9564 \tTime: 0.0505\n",
      "Validation \tLoss_D: 1.3824\tLoss_G: 1.1805 \tMSE_loss: 3.8778 \tBest_loss: 3.7034\n",
      "[153/200][141/142]\tLoss_D: 0.9679\tLoss_G: 1.8307 \tMSE_loss: 3.5644 \tTime: 0.0542\n",
      "Validation \tLoss_D: 1.4275\tLoss_G: 1.0962 \tMSE_loss: 3.8773 \tBest_loss: 3.7034\n",
      "[154/200][141/142]\tLoss_D: 0.8220\tLoss_G: 1.9583 \tMSE_loss: 5.6757 \tTime: 0.0570\n",
      "Validation \tLoss_D: 1.4428\tLoss_G: 1.0765 \tMSE_loss: 3.8214 \tBest_loss: 3.7034\n",
      "[155/200][141/142]\tLoss_D: 0.6983\tLoss_G: 2.0621 \tMSE_loss: 4.9652 \tTime: 0.0523\n",
      "Validation \tLoss_D: 1.3766\tLoss_G: 1.2840 \tMSE_loss: 3.9021 \tBest_loss: 3.7034\n",
      "[156/200][141/142]\tLoss_D: 0.6773\tLoss_G: 2.2590 \tMSE_loss: 3.5463 \tTime: 0.0525\n",
      "Validation \tLoss_D: 1.4162\tLoss_G: 1.1807 \tMSE_loss: 3.8709 \tBest_loss: 3.7034\n",
      "[157/200][141/142]\tLoss_D: 0.6841\tLoss_G: 1.8786 \tMSE_loss: 4.0769 \tTime: 0.0561\n",
      "Validation \tLoss_D: 1.3874\tLoss_G: 1.2032 \tMSE_loss: 3.8886 \tBest_loss: 3.7034\n",
      "[158/200][141/142]\tLoss_D: 0.7479\tLoss_G: 2.0990 \tMSE_loss: 4.0776 \tTime: 0.0536\n",
      "Validation \tLoss_D: 1.3847\tLoss_G: 1.2080 \tMSE_loss: 3.8797 \tBest_loss: 3.7034\n",
      "[159/200][141/142]\tLoss_D: 0.9145\tLoss_G: 1.4531 \tMSE_loss: 3.7238 \tTime: 0.0567\n",
      "Validation \tLoss_D: 1.4168\tLoss_G: 1.1566 \tMSE_loss: 3.8701 \tBest_loss: 3.7034\n",
      "[160/200][141/142]\tLoss_D: 0.7963\tLoss_G: 2.0422 \tMSE_loss: 3.9937 \tTime: 0.0577\n",
      "Validation \tLoss_D: 1.3840\tLoss_G: 1.2276 \tMSE_loss: 3.9085 \tBest_loss: 3.7034\n",
      "[161/200][141/142]\tLoss_D: 0.9984\tLoss_G: 1.9836 \tMSE_loss: 3.6109 \tTime: 0.0619\n",
      "Validation \tLoss_D: 1.4068\tLoss_G: 1.2225 \tMSE_loss: 3.9112 \tBest_loss: 3.7034\n",
      "[162/200][141/142]\tLoss_D: 0.8252\tLoss_G: 2.1410 \tMSE_loss: 5.1698 \tTime: 0.0625\n",
      "Validation \tLoss_D: 1.3960\tLoss_G: 1.2098 \tMSE_loss: 3.8776 \tBest_loss: 3.7034\n",
      "[163/200][141/142]\tLoss_D: 0.8959\tLoss_G: 1.8218 \tMSE_loss: 3.9482 \tTime: 0.0595\n",
      "Validation \tLoss_D: 1.3919\tLoss_G: 1.2308 \tMSE_loss: 3.9311 \tBest_loss: 3.7034\n",
      "[164/200][141/142]\tLoss_D: 0.8912\tLoss_G: 2.1134 \tMSE_loss: 5.9049 \tTime: 0.0597\n",
      "Validation \tLoss_D: 1.4405\tLoss_G: 1.1516 \tMSE_loss: 3.8386 \tBest_loss: 3.7034\n",
      "[165/200][141/142]\tLoss_D: 0.7188\tLoss_G: 2.1526 \tMSE_loss: 4.9034 \tTime: 0.0567\n",
      "Validation \tLoss_D: 1.4145\tLoss_G: 1.1834 \tMSE_loss: 3.8821 \tBest_loss: 3.7034\n",
      "[166/200][141/142]\tLoss_D: 1.1327\tLoss_G: 1.9765 \tMSE_loss: 3.7799 \tTime: 0.0507\n",
      "Validation \tLoss_D: 1.4257\tLoss_G: 1.1531 \tMSE_loss: 3.8817 \tBest_loss: 3.7034\n",
      "[167/200][141/142]\tLoss_D: 0.7850\tLoss_G: 1.8780 \tMSE_loss: 3.2001 \tTime: 0.0578\n",
      "Validation \tLoss_D: 1.4565\tLoss_G: 1.1601 \tMSE_loss: 3.8925 \tBest_loss: 3.7034\n",
      "[168/200][141/142]\tLoss_D: 0.6123\tLoss_G: 2.0462 \tMSE_loss: 4.8046 \tTime: 0.0532\n",
      "Validation \tLoss_D: 1.4289\tLoss_G: 1.1675 \tMSE_loss: 3.8771 \tBest_loss: 3.7034\n",
      "[169/200][141/142]\tLoss_D: 0.9991\tLoss_G: 1.5027 \tMSE_loss: 3.7104 \tTime: 0.0506\n",
      "Validation \tLoss_D: 1.4150\tLoss_G: 1.1873 \tMSE_loss: 3.8898 \tBest_loss: 3.7034\n",
      "[170/200][141/142]\tLoss_D: 0.7596\tLoss_G: 2.1070 \tMSE_loss: 5.0349 \tTime: 0.0540\n",
      "Validation \tLoss_D: 1.4478\tLoss_G: 1.1351 \tMSE_loss: 3.8712 \tBest_loss: 3.7034\n",
      "[171/200][141/142]\tLoss_D: 0.7759\tLoss_G: 1.5406 \tMSE_loss: 3.8101 \tTime: 0.0573\n",
      "Validation \tLoss_D: 1.4274\tLoss_G: 1.1920 \tMSE_loss: 3.8958 \tBest_loss: 3.7034\n",
      "[172/200][141/142]\tLoss_D: 0.9105\tLoss_G: 2.0990 \tMSE_loss: 3.0771 \tTime: 0.0494\n",
      "Validation \tLoss_D: 1.4270\tLoss_G: 1.1990 \tMSE_loss: 3.8749 \tBest_loss: 3.7034\n",
      "[173/200][141/142]\tLoss_D: 0.8270\tLoss_G: 2.0699 \tMSE_loss: 4.0986 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.3795\tLoss_G: 1.3113 \tMSE_loss: 3.9080 \tBest_loss: 3.7034\n",
      "[174/200][141/142]\tLoss_D: 0.9518\tLoss_G: 1.8492 \tMSE_loss: 3.3675 \tTime: 0.0509\n",
      "Validation \tLoss_D: 1.4513\tLoss_G: 1.1797 \tMSE_loss: 3.9005 \tBest_loss: 3.7034\n",
      "[175/200][141/142]\tLoss_D: 0.8797\tLoss_G: 2.0339 \tMSE_loss: 5.2193 \tTime: 0.0551\n",
      "Validation \tLoss_D: 1.4531\tLoss_G: 1.1773 \tMSE_loss: 3.8869 \tBest_loss: 3.7034\n",
      "[176/200][141/142]\tLoss_D: 0.7536\tLoss_G: 2.2005 \tMSE_loss: 2.8710 \tTime: 0.0527\n",
      "Validation \tLoss_D: 1.4501\tLoss_G: 1.1381 \tMSE_loss: 3.8907 \tBest_loss: 3.7034\n",
      "[177/200][141/142]\tLoss_D: 0.8499\tLoss_G: 1.9719 \tMSE_loss: 3.2424 \tTime: 0.0526\n",
      "Validation \tLoss_D: 1.4544\tLoss_G: 1.1465 \tMSE_loss: 3.9011 \tBest_loss: 3.7034\n",
      "[178/200][141/142]\tLoss_D: 0.8237\tLoss_G: 1.8880 \tMSE_loss: 3.9736 \tTime: 0.0535\n",
      "Validation \tLoss_D: 1.3991\tLoss_G: 1.3033 \tMSE_loss: 3.9185 \tBest_loss: 3.7034\n",
      "[179/200][141/142]\tLoss_D: 0.9766\tLoss_G: 1.9737 \tMSE_loss: 3.6921 \tTime: 0.0503\n",
      "Validation \tLoss_D: 1.4397\tLoss_G: 1.2067 \tMSE_loss: 3.8915 \tBest_loss: 3.7034\n",
      "[180/200][141/142]\tLoss_D: 0.7999\tLoss_G: 1.6305 \tMSE_loss: 2.1445 \tTime: 0.0636\n",
      "Validation \tLoss_D: 1.4291\tLoss_G: 1.1873 \tMSE_loss: 3.8997 \tBest_loss: 3.7034\n",
      "[181/200][141/142]\tLoss_D: 0.8687\tLoss_G: 1.4952 \tMSE_loss: 4.4496 \tTime: 0.0510\n",
      "Validation \tLoss_D: 1.4836\tLoss_G: 1.1040 \tMSE_loss: 3.8928 \tBest_loss: 3.7034\n",
      "[182/200][141/142]\tLoss_D: 0.8651\tLoss_G: 2.2921 \tMSE_loss: 4.4085 \tTime: 0.0568\n",
      "Validation \tLoss_D: 1.4816\tLoss_G: 1.1193 \tMSE_loss: 3.8890 \tBest_loss: 3.7034\n",
      "[183/200][141/142]\tLoss_D: 0.8072\tLoss_G: 1.9515 \tMSE_loss: 3.5949 \tTime: 0.0517\n",
      "Validation \tLoss_D: 1.4517\tLoss_G: 1.2090 \tMSE_loss: 3.9139 \tBest_loss: 3.7034\n",
      "[184/200][141/142]\tLoss_D: 0.7451\tLoss_G: 2.3227 \tMSE_loss: 4.2602 \tTime: 0.0643\n",
      "Validation \tLoss_D: 1.4806\tLoss_G: 1.1567 \tMSE_loss: 3.8669 \tBest_loss: 3.7034\n",
      "[185/200][141/142]\tLoss_D: 0.7510\tLoss_G: 2.1235 \tMSE_loss: 3.5851 \tTime: 0.0529\n",
      "Validation \tLoss_D: 1.5187\tLoss_G: 1.1022 \tMSE_loss: 3.8670 \tBest_loss: 3.7034\n",
      "[186/200][141/142]\tLoss_D: 0.9070\tLoss_G: 2.6737 \tMSE_loss: 3.7707 \tTime: 0.0505\n",
      "Validation \tLoss_D: 1.4574\tLoss_G: 1.1744 \tMSE_loss: 3.9053 \tBest_loss: 3.7034\n",
      "[187/200][141/142]\tLoss_D: 0.7444\tLoss_G: 2.2911 \tMSE_loss: 4.3227 \tTime: 0.0572\n",
      "Validation \tLoss_D: 1.4681\tLoss_G: 1.1902 \tMSE_loss: 3.9295 \tBest_loss: 3.7034\n",
      "[188/200][141/142]\tLoss_D: 0.6580\tLoss_G: 2.2964 \tMSE_loss: 3.6336 \tTime: 0.0574\n",
      "Validation \tLoss_D: 1.5159\tLoss_G: 1.1508 \tMSE_loss: 3.8837 \tBest_loss: 3.7034\n",
      "[189/200][141/142]\tLoss_D: 0.8838\tLoss_G: 1.7853 \tMSE_loss: 5.9557 \tTime: 0.0551\n",
      "Validation \tLoss_D: 1.4841\tLoss_G: 1.1190 \tMSE_loss: 3.8810 \tBest_loss: 3.7034\n",
      "[190/200][141/142]\tLoss_D: 0.9175\tLoss_G: 2.3753 \tMSE_loss: 3.1911 \tTime: 0.0573\n",
      "Validation \tLoss_D: 1.4603\tLoss_G: 1.2032 \tMSE_loss: 3.9255 \tBest_loss: 3.7034\n",
      "[191/200][141/142]\tLoss_D: 0.9060\tLoss_G: 2.0121 \tMSE_loss: 4.3281 \tTime: 0.0565\n",
      "Validation \tLoss_D: 1.5172\tLoss_G: 1.1102 \tMSE_loss: 3.8416 \tBest_loss: 3.7034\n",
      "[192/200][141/142]\tLoss_D: 0.7822\tLoss_G: 2.2747 \tMSE_loss: 3.9536 \tTime: 0.0595\n",
      "Validation \tLoss_D: 1.5235\tLoss_G: 1.1071 \tMSE_loss: 3.8716 \tBest_loss: 3.7034\n",
      "[193/200][141/142]\tLoss_D: 1.0516\tLoss_G: 1.9137 \tMSE_loss: 3.7544 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.5461\tLoss_G: 1.0613 \tMSE_loss: 3.8477 \tBest_loss: 3.7034\n",
      "[194/200][141/142]\tLoss_D: 0.7404\tLoss_G: 1.7795 \tMSE_loss: 4.6685 \tTime: 0.0517\n",
      "Validation \tLoss_D: 1.5214\tLoss_G: 1.0842 \tMSE_loss: 3.8831 \tBest_loss: 3.7034\n",
      "[195/200][141/142]\tLoss_D: 0.8207\tLoss_G: 1.8960 \tMSE_loss: 3.1421 \tTime: 0.0617\n",
      "Validation \tLoss_D: 1.5408\tLoss_G: 1.1213 \tMSE_loss: 3.8915 \tBest_loss: 3.7034\n",
      "[196/200][141/142]\tLoss_D: 0.7066\tLoss_G: 2.5005 \tMSE_loss: 4.0713 \tTime: 0.0557\n",
      "Validation \tLoss_D: 1.5430\tLoss_G: 1.0636 \tMSE_loss: 3.8963 \tBest_loss: 3.7034\n",
      "[197/200][141/142]\tLoss_D: 0.7500\tLoss_G: 2.1706 \tMSE_loss: 2.7013 \tTime: 0.0596\n",
      "Validation \tLoss_D: 1.5148\tLoss_G: 1.1289 \tMSE_loss: 3.9264 \tBest_loss: 3.7034\n",
      "[198/200][141/142]\tLoss_D: 0.8801\tLoss_G: 1.9147 \tMSE_loss: 3.4101 \tTime: 0.0537\n",
      "Validation \tLoss_D: 1.5016\tLoss_G: 1.1386 \tMSE_loss: 3.9111 \tBest_loss: 3.7034\n",
      "[199/200][141/142]\tLoss_D: 0.8993\tLoss_G: 2.0681 \tMSE_loss: 4.6755 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.4976\tLoss_G: 1.1562 \tMSE_loss: 3.9232 \tBest_loss: 3.7034\n"
     ]
    }
   ],
   "source": [
    "result = train_GAN(generator, discriminator, generator_optimizer, discriminator_optimizer, loss_fn, data_gen_train, data_gen_test, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734be51a-a19e-4fa9-be9b-b0a6df2e08a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
