{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9715a90-f39c-4964-9193-5ee44431250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import kan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77d11873-35d1-466e-af7e-424c5607439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/S&P500.csv\n",
      "shape =  (5031, 7)\n"
     ]
    }
   ],
   "source": [
    "data_names = [\"S&P500\",\"SSE\",\"IBM\",\"MSFT\",\"PAICC\"]\n",
    "data_name = data_names[0]\n",
    "data_path=\"./datasets/S&P500.csv\"\n",
    "print(data_path)\n",
    "dataframe = pd.read_csv(data_path)\n",
    "dataframe.describe()\n",
    "print(\"shape = \",dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a805dde-5d75-41f4-8fe8-8796e074b81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999-01-11</td>\n",
       "      <td>1275.089966</td>\n",
       "      <td>1276.219971</td>\n",
       "      <td>1253.339966</td>\n",
       "      <td>1263.880005</td>\n",
       "      <td>1263.880005</td>\n",
       "      <td>818000000</td>\n",
       "      <td>1258.007983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1999-01-12</td>\n",
       "      <td>1263.880005</td>\n",
       "      <td>1264.449951</td>\n",
       "      <td>1238.290039</td>\n",
       "      <td>1239.510010</td>\n",
       "      <td>1239.510010</td>\n",
       "      <td>800200000</td>\n",
       "      <td>1265.163989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1999-01-13</td>\n",
       "      <td>1239.510010</td>\n",
       "      <td>1247.750000</td>\n",
       "      <td>1205.459961</td>\n",
       "      <td>1234.400024</td>\n",
       "      <td>1234.400024</td>\n",
       "      <td>931500000</td>\n",
       "      <td>1264.109985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1999-01-14</td>\n",
       "      <td>1234.400024</td>\n",
       "      <td>1236.810059</td>\n",
       "      <td>1209.540039</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>797200000</td>\n",
       "      <td>1256.521997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1999-01-15</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>1243.260010</td>\n",
       "      <td>1212.189941</td>\n",
       "      <td>1243.260010</td>\n",
       "      <td>1243.260010</td>\n",
       "      <td>798100000</td>\n",
       "      <td>1245.013989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         Open         High          Low        Close  \\\n",
       "5  1999-01-11  1275.089966  1276.219971  1253.339966  1263.880005   \n",
       "6  1999-01-12  1263.880005  1264.449951  1238.290039  1239.510010   \n",
       "7  1999-01-13  1239.510010  1247.750000  1205.459961  1234.400024   \n",
       "8  1999-01-14  1234.400024  1236.810059  1209.540039  1212.189941   \n",
       "9  1999-01-15  1212.189941  1243.260010  1212.189941  1243.260010   \n",
       "\n",
       "     Adj Close     Volume           Ma  \n",
       "5  1263.880005  818000000  1258.007983  \n",
       "6  1239.510010  800200000  1265.163989  \n",
       "7  1234.400024  931500000  1264.109985  \n",
       "8  1212.189941  797200000  1256.521997  \n",
       "9  1243.260010  798100000  1245.013989  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_Ma(dataframe):\n",
    "  Ma_window=5\n",
    "  for i in range(0,dataframe.shape[0]-Ma_window):\n",
    "    dataframe.loc[dataframe.index[i+Ma_window],'Ma'] = np.round(((dataframe.iloc[i,4]+ dataframe.iloc[i+1,4] +dataframe.iloc[i+2,4] + dataframe.iloc[i+3,4]+ dataframe.iloc[i+4,4])/5),6)\n",
    "  return dataframe[5:-5]\n",
    "\n",
    "dataframe=add_Ma(dataframe)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7331a555-0b19-4c1e-8b75-f2323f80746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class GeneratorModel(nn.Module):\n",
    "    def __init__(self, n_sequence, n_features):\n",
    "        super(GeneratorModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=n_features, hidden_size=10, batch_first=True)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(10)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.3)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(input_size=10, hidden_size=10, batch_first=True)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(10)  \n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.output_dense = nn.Linear(10, n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.batch_norm1(x.permute(0, 2, 1)).permute(0, 2, 1) \n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        _, (x, _) = self.lstm2(x)\n",
    "        x=x.permute(1, 0, 2)\n",
    "        x = self.batch_norm2(x.permute(0, 2, 1)).permute(0, 2, 1)  \n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.output_dense(x)\n",
    "        x = self.leaky_relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "n_sequence = 5  # Sequence length\n",
    "n_features = 7   # Number of features\n",
    "\n",
    "\n",
    "class KAN_discriminator(torch.nn.Module):\n",
    "    def __init__(self, n_sequence, n_features):\n",
    "        super(KAN_discriminator, self).__init__()\n",
    "        input_dim = (n_sequence + 1) * n_features\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            kan.KAN([42,64,10,1]),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "530f7259-5fdf-4575-ae9f-374cb66617e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=8)\n",
    "class Standarized_TimeseriesGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets, length, batch_size=1, stride=1):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.length = length\n",
    "        self.batch_size = batch_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        samples = [self.data[i:i+self.length] for i in range(index, len(self.data)-self.length, self.stride)]\n",
    "        targets = [self.targets[i+self.length] for i in range(index, len(self.data)-self.length, self.stride)]\n",
    "        # Pack sequences into tensor\n",
    "        samples = torch.tensor(samples[0])\n",
    "        targets = torch.tensor(targets[0])\n",
    "        samples= samples.to(torch.float64)\n",
    "        targets= targets.to(torch.float64)\n",
    "        # shape : (n_batch, n_sequence, n_features)\n",
    "        mean = samples.mean(dim=0)\n",
    "        std = samples.std(dim=0,correction=0)\n",
    "        samples = (samples - mean)/std  # standardize along each feature\n",
    "\n",
    "\n",
    "        # targets = (targets - mean[..., 3])/std[..., 3]  # The close value is our target\n",
    "        targets = (targets - mean)/std  # The close value is our target\n",
    "        return samples, targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b687e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sequence = 5\n",
    "n_features = 7\n",
    "n_batch = 32\n",
    "\n",
    "def get_gen_train_test(dataframe):\n",
    "  data = dataframe.drop(columns='Date').to_numpy()\n",
    "  #targets = data[:,3, None] #add none to have same number of dimensions as data\n",
    "  targets = data\n",
    "  n_samples = data.shape[0]\n",
    "  train_test_split=int(n_samples*0.9)\n",
    "  train_data = data[:train_test_split]\n",
    "  test_data = data[train_test_split:]\n",
    "  train_target = targets[:train_test_split]\n",
    "  test_target = targets[train_test_split:]\n",
    "  data_train = Standarized_TimeseriesGenerator(train_data, train_target,\n",
    "                                length=n_sequence, \n",
    "                                stride=1)\n",
    "  data_test = Standarized_TimeseriesGenerator(test_data, test_target,\n",
    "                                length=n_sequence, \n",
    "                                stride=1)\n",
    "  train_loader = DataLoader(data_train, batch_size=n_batch, shuffle=True)\n",
    "  test_loader = DataLoader(data_test, batch_size=n_batch, shuffle=False)\n",
    "  return train_loader, test_loader\n",
    "\n",
    "data_gen_train, data_gen_test = get_gen_train_test(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2ab17e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/400][141/142]\tLoss_D: 1.3820\tLoss_G: 0.7551 \tMSE_loss: 5.7827 \tTime: 0.0549\n",
      "Validation \tLoss_D: 1.3729\tLoss_G: 0.7511 \tMSE_loss: 5.5178 \tBest_loss: 5.5178\n",
      "[1/400][141/142]\tLoss_D: 1.3673\tLoss_G: 0.7422 \tMSE_loss: 4.5829 \tTime: 0.0564\n",
      "Validation \tLoss_D: 1.3494\tLoss_G: 0.7552 \tMSE_loss: 5.4901 \tBest_loss: 5.4901\n",
      "[2/400][141/142]\tLoss_D: 1.3542\tLoss_G: 0.7559 \tMSE_loss: 5.2410 \tTime: 0.0516\n",
      "Validation \tLoss_D: 1.3200\tLoss_G: 0.7617 \tMSE_loss: 5.3920 \tBest_loss: 5.3920\n",
      "[3/400][141/142]\tLoss_D: 1.2856\tLoss_G: 0.7585 \tMSE_loss: 3.8800 \tTime: 0.0625\n",
      "Validation \tLoss_D: 1.2818\tLoss_G: 0.7739 \tMSE_loss: 5.3468 \tBest_loss: 5.3468\n",
      "[4/400][141/142]\tLoss_D: 1.2270\tLoss_G: 0.7760 \tMSE_loss: 4.2718 \tTime: 0.0553\n",
      "Validation \tLoss_D: 1.2383\tLoss_G: 0.7915 \tMSE_loss: 5.2938 \tBest_loss: 5.2938\n",
      "[5/400][141/142]\tLoss_D: 1.3204\tLoss_G: 0.7857 \tMSE_loss: 4.7358 \tTime: 0.0566\n",
      "Validation \tLoss_D: 1.2021\tLoss_G: 0.8069 \tMSE_loss: 5.1635 \tBest_loss: 5.1635\n",
      "[6/400][141/142]\tLoss_D: 1.1739\tLoss_G: 0.8534 \tMSE_loss: 4.9274 \tTime: 0.0540\n",
      "Validation \tLoss_D: 1.1548\tLoss_G: 0.8480 \tMSE_loss: 5.1479 \tBest_loss: 5.1479\n",
      "[7/400][141/142]\tLoss_D: 1.2233\tLoss_G: 0.8503 \tMSE_loss: 6.2240 \tTime: 0.0540\n",
      "Validation \tLoss_D: 1.1273\tLoss_G: 0.8740 \tMSE_loss: 5.0829 \tBest_loss: 5.0829\n",
      "[8/400][141/142]\tLoss_D: 1.1956\tLoss_G: 0.8646 \tMSE_loss: 4.4300 \tTime: 0.0591\n",
      "Validation \tLoss_D: 1.0965\tLoss_G: 0.9104 \tMSE_loss: 5.0677 \tBest_loss: 5.0677\n",
      "[9/400][141/142]\tLoss_D: 1.2400\tLoss_G: 0.8352 \tMSE_loss: 3.7065 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.1014\tLoss_G: 0.9062 \tMSE_loss: 5.0050 \tBest_loss: 5.0050\n",
      "[10/400][141/142]\tLoss_D: 1.1754\tLoss_G: 0.9605 \tMSE_loss: 4.0561 \tTime: 0.0640\n",
      "Validation \tLoss_D: 1.0559\tLoss_G: 0.9753 \tMSE_loss: 5.0044 \tBest_loss: 5.0044\n",
      "[11/400][141/142]\tLoss_D: 1.2344\tLoss_G: 1.0373 \tMSE_loss: 4.0021 \tTime: 0.0565\n",
      "Validation \tLoss_D: 1.0756\tLoss_G: 0.9574 \tMSE_loss: 4.9547 \tBest_loss: 4.9547\n",
      "[12/400][141/142]\tLoss_D: 1.0663\tLoss_G: 1.0478 \tMSE_loss: 4.0849 \tTime: 0.0515\n",
      "Validation \tLoss_D: 1.0527\tLoss_G: 1.0004 \tMSE_loss: 4.9257 \tBest_loss: 4.9257\n",
      "[13/400][141/142]\tLoss_D: 1.1543\tLoss_G: 0.9145 \tMSE_loss: 3.1234 \tTime: 0.0537\n",
      "Validation \tLoss_D: 1.0479\tLoss_G: 0.9945 \tMSE_loss: 4.8989 \tBest_loss: 4.8989\n",
      "[14/400][141/142]\tLoss_D: 1.0068\tLoss_G: 1.0602 \tMSE_loss: 4.7064 \tTime: 0.0636\n",
      "Validation \tLoss_D: 1.0282\tLoss_G: 1.0192 \tMSE_loss: 4.8962 \tBest_loss: 4.8962\n",
      "[15/400][141/142]\tLoss_D: 1.0001\tLoss_G: 1.1036 \tMSE_loss: 6.4344 \tTime: 0.0586\n",
      "Validation \tLoss_D: 0.9973\tLoss_G: 1.0703 \tMSE_loss: 4.8384 \tBest_loss: 4.8384\n",
      "[16/400][141/142]\tLoss_D: 1.1559\tLoss_G: 1.0444 \tMSE_loss: 6.3705 \tTime: 0.0545\n",
      "Validation \tLoss_D: 0.9896\tLoss_G: 1.0716 \tMSE_loss: 4.8150 \tBest_loss: 4.8150\n",
      "[17/400][141/142]\tLoss_D: 0.8940\tLoss_G: 1.2066 \tMSE_loss: 7.5539 \tTime: 0.0553\n",
      "Validation \tLoss_D: 0.9270\tLoss_G: 1.1618 \tMSE_loss: 4.7726 \tBest_loss: 4.7726\n",
      "[18/400][141/142]\tLoss_D: 0.9823\tLoss_G: 1.1992 \tMSE_loss: 4.2338 \tTime: 0.0573\n",
      "Validation \tLoss_D: 0.9154\tLoss_G: 1.1720 \tMSE_loss: 4.7478 \tBest_loss: 4.7478\n",
      "[19/400][141/142]\tLoss_D: 1.0045\tLoss_G: 1.0778 \tMSE_loss: 4.6071 \tTime: 0.0540\n",
      "Validation \tLoss_D: 0.9174\tLoss_G: 1.1592 \tMSE_loss: 4.7503 \tBest_loss: 4.7478\n",
      "[20/400][141/142]\tLoss_D: 0.8938\tLoss_G: 1.2686 \tMSE_loss: 3.9485 \tTime: 0.0496\n",
      "Validation \tLoss_D: 0.8735\tLoss_G: 1.2156 \tMSE_loss: 4.6982 \tBest_loss: 4.6982\n",
      "[21/400][141/142]\tLoss_D: 0.8448\tLoss_G: 1.1474 \tMSE_loss: 5.4665 \tTime: 0.0589\n",
      "Validation \tLoss_D: 0.8346\tLoss_G: 1.2731 \tMSE_loss: 4.6365 \tBest_loss: 4.6365\n",
      "[22/400][141/142]\tLoss_D: 0.8736\tLoss_G: 1.3075 \tMSE_loss: 11.5175 \tTime: 0.0523\n",
      "Validation \tLoss_D: 0.8146\tLoss_G: 1.2990 \tMSE_loss: 4.6421 \tBest_loss: 4.6365\n",
      "[23/400][141/142]\tLoss_D: 0.8419\tLoss_G: 1.1669 \tMSE_loss: 6.1334 \tTime: 0.0581\n",
      "Validation \tLoss_D: 0.7803\tLoss_G: 1.3630 \tMSE_loss: 4.5910 \tBest_loss: 4.5910\n",
      "[24/400][141/142]\tLoss_D: 0.7331\tLoss_G: 1.2925 \tMSE_loss: 3.7883 \tTime: 0.0557\n",
      "Validation \tLoss_D: 0.7719\tLoss_G: 1.3780 \tMSE_loss: 4.5952 \tBest_loss: 4.5910\n",
      "[25/400][141/142]\tLoss_D: 0.7681\tLoss_G: 1.3875 \tMSE_loss: 7.2580 \tTime: 0.0564\n",
      "Validation \tLoss_D: 0.7494\tLoss_G: 1.3910 \tMSE_loss: 4.6042 \tBest_loss: 4.5910\n",
      "[26/400][141/142]\tLoss_D: 0.7948\tLoss_G: 1.2764 \tMSE_loss: 2.0897 \tTime: 0.0599\n",
      "Validation \tLoss_D: 0.7093\tLoss_G: 1.4853 \tMSE_loss: 4.5254 \tBest_loss: 4.5254\n",
      "[27/400][141/142]\tLoss_D: 0.7439\tLoss_G: 1.4716 \tMSE_loss: 3.8305 \tTime: 0.0574\n",
      "Validation \tLoss_D: 0.7210\tLoss_G: 1.4554 \tMSE_loss: 4.5523 \tBest_loss: 4.5254\n",
      "[28/400][141/142]\tLoss_D: 0.7312\tLoss_G: 1.4489 \tMSE_loss: 3.7099 \tTime: 0.0562\n",
      "Validation \tLoss_D: 0.7142\tLoss_G: 1.5076 \tMSE_loss: 4.5601 \tBest_loss: 4.5254\n",
      "[29/400][141/142]\tLoss_D: 0.7199\tLoss_G: 1.4136 \tMSE_loss: 3.1754 \tTime: 0.0610\n",
      "Validation \tLoss_D: 0.6906\tLoss_G: 1.5512 \tMSE_loss: 4.4634 \tBest_loss: 4.4634\n",
      "[30/400][141/142]\tLoss_D: 0.6635\tLoss_G: 1.5838 \tMSE_loss: 6.2552 \tTime: 0.0546\n",
      "Validation \tLoss_D: 0.6957\tLoss_G: 1.5256 \tMSE_loss: 4.4927 \tBest_loss: 4.4634\n",
      "[31/400][141/142]\tLoss_D: 0.8650\tLoss_G: 1.4625 \tMSE_loss: 4.2168 \tTime: 0.0624\n",
      "Validation \tLoss_D: 0.6900\tLoss_G: 1.5394 \tMSE_loss: 4.4589 \tBest_loss: 4.4589\n",
      "[32/400][141/142]\tLoss_D: 0.6534\tLoss_G: 1.4209 \tMSE_loss: 3.7016 \tTime: 0.0578\n",
      "Validation \tLoss_D: 0.6844\tLoss_G: 1.5964 \tMSE_loss: 4.5372 \tBest_loss: 4.4589\n",
      "[33/400][141/142]\tLoss_D: 0.7172\tLoss_G: 1.6915 \tMSE_loss: 4.6581 \tTime: 0.0420\n",
      "Validation \tLoss_D: 0.6703\tLoss_G: 1.6125 \tMSE_loss: 4.4775 \tBest_loss: 4.4589\n",
      "[34/400][141/142]\tLoss_D: 0.7391\tLoss_G: 1.6829 \tMSE_loss: 4.2920 \tTime: 0.0567\n",
      "Validation \tLoss_D: 0.6583\tLoss_G: 1.6379 \tMSE_loss: 4.5290 \tBest_loss: 4.4589\n",
      "[35/400][141/142]\tLoss_D: 0.5446\tLoss_G: 1.7989 \tMSE_loss: 2.9253 \tTime: 0.0528\n",
      "Validation \tLoss_D: 0.6603\tLoss_G: 1.6287 \tMSE_loss: 4.5044 \tBest_loss: 4.4589\n",
      "[36/400][141/142]\tLoss_D: 0.5382\tLoss_G: 1.6329 \tMSE_loss: 4.3196 \tTime: 0.0595\n",
      "Validation \tLoss_D: 0.6468\tLoss_G: 1.6749 \tMSE_loss: 4.5087 \tBest_loss: 4.4589\n",
      "[37/400][141/142]\tLoss_D: 0.7127\tLoss_G: 1.6303 \tMSE_loss: 4.3529 \tTime: 0.0556\n",
      "Validation \tLoss_D: 0.6282\tLoss_G: 1.7000 \tMSE_loss: 4.5178 \tBest_loss: 4.4589\n",
      "[38/400][141/142]\tLoss_D: 0.7453\tLoss_G: 1.4994 \tMSE_loss: 3.1728 \tTime: 0.0574\n",
      "Validation \tLoss_D: 0.6237\tLoss_G: 1.7019 \tMSE_loss: 4.5492 \tBest_loss: 4.4589\n",
      "[39/400][141/142]\tLoss_D: 0.6482\tLoss_G: 1.5558 \tMSE_loss: 4.5284 \tTime: 0.0569\n",
      "Validation \tLoss_D: 0.6282\tLoss_G: 1.6654 \tMSE_loss: 4.4419 \tBest_loss: 4.4419\n",
      "[40/400][141/142]\tLoss_D: 0.7624\tLoss_G: 1.7887 \tMSE_loss: 3.2247 \tTime: 0.0529\n",
      "Validation \tLoss_D: 0.6127\tLoss_G: 1.6868 \tMSE_loss: 4.4652 \tBest_loss: 4.4419\n",
      "[41/400][141/142]\tLoss_D: 0.6668\tLoss_G: 1.9328 \tMSE_loss: 4.4140 \tTime: 0.0523\n",
      "Validation \tLoss_D: 0.5958\tLoss_G: 1.7938 \tMSE_loss: 4.5233 \tBest_loss: 4.4419\n",
      "[42/400][141/142]\tLoss_D: 0.5956\tLoss_G: 1.8407 \tMSE_loss: 3.4796 \tTime: 0.0577\n",
      "Validation \tLoss_D: 0.5871\tLoss_G: 1.8277 \tMSE_loss: 4.5294 \tBest_loss: 4.4419\n",
      "[43/400][141/142]\tLoss_D: 0.5481\tLoss_G: 1.8465 \tMSE_loss: 3.6214 \tTime: 0.0533\n",
      "Validation \tLoss_D: 0.5835\tLoss_G: 1.8026 \tMSE_loss: 4.5770 \tBest_loss: 4.4419\n",
      "[44/400][141/142]\tLoss_D: 0.6744\tLoss_G: 1.5509 \tMSE_loss: 4.4759 \tTime: 0.0586\n",
      "Validation \tLoss_D: 0.5803\tLoss_G: 1.7877 \tMSE_loss: 4.4688 \tBest_loss: 4.4419\n",
      "[45/400][141/142]\tLoss_D: 0.5690\tLoss_G: 1.6732 \tMSE_loss: 3.4523 \tTime: 0.0545\n",
      "Validation \tLoss_D: 0.5665\tLoss_G: 1.8275 \tMSE_loss: 4.5108 \tBest_loss: 4.4419\n",
      "[46/400][141/142]\tLoss_D: 0.5970\tLoss_G: 1.7925 \tMSE_loss: 3.8406 \tTime: 0.0546\n",
      "Validation \tLoss_D: 0.5746\tLoss_G: 1.8330 \tMSE_loss: 4.4268 \tBest_loss: 4.4268\n",
      "[47/400][141/142]\tLoss_D: 0.6047\tLoss_G: 1.5225 \tMSE_loss: 4.8611 \tTime: 0.0655\n",
      "Validation \tLoss_D: 0.5613\tLoss_G: 1.8462 \tMSE_loss: 4.4283 \tBest_loss: 4.4268\n",
      "[48/400][141/142]\tLoss_D: 0.6292\tLoss_G: 1.9259 \tMSE_loss: 4.5709 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.5517\tLoss_G: 1.8885 \tMSE_loss: 4.4827 \tBest_loss: 4.4268\n",
      "[49/400][141/142]\tLoss_D: 0.5580\tLoss_G: 1.9031 \tMSE_loss: 4.6650 \tTime: 0.0563\n",
      "Validation \tLoss_D: 0.5549\tLoss_G: 1.8957 \tMSE_loss: 4.4183 \tBest_loss: 4.4183\n",
      "[50/400][141/142]\tLoss_D: 0.4796\tLoss_G: 1.8137 \tMSE_loss: 5.6421 \tTime: 0.0567\n",
      "Validation \tLoss_D: 0.5421\tLoss_G: 1.8913 \tMSE_loss: 4.4641 \tBest_loss: 4.4183\n",
      "[51/400][141/142]\tLoss_D: 0.6213\tLoss_G: 2.0507 \tMSE_loss: 6.2379 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.5328\tLoss_G: 1.9248 \tMSE_loss: 4.4616 \tBest_loss: 4.4183\n",
      "[52/400][141/142]\tLoss_D: 0.5734\tLoss_G: 1.7632 \tMSE_loss: 8.4514 \tTime: 0.0474\n",
      "Validation \tLoss_D: 0.5327\tLoss_G: 1.9208 \tMSE_loss: 4.4175 \tBest_loss: 4.4175\n",
      "[53/400][141/142]\tLoss_D: 0.5431\tLoss_G: 1.7315 \tMSE_loss: 5.9308 \tTime: 0.0480\n",
      "Validation \tLoss_D: 0.5242\tLoss_G: 1.9702 \tMSE_loss: 4.4159 \tBest_loss: 4.4159\n",
      "[54/400][141/142]\tLoss_D: 0.5621\tLoss_G: 2.0189 \tMSE_loss: 5.2148 \tTime: 0.0537\n",
      "Validation \tLoss_D: 0.5193\tLoss_G: 2.0305 \tMSE_loss: 4.4774 \tBest_loss: 4.4159\n",
      "[55/400][141/142]\tLoss_D: 0.5497\tLoss_G: 2.0265 \tMSE_loss: 3.8793 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.5235\tLoss_G: 1.9155 \tMSE_loss: 4.4010 \tBest_loss: 4.4010\n",
      "[56/400][141/142]\tLoss_D: 0.5575\tLoss_G: 1.9442 \tMSE_loss: 2.6943 \tTime: 0.0500\n",
      "Validation \tLoss_D: 0.5083\tLoss_G: 1.9835 \tMSE_loss: 4.3583 \tBest_loss: 4.3583\n",
      "[57/400][141/142]\tLoss_D: 0.6239\tLoss_G: 2.3009 \tMSE_loss: 4.6735 \tTime: 0.0615\n",
      "Validation \tLoss_D: 0.4981\tLoss_G: 2.0747 \tMSE_loss: 4.5047 \tBest_loss: 4.3583\n",
      "[58/400][141/142]\tLoss_D: 0.5390\tLoss_G: 1.9154 \tMSE_loss: 5.9131 \tTime: 0.0541\n",
      "Validation \tLoss_D: 0.5050\tLoss_G: 2.0132 \tMSE_loss: 4.3757 \tBest_loss: 4.3583\n",
      "[59/400][141/142]\tLoss_D: 0.6147\tLoss_G: 2.0267 \tMSE_loss: 4.7736 \tTime: 0.0569\n",
      "Validation \tLoss_D: 0.5025\tLoss_G: 1.9989 \tMSE_loss: 4.3960 \tBest_loss: 4.3583\n",
      "[60/400][141/142]\tLoss_D: 0.6329\tLoss_G: 2.3171 \tMSE_loss: 4.5359 \tTime: 0.0499\n",
      "Validation \tLoss_D: 0.4947\tLoss_G: 2.0696 \tMSE_loss: 4.4336 \tBest_loss: 4.3583\n",
      "[61/400][141/142]\tLoss_D: 0.4572\tLoss_G: 2.3713 \tMSE_loss: 6.0035 \tTime: 0.0516\n",
      "Validation \tLoss_D: 0.4908\tLoss_G: 2.0766 \tMSE_loss: 4.4144 \tBest_loss: 4.3583\n",
      "[62/400][141/142]\tLoss_D: 0.4015\tLoss_G: 1.9134 \tMSE_loss: 4.9871 \tTime: 0.0535\n",
      "Validation \tLoss_D: 0.5000\tLoss_G: 2.0810 \tMSE_loss: 4.3554 \tBest_loss: 4.3554\n",
      "[63/400][141/142]\tLoss_D: 0.6606\tLoss_G: 2.1080 \tMSE_loss: 3.4495 \tTime: 0.0549\n",
      "Validation \tLoss_D: 0.4884\tLoss_G: 2.1428 \tMSE_loss: 4.4148 \tBest_loss: 4.3554\n",
      "[64/400][141/142]\tLoss_D: 0.4528\tLoss_G: 2.2841 \tMSE_loss: 3.8566 \tTime: 0.0585\n",
      "Validation \tLoss_D: 0.4913\tLoss_G: 2.1031 \tMSE_loss: 4.3589 \tBest_loss: 4.3554\n",
      "[65/400][141/142]\tLoss_D: 0.4643\tLoss_G: 2.1442 \tMSE_loss: 2.9072 \tTime: 0.0552\n",
      "Validation \tLoss_D: 0.4994\tLoss_G: 2.0670 \tMSE_loss: 4.2770 \tBest_loss: 4.2770\n",
      "[66/400][141/142]\tLoss_D: 0.4440\tLoss_G: 2.7333 \tMSE_loss: 5.0851 \tTime: 0.0606\n",
      "Validation \tLoss_D: 0.4844\tLoss_G: 2.1200 \tMSE_loss: 4.4914 \tBest_loss: 4.2770\n",
      "[67/400][141/142]\tLoss_D: 0.7035\tLoss_G: 1.7066 \tMSE_loss: 5.1419 \tTime: 0.0505\n",
      "Validation \tLoss_D: 0.5134\tLoss_G: 1.9614 \tMSE_loss: 4.2628 \tBest_loss: 4.2628\n",
      "[68/400][141/142]\tLoss_D: 0.6378\tLoss_G: 1.8646 \tMSE_loss: 4.9903 \tTime: 0.0573\n",
      "Validation \tLoss_D: 0.5140\tLoss_G: 2.1243 \tMSE_loss: 4.3069 \tBest_loss: 4.2628\n",
      "[69/400][141/142]\tLoss_D: 0.4070\tLoss_G: 1.9750 \tMSE_loss: 5.6886 \tTime: 0.0510\n",
      "Validation \tLoss_D: 0.5030\tLoss_G: 2.1591 \tMSE_loss: 4.4020 \tBest_loss: 4.2628\n",
      "[70/400][141/142]\tLoss_D: 0.4687\tLoss_G: 1.8106 \tMSE_loss: 9.9894 \tTime: 0.0538\n",
      "Validation \tLoss_D: 0.5071\tLoss_G: 2.1138 \tMSE_loss: 4.4058 \tBest_loss: 4.2628\n",
      "[71/400][141/142]\tLoss_D: 0.5238\tLoss_G: 1.8900 \tMSE_loss: 4.8635 \tTime: 0.0570\n",
      "Validation \tLoss_D: 0.5375\tLoss_G: 2.0143 \tMSE_loss: 4.2721 \tBest_loss: 4.2628\n",
      "[72/400][141/142]\tLoss_D: 0.5840\tLoss_G: 2.0342 \tMSE_loss: 2.8692 \tTime: 0.0571\n",
      "Validation \tLoss_D: 0.5200\tLoss_G: 2.1346 \tMSE_loss: 4.4878 \tBest_loss: 4.2628\n",
      "[73/400][141/142]\tLoss_D: 0.4041\tLoss_G: 2.2105 \tMSE_loss: 4.1970 \tTime: 0.0589\n",
      "Validation \tLoss_D: 0.5433\tLoss_G: 2.0754 \tMSE_loss: 4.3692 \tBest_loss: 4.2628\n",
      "[74/400][141/142]\tLoss_D: 0.6382\tLoss_G: 2.2737 \tMSE_loss: 3.2001 \tTime: 0.0524\n",
      "Validation \tLoss_D: 0.5496\tLoss_G: 2.1040 \tMSE_loss: 4.5446 \tBest_loss: 4.2628\n",
      "[75/400][141/142]\tLoss_D: 0.5729\tLoss_G: 2.3202 \tMSE_loss: 5.4615 \tTime: 0.0640\n",
      "Validation \tLoss_D: 0.5511\tLoss_G: 2.1190 \tMSE_loss: 4.4675 \tBest_loss: 4.2628\n",
      "[76/400][141/142]\tLoss_D: 0.5378\tLoss_G: 2.2998 \tMSE_loss: 4.7188 \tTime: 0.0576\n",
      "Validation \tLoss_D: 0.5646\tLoss_G: 2.0480 \tMSE_loss: 4.4046 \tBest_loss: 4.2628\n",
      "[77/400][141/142]\tLoss_D: 0.5840\tLoss_G: 2.4539 \tMSE_loss: 4.5515 \tTime: 0.0582\n",
      "Validation \tLoss_D: 0.5734\tLoss_G: 2.0915 \tMSE_loss: 4.5777 \tBest_loss: 4.2628\n",
      "[78/400][141/142]\tLoss_D: 0.7232\tLoss_G: 2.0766 \tMSE_loss: 3.5326 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.5806\tLoss_G: 1.9851 \tMSE_loss: 4.5590 \tBest_loss: 4.2628\n",
      "[79/400][141/142]\tLoss_D: 0.4673\tLoss_G: 2.3756 \tMSE_loss: 5.8252 \tTime: 0.0529\n",
      "Validation \tLoss_D: 0.5903\tLoss_G: 2.0783 \tMSE_loss: 4.5807 \tBest_loss: 4.2628\n",
      "[80/400][141/142]\tLoss_D: 0.5034\tLoss_G: 2.0292 \tMSE_loss: 3.7872 \tTime: 0.0598\n",
      "Validation \tLoss_D: 0.5809\tLoss_G: 2.0341 \tMSE_loss: 4.5359 \tBest_loss: 4.2628\n",
      "[81/400][141/142]\tLoss_D: 0.6514\tLoss_G: 2.1182 \tMSE_loss: 4.1216 \tTime: 0.0579\n",
      "Validation \tLoss_D: 0.5944\tLoss_G: 1.9621 \tMSE_loss: 4.5394 \tBest_loss: 4.2628\n",
      "[82/400][141/142]\tLoss_D: 0.8118\tLoss_G: 2.1592 \tMSE_loss: 5.6521 \tTime: 0.0506\n",
      "Validation \tLoss_D: 0.5934\tLoss_G: 1.9355 \tMSE_loss: 4.5319 \tBest_loss: 4.2628\n",
      "[83/400][141/142]\tLoss_D: 0.6710\tLoss_G: 1.9364 \tMSE_loss: 4.0780 \tTime: 0.0535\n",
      "Validation \tLoss_D: 0.5801\tLoss_G: 1.9462 \tMSE_loss: 4.5262 \tBest_loss: 4.2628\n",
      "[84/400][141/142]\tLoss_D: 0.5468\tLoss_G: 1.9679 \tMSE_loss: 4.6625 \tTime: 0.0571\n",
      "Validation \tLoss_D: 0.5967\tLoss_G: 1.9720 \tMSE_loss: 4.5268 \tBest_loss: 4.2628\n",
      "[85/400][141/142]\tLoss_D: 0.5967\tLoss_G: 1.9100 \tMSE_loss: 5.5363 \tTime: 0.0573\n",
      "Validation \tLoss_D: 0.5955\tLoss_G: 1.9576 \tMSE_loss: 4.5822 \tBest_loss: 4.2628\n",
      "[86/400][141/142]\tLoss_D: 0.4758\tLoss_G: 2.2711 \tMSE_loss: 4.4629 \tTime: 0.0548\n",
      "Validation \tLoss_D: 0.5942\tLoss_G: 2.0274 \tMSE_loss: 4.6121 \tBest_loss: 4.2628\n",
      "[87/400][141/142]\tLoss_D: 0.6375\tLoss_G: 1.9672 \tMSE_loss: 6.3095 \tTime: 0.0591\n",
      "Validation \tLoss_D: 0.5900\tLoss_G: 1.9448 \tMSE_loss: 4.4228 \tBest_loss: 4.2628\n",
      "[88/400][141/142]\tLoss_D: 0.6885\tLoss_G: 1.8168 \tMSE_loss: 4.7595 \tTime: 0.0526\n",
      "Validation \tLoss_D: 0.5797\tLoss_G: 1.9758 \tMSE_loss: 4.4616 \tBest_loss: 4.2628\n",
      "[89/400][141/142]\tLoss_D: 0.8147\tLoss_G: 2.1462 \tMSE_loss: 3.2922 \tTime: 0.0605\n",
      "Validation \tLoss_D: 0.5867\tLoss_G: 1.9981 \tMSE_loss: 4.4755 \tBest_loss: 4.2628\n",
      "[90/400][141/142]\tLoss_D: 0.6223\tLoss_G: 2.3923 \tMSE_loss: 4.2016 \tTime: 0.0558\n",
      "Validation \tLoss_D: 0.5874\tLoss_G: 1.9715 \tMSE_loss: 4.5002 \tBest_loss: 4.2628\n",
      "[91/400][141/142]\tLoss_D: 0.7630\tLoss_G: 2.2724 \tMSE_loss: 3.5086 \tTime: 0.0584\n",
      "Validation \tLoss_D: 0.5622\tLoss_G: 2.1074 \tMSE_loss: 4.4540 \tBest_loss: 4.2628\n",
      "[92/400][141/142]\tLoss_D: 0.6746\tLoss_G: 2.1790 \tMSE_loss: 3.8851 \tTime: 0.0569\n",
      "Validation \tLoss_D: 0.5749\tLoss_G: 2.0623 \tMSE_loss: 4.4289 \tBest_loss: 4.2628\n",
      "[93/400][141/142]\tLoss_D: 0.6708\tLoss_G: 2.4789 \tMSE_loss: 3.6625 \tTime: 0.0569\n",
      "Validation \tLoss_D: 0.5712\tLoss_G: 2.0550 \tMSE_loss: 4.5113 \tBest_loss: 4.2628\n",
      "[94/400][141/142]\tLoss_D: 0.4069\tLoss_G: 2.4788 \tMSE_loss: 5.8888 \tTime: 0.0583\n",
      "Validation \tLoss_D: 0.5618\tLoss_G: 2.0847 \tMSE_loss: 4.4912 \tBest_loss: 4.2628\n",
      "[95/400][141/142]\tLoss_D: 0.4309\tLoss_G: 2.0220 \tMSE_loss: 5.7385 \tTime: 0.0534\n",
      "Validation \tLoss_D: 0.5501\tLoss_G: 2.2541 \tMSE_loss: 4.4659 \tBest_loss: 4.2628\n",
      "[96/400][141/142]\tLoss_D: 0.6151\tLoss_G: 2.3545 \tMSE_loss: 3.3582 \tTime: 0.0580\n",
      "Validation \tLoss_D: 0.5906\tLoss_G: 2.1279 \tMSE_loss: 4.5029 \tBest_loss: 4.2628\n",
      "[97/400][141/142]\tLoss_D: 0.7582\tLoss_G: 2.3609 \tMSE_loss: 5.2888 \tTime: 0.0597\n",
      "Validation \tLoss_D: 0.5735\tLoss_G: 2.2136 \tMSE_loss: 4.4840 \tBest_loss: 4.2628\n",
      "[98/400][141/142]\tLoss_D: 0.8805\tLoss_G: 2.2246 \tMSE_loss: 3.4563 \tTime: 0.0531\n",
      "Validation \tLoss_D: 0.5831\tLoss_G: 2.1098 \tMSE_loss: 4.3010 \tBest_loss: 4.2628\n",
      "[99/400][141/142]\tLoss_D: 0.3601\tLoss_G: 2.8013 \tMSE_loss: 5.5488 \tTime: 0.0552\n",
      "Validation \tLoss_D: 0.5625\tLoss_G: 2.2589 \tMSE_loss: 4.4985 \tBest_loss: 4.2628\n",
      "[100/400][141/142]\tLoss_D: 0.7424\tLoss_G: 2.0232 \tMSE_loss: 7.1004 \tTime: 0.0628\n",
      "Validation \tLoss_D: 0.5580\tLoss_G: 2.2248 \tMSE_loss: 4.4898 \tBest_loss: 4.2628\n",
      "[101/400][141/142]\tLoss_D: 0.6974\tLoss_G: 2.2134 \tMSE_loss: 6.3548 \tTime: 0.0513\n",
      "Validation \tLoss_D: 0.5543\tLoss_G: 2.3204 \tMSE_loss: 4.5976 \tBest_loss: 4.2628\n",
      "[102/400][141/142]\tLoss_D: 0.5902\tLoss_G: 2.0329 \tMSE_loss: 3.3502 \tTime: 0.0607\n",
      "Validation \tLoss_D: 0.5624\tLoss_G: 2.2631 \tMSE_loss: 4.4008 \tBest_loss: 4.2628\n",
      "[103/400][141/142]\tLoss_D: 0.5228\tLoss_G: 2.3845 \tMSE_loss: 3.0456 \tTime: 0.0585\n",
      "Validation \tLoss_D: 0.5418\tLoss_G: 2.3146 \tMSE_loss: 4.3755 \tBest_loss: 4.2628\n",
      "[104/400][141/142]\tLoss_D: 0.5017\tLoss_G: 2.5228 \tMSE_loss: 4.8648 \tTime: 0.0615\n",
      "Validation \tLoss_D: 0.5459\tLoss_G: 2.2930 \tMSE_loss: 4.4224 \tBest_loss: 4.2628\n",
      "[105/400][141/142]\tLoss_D: 0.6670\tLoss_G: 2.0505 \tMSE_loss: 6.7208 \tTime: 0.0585\n",
      "Validation \tLoss_D: 0.5540\tLoss_G: 2.3862 \tMSE_loss: 4.3155 \tBest_loss: 4.2628\n",
      "[106/400][141/142]\tLoss_D: 0.8543\tLoss_G: 2.0061 \tMSE_loss: 3.2072 \tTime: 0.0583\n",
      "Validation \tLoss_D: 0.5214\tLoss_G: 2.3416 \tMSE_loss: 4.3086 \tBest_loss: 4.2628\n",
      "[107/400][141/142]\tLoss_D: 0.5486\tLoss_G: 2.7358 \tMSE_loss: 6.4691 \tTime: 0.0511\n",
      "Validation \tLoss_D: 0.5441\tLoss_G: 2.4286 \tMSE_loss: 4.4160 \tBest_loss: 4.2628\n",
      "[108/400][141/142]\tLoss_D: 0.4971\tLoss_G: 2.2370 \tMSE_loss: 8.1990 \tTime: 0.0576\n",
      "Validation \tLoss_D: 0.5335\tLoss_G: 2.3769 \tMSE_loss: 4.3491 \tBest_loss: 4.2628\n",
      "[109/400][141/142]\tLoss_D: 0.4446\tLoss_G: 2.6315 \tMSE_loss: 5.0126 \tTime: 0.0552\n",
      "Validation \tLoss_D: 0.5431\tLoss_G: 2.4349 \tMSE_loss: 4.4114 \tBest_loss: 4.2628\n",
      "[110/400][141/142]\tLoss_D: 0.4756\tLoss_G: 2.4766 \tMSE_loss: 4.1197 \tTime: 0.0517\n",
      "Validation \tLoss_D: 0.5290\tLoss_G: 2.4618 \tMSE_loss: 4.4349 \tBest_loss: 4.2628\n",
      "[111/400][141/142]\tLoss_D: 0.4947\tLoss_G: 2.6915 \tMSE_loss: 5.3035 \tTime: 0.0576\n",
      "Validation \tLoss_D: 0.5366\tLoss_G: 2.4741 \tMSE_loss: 4.3885 \tBest_loss: 4.2628\n",
      "[112/400][141/142]\tLoss_D: 0.6100\tLoss_G: 2.1307 \tMSE_loss: 4.5666 \tTime: 0.0524\n",
      "Validation \tLoss_D: 0.5445\tLoss_G: 2.4856 \tMSE_loss: 4.2632 \tBest_loss: 4.2628\n",
      "[113/400][141/142]\tLoss_D: 0.6672\tLoss_G: 2.0953 \tMSE_loss: 4.9427 \tTime: 0.0578\n",
      "Validation \tLoss_D: 0.5287\tLoss_G: 2.4863 \tMSE_loss: 4.2399 \tBest_loss: 4.2399\n",
      "[114/400][141/142]\tLoss_D: 0.7355\tLoss_G: 2.3711 \tMSE_loss: 4.2515 \tTime: 0.0530\n",
      "Validation \tLoss_D: 0.5420\tLoss_G: 2.4635 \tMSE_loss: 4.2531 \tBest_loss: 4.2399\n",
      "[115/400][141/142]\tLoss_D: 0.4566\tLoss_G: 2.5081 \tMSE_loss: 6.5112 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.5377\tLoss_G: 2.4010 \tMSE_loss: 4.2613 \tBest_loss: 4.2399\n",
      "[116/400][141/142]\tLoss_D: 0.5756\tLoss_G: 2.4783 \tMSE_loss: 6.2378 \tTime: 0.0626\n",
      "Validation \tLoss_D: 0.5260\tLoss_G: 2.5703 \tMSE_loss: 4.3642 \tBest_loss: 4.2399\n",
      "[117/400][141/142]\tLoss_D: 0.4538\tLoss_G: 2.3175 \tMSE_loss: 6.3333 \tTime: 0.0555\n",
      "Validation \tLoss_D: 0.5197\tLoss_G: 2.5575 \tMSE_loss: 4.3274 \tBest_loss: 4.2399\n",
      "[118/400][141/142]\tLoss_D: 0.4261\tLoss_G: 2.5221 \tMSE_loss: 5.1333 \tTime: 0.0632\n",
      "Validation \tLoss_D: 0.5432\tLoss_G: 2.4827 \tMSE_loss: 4.1796 \tBest_loss: 4.1796\n",
      "[119/400][141/142]\tLoss_D: 0.7188\tLoss_G: 2.6602 \tMSE_loss: 4.3973 \tTime: 0.0579\n",
      "Validation \tLoss_D: 0.5400\tLoss_G: 2.5224 \tMSE_loss: 4.1923 \tBest_loss: 4.1796\n",
      "[120/400][141/142]\tLoss_D: 0.5872\tLoss_G: 1.9080 \tMSE_loss: 5.7808 \tTime: 0.0524\n",
      "Validation \tLoss_D: 0.5690\tLoss_G: 2.3802 \tMSE_loss: 4.1653 \tBest_loss: 4.1653\n",
      "[121/400][141/142]\tLoss_D: 0.7820\tLoss_G: 2.3113 \tMSE_loss: 3.1954 \tTime: 0.0515\n",
      "Validation \tLoss_D: 0.5685\tLoss_G: 2.3790 \tMSE_loss: 4.1460 \tBest_loss: 4.1460\n",
      "[122/400][141/142]\tLoss_D: 0.5326\tLoss_G: 2.5376 \tMSE_loss: 9.0645 \tTime: 0.0568\n",
      "Validation \tLoss_D: 0.5457\tLoss_G: 2.4837 \tMSE_loss: 4.1721 \tBest_loss: 4.1460\n",
      "[123/400][141/142]\tLoss_D: 0.5060\tLoss_G: 2.8497 \tMSE_loss: 5.6898 \tTime: 0.0535\n",
      "Validation \tLoss_D: 0.5701\tLoss_G: 2.4784 \tMSE_loss: 4.1863 \tBest_loss: 4.1460\n",
      "[124/400][141/142]\tLoss_D: 0.4083\tLoss_G: 2.2811 \tMSE_loss: 3.8696 \tTime: 0.0553\n",
      "Validation \tLoss_D: 0.5930\tLoss_G: 2.3006 \tMSE_loss: 4.0461 \tBest_loss: 4.0461\n",
      "[125/400][141/142]\tLoss_D: 0.7216\tLoss_G: 2.0354 \tMSE_loss: 5.2613 \tTime: 0.0556\n",
      "Validation \tLoss_D: 0.6020\tLoss_G: 2.3974 \tMSE_loss: 4.0454 \tBest_loss: 4.0454\n",
      "[126/400][141/142]\tLoss_D: 0.5013\tLoss_G: 2.2651 \tMSE_loss: 3.4025 \tTime: 0.0473\n",
      "Validation \tLoss_D: 0.5872\tLoss_G: 2.3688 \tMSE_loss: 4.0597 \tBest_loss: 4.0454\n",
      "[127/400][141/142]\tLoss_D: 0.4619\tLoss_G: 2.1349 \tMSE_loss: 3.1525 \tTime: 0.0606\n",
      "Validation \tLoss_D: 0.6232\tLoss_G: 2.2456 \tMSE_loss: 3.9644 \tBest_loss: 3.9644\n",
      "[128/400][141/142]\tLoss_D: 0.4119\tLoss_G: 2.2712 \tMSE_loss: 4.6622 \tTime: 0.0555\n",
      "Validation \tLoss_D: 0.6184\tLoss_G: 2.2772 \tMSE_loss: 3.9277 \tBest_loss: 3.9277\n",
      "[129/400][141/142]\tLoss_D: 0.5487\tLoss_G: 2.7122 \tMSE_loss: 3.5145 \tTime: 0.0585\n",
      "Validation \tLoss_D: 0.6237\tLoss_G: 2.3509 \tMSE_loss: 3.9781 \tBest_loss: 3.9277\n",
      "[130/400][141/142]\tLoss_D: 0.5861\tLoss_G: 1.9902 \tMSE_loss: 4.7211 \tTime: 0.0578\n",
      "Validation \tLoss_D: 0.6261\tLoss_G: 2.2780 \tMSE_loss: 3.9703 \tBest_loss: 3.9277\n",
      "[131/400][141/142]\tLoss_D: 0.6060\tLoss_G: 2.1429 \tMSE_loss: 3.2157 \tTime: 0.0505\n",
      "Validation \tLoss_D: 0.6309\tLoss_G: 2.2513 \tMSE_loss: 3.9357 \tBest_loss: 3.9277\n",
      "[132/400][141/142]\tLoss_D: 0.6163\tLoss_G: 1.8987 \tMSE_loss: 3.6999 \tTime: 0.0513\n",
      "Validation \tLoss_D: 0.6362\tLoss_G: 2.2226 \tMSE_loss: 3.8467 \tBest_loss: 3.8467\n",
      "[133/400][141/142]\tLoss_D: 0.5257\tLoss_G: 2.4952 \tMSE_loss: 5.3074 \tTime: 0.0558\n",
      "Validation \tLoss_D: 0.6402\tLoss_G: 2.2795 \tMSE_loss: 3.9679 \tBest_loss: 3.8467\n",
      "[134/400][141/142]\tLoss_D: 0.5165\tLoss_G: 2.2352 \tMSE_loss: 3.3328 \tTime: 0.0526\n",
      "Validation \tLoss_D: 0.6568\tLoss_G: 2.2633 \tMSE_loss: 3.9277 \tBest_loss: 3.8467\n",
      "[135/400][141/142]\tLoss_D: 0.6384\tLoss_G: 2.3226 \tMSE_loss: 5.2077 \tTime: 0.0572\n",
      "Validation \tLoss_D: 0.6671\tLoss_G: 2.1902 \tMSE_loss: 3.8463 \tBest_loss: 3.8463\n",
      "[136/400][141/142]\tLoss_D: 0.6602\tLoss_G: 2.2054 \tMSE_loss: 5.1418 \tTime: 0.0590\n",
      "Validation \tLoss_D: 0.6828\tLoss_G: 2.2210 \tMSE_loss: 3.8136 \tBest_loss: 3.8136\n",
      "[137/400][141/142]\tLoss_D: 0.6458\tLoss_G: 2.4305 \tMSE_loss: 4.3424 \tTime: 0.0500\n",
      "Validation \tLoss_D: 0.6922\tLoss_G: 2.1068 \tMSE_loss: 3.8747 \tBest_loss: 3.8136\n",
      "[138/400][141/142]\tLoss_D: 0.7972\tLoss_G: 2.2213 \tMSE_loss: 2.3446 \tTime: 0.0608\n",
      "Validation \tLoss_D: 0.7107\tLoss_G: 2.1525 \tMSE_loss: 3.8922 \tBest_loss: 3.8136\n",
      "[139/400][141/142]\tLoss_D: 0.6812\tLoss_G: 2.2819 \tMSE_loss: 4.3007 \tTime: 0.0540\n",
      "Validation \tLoss_D: 0.7183\tLoss_G: 2.1877 \tMSE_loss: 3.9369 \tBest_loss: 3.8136\n",
      "[140/400][141/142]\tLoss_D: 0.5642\tLoss_G: 2.6735 \tMSE_loss: 5.2778 \tTime: 0.0585\n",
      "Validation \tLoss_D: 0.7410\tLoss_G: 2.0807 \tMSE_loss: 3.8666 \tBest_loss: 3.8136\n",
      "[141/400][141/142]\tLoss_D: 0.9639\tLoss_G: 2.2275 \tMSE_loss: 2.4238 \tTime: 0.0583\n",
      "Validation \tLoss_D: 0.7271\tLoss_G: 2.1906 \tMSE_loss: 3.8906 \tBest_loss: 3.8136\n",
      "[142/400][141/142]\tLoss_D: 0.6407\tLoss_G: 2.6274 \tMSE_loss: 5.6481 \tTime: 0.0564\n",
      "Validation \tLoss_D: 0.7341\tLoss_G: 2.1105 \tMSE_loss: 3.8588 \tBest_loss: 3.8136\n",
      "[143/400][141/142]\tLoss_D: 0.6302\tLoss_G: 2.2611 \tMSE_loss: 4.2253 \tTime: 0.0620\n",
      "Validation \tLoss_D: 0.7335\tLoss_G: 2.0506 \tMSE_loss: 3.8256 \tBest_loss: 3.8136\n",
      "[144/400][141/142]\tLoss_D: 0.6280\tLoss_G: 2.2497 \tMSE_loss: 3.4845 \tTime: 0.0622\n",
      "Validation \tLoss_D: 0.7322\tLoss_G: 2.0467 \tMSE_loss: 3.8423 \tBest_loss: 3.8136\n",
      "[145/400][141/142]\tLoss_D: 0.7045\tLoss_G: 1.7533 \tMSE_loss: 2.8580 \tTime: 0.0514\n",
      "Validation \tLoss_D: 0.7349\tLoss_G: 1.9590 \tMSE_loss: 3.8499 \tBest_loss: 3.8136\n",
      "[146/400][141/142]\tLoss_D: 0.7074\tLoss_G: 2.0035 \tMSE_loss: 2.7041 \tTime: 0.0519\n",
      "Validation \tLoss_D: 0.7406\tLoss_G: 2.0271 \tMSE_loss: 3.8294 \tBest_loss: 3.8136\n",
      "[147/400][141/142]\tLoss_D: 0.4139\tLoss_G: 2.4481 \tMSE_loss: 4.9676 \tTime: 0.0520\n",
      "Validation \tLoss_D: 0.7185\tLoss_G: 2.0439 \tMSE_loss: 3.8432 \tBest_loss: 3.8136\n",
      "[148/400][141/142]\tLoss_D: 0.4826\tLoss_G: 2.1083 \tMSE_loss: 3.7736 \tTime: 0.0588\n",
      "Validation \tLoss_D: 0.7239\tLoss_G: 2.0183 \tMSE_loss: 3.8169 \tBest_loss: 3.8136\n",
      "[149/400][141/142]\tLoss_D: 0.9167\tLoss_G: 2.1345 \tMSE_loss: 2.8917 \tTime: 0.0506\n",
      "Validation \tLoss_D: 0.7323\tLoss_G: 2.0767 \tMSE_loss: 3.7853 \tBest_loss: 3.7853\n",
      "[150/400][141/142]\tLoss_D: 0.5825\tLoss_G: 2.7711 \tMSE_loss: 3.5893 \tTime: 0.0570\n",
      "Validation \tLoss_D: 0.7280\tLoss_G: 2.0620 \tMSE_loss: 3.8346 \tBest_loss: 3.7853\n",
      "[151/400][141/142]\tLoss_D: 0.9048\tLoss_G: 2.1151 \tMSE_loss: 2.9773 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.7365\tLoss_G: 2.0393 \tMSE_loss: 3.7723 \tBest_loss: 3.7723\n",
      "[152/400][141/142]\tLoss_D: 0.6265\tLoss_G: 2.0542 \tMSE_loss: 4.9509 \tTime: 0.0556\n",
      "Validation \tLoss_D: 0.7173\tLoss_G: 2.0341 \tMSE_loss: 3.8262 \tBest_loss: 3.7723\n",
      "[153/400][141/142]\tLoss_D: 0.5159\tLoss_G: 1.8300 \tMSE_loss: 2.7848 \tTime: 0.0584\n",
      "Validation \tLoss_D: 0.7090\tLoss_G: 2.0437 \tMSE_loss: 3.8406 \tBest_loss: 3.7723\n",
      "[154/400][141/142]\tLoss_D: 0.7363\tLoss_G: 2.2922 \tMSE_loss: 4.4040 \tTime: 0.0614\n",
      "Validation \tLoss_D: 0.7231\tLoss_G: 2.0958 \tMSE_loss: 3.8250 \tBest_loss: 3.7723\n",
      "[155/400][141/142]\tLoss_D: 0.5275\tLoss_G: 2.2026 \tMSE_loss: 4.8438 \tTime: 0.0530\n",
      "Validation \tLoss_D: 0.7164\tLoss_G: 2.0248 \tMSE_loss: 3.8008 \tBest_loss: 3.7723\n",
      "[156/400][141/142]\tLoss_D: 0.5816\tLoss_G: 1.9775 \tMSE_loss: 3.4278 \tTime: 0.0533\n",
      "Validation \tLoss_D: 0.7301\tLoss_G: 1.9795 \tMSE_loss: 3.7766 \tBest_loss: 3.7723\n",
      "[157/400][141/142]\tLoss_D: 0.6992\tLoss_G: 2.1825 \tMSE_loss: 4.8901 \tTime: 0.0505\n",
      "Validation \tLoss_D: 0.7109\tLoss_G: 2.0601 \tMSE_loss: 3.8694 \tBest_loss: 3.7723\n",
      "[158/400][141/142]\tLoss_D: 0.7803\tLoss_G: 1.6529 \tMSE_loss: 2.6602 \tTime: 0.0498\n",
      "Validation \tLoss_D: 0.7295\tLoss_G: 1.9821 \tMSE_loss: 3.7925 \tBest_loss: 3.7723\n",
      "[159/400][141/142]\tLoss_D: 0.7073\tLoss_G: 1.8163 \tMSE_loss: 4.5970 \tTime: 0.0584\n",
      "Validation \tLoss_D: 0.7412\tLoss_G: 1.9872 \tMSE_loss: 3.7443 \tBest_loss: 3.7443\n",
      "[160/400][141/142]\tLoss_D: 0.5167\tLoss_G: 2.3908 \tMSE_loss: 4.1136 \tTime: 0.0630\n",
      "Validation \tLoss_D: 0.7274\tLoss_G: 2.1258 \tMSE_loss: 3.8644 \tBest_loss: 3.7443\n",
      "[161/400][141/142]\tLoss_D: 0.7786\tLoss_G: 1.9574 \tMSE_loss: 2.8629 \tTime: 0.0625\n",
      "Validation \tLoss_D: 0.7490\tLoss_G: 2.0408 \tMSE_loss: 3.7867 \tBest_loss: 3.7443\n",
      "[162/400][141/142]\tLoss_D: 0.4334\tLoss_G: 1.9731 \tMSE_loss: 3.2610 \tTime: 0.0582\n",
      "Validation \tLoss_D: 0.7286\tLoss_G: 2.0019 \tMSE_loss: 3.8469 \tBest_loss: 3.7443\n",
      "[163/400][141/142]\tLoss_D: 0.7380\tLoss_G: 1.8389 \tMSE_loss: 3.3092 \tTime: 0.0556\n",
      "Validation \tLoss_D: 0.7618\tLoss_G: 1.9372 \tMSE_loss: 3.7832 \tBest_loss: 3.7443\n",
      "[164/400][141/142]\tLoss_D: 0.5812\tLoss_G: 1.7643 \tMSE_loss: 2.2850 \tTime: 0.0531\n",
      "Validation \tLoss_D: 0.7254\tLoss_G: 2.0264 \tMSE_loss: 3.8070 \tBest_loss: 3.7443\n",
      "[165/400][141/142]\tLoss_D: 0.6330\tLoss_G: 2.5414 \tMSE_loss: 5.5554 \tTime: 0.0566\n",
      "Validation \tLoss_D: 0.7389\tLoss_G: 2.0406 \tMSE_loss: 3.8299 \tBest_loss: 3.7443\n",
      "[166/400][141/142]\tLoss_D: 0.5249\tLoss_G: 1.9020 \tMSE_loss: 3.7276 \tTime: 0.0549\n",
      "Validation \tLoss_D: 0.7329\tLoss_G: 2.0832 \tMSE_loss: 3.8845 \tBest_loss: 3.7443\n",
      "[167/400][141/142]\tLoss_D: 0.5447\tLoss_G: 2.4169 \tMSE_loss: 3.6604 \tTime: 0.0490\n",
      "Validation \tLoss_D: 0.7612\tLoss_G: 1.9956 \tMSE_loss: 3.7815 \tBest_loss: 3.7443\n",
      "[168/400][141/142]\tLoss_D: 0.5623\tLoss_G: 2.6473 \tMSE_loss: 3.3266 \tTime: 0.0574\n",
      "Validation \tLoss_D: 0.7732\tLoss_G: 2.0468 \tMSE_loss: 3.7794 \tBest_loss: 3.7443\n",
      "[169/400][141/142]\tLoss_D: 0.8044\tLoss_G: 2.1569 \tMSE_loss: 2.6122 \tTime: 0.0591\n",
      "Validation \tLoss_D: 0.7760\tLoss_G: 2.0838 \tMSE_loss: 3.7769 \tBest_loss: 3.7443\n",
      "[170/400][141/142]\tLoss_D: 0.5066\tLoss_G: 2.1087 \tMSE_loss: 2.8342 \tTime: 0.0583\n",
      "Validation \tLoss_D: 0.7701\tLoss_G: 1.9508 \tMSE_loss: 3.7469 \tBest_loss: 3.7443\n",
      "[171/400][141/142]\tLoss_D: 0.8494\tLoss_G: 2.1230 \tMSE_loss: 3.4722 \tTime: 0.0587\n",
      "Validation \tLoss_D: 0.7963\tLoss_G: 1.9412 \tMSE_loss: 3.7410 \tBest_loss: 3.7410\n",
      "[172/400][141/142]\tLoss_D: 0.7462\tLoss_G: 1.9374 \tMSE_loss: 3.6923 \tTime: 0.0645\n",
      "Validation \tLoss_D: 0.7746\tLoss_G: 2.0587 \tMSE_loss: 3.7818 \tBest_loss: 3.7410\n",
      "[173/400][141/142]\tLoss_D: 0.6837\tLoss_G: 1.9055 \tMSE_loss: 3.6661 \tTime: 0.0632\n",
      "Validation \tLoss_D: 0.7968\tLoss_G: 2.0420 \tMSE_loss: 3.7397 \tBest_loss: 3.7397\n",
      "[174/400][141/142]\tLoss_D: 0.7218\tLoss_G: 2.5969 \tMSE_loss: 6.8698 \tTime: 0.0540\n",
      "Validation \tLoss_D: 0.8039\tLoss_G: 2.0477 \tMSE_loss: 3.7472 \tBest_loss: 3.7397\n",
      "[175/400][141/142]\tLoss_D: 0.9021\tLoss_G: 2.1927 \tMSE_loss: 3.2524 \tTime: 0.0529\n",
      "Validation \tLoss_D: 0.8224\tLoss_G: 1.9384 \tMSE_loss: 3.7387 \tBest_loss: 3.7387\n",
      "[176/400][141/142]\tLoss_D: 0.7673\tLoss_G: 2.1944 \tMSE_loss: 5.7596 \tTime: 0.0564\n",
      "Validation \tLoss_D: 0.8096\tLoss_G: 2.0500 \tMSE_loss: 3.7365 \tBest_loss: 3.7365\n",
      "[177/400][141/142]\tLoss_D: 0.8526\tLoss_G: 2.3386 \tMSE_loss: 3.3651 \tTime: 0.0555\n",
      "Validation \tLoss_D: 0.8517\tLoss_G: 1.9703 \tMSE_loss: 3.7049 \tBest_loss: 3.7049\n",
      "[178/400][141/142]\tLoss_D: 0.8511\tLoss_G: 1.9188 \tMSE_loss: 3.8780 \tTime: 0.0646\n",
      "Validation \tLoss_D: 0.8620\tLoss_G: 1.9927 \tMSE_loss: 3.7093 \tBest_loss: 3.7049\n",
      "[179/400][141/142]\tLoss_D: 0.7026\tLoss_G: 2.1488 \tMSE_loss: 4.4192 \tTime: 0.0600\n",
      "Validation \tLoss_D: 0.8658\tLoss_G: 2.0102 \tMSE_loss: 3.7005 \tBest_loss: 3.7005\n",
      "[180/400][141/142]\tLoss_D: 0.6874\tLoss_G: 2.0048 \tMSE_loss: 3.1887 \tTime: 0.0568\n",
      "Validation \tLoss_D: 0.8519\tLoss_G: 1.9901 \tMSE_loss: 3.7272 \tBest_loss: 3.7005\n",
      "[181/400][141/142]\tLoss_D: 0.5472\tLoss_G: 1.8588 \tMSE_loss: 4.4960 \tTime: 0.0569\n",
      "Validation \tLoss_D: 0.8666\tLoss_G: 1.9618 \tMSE_loss: 3.7065 \tBest_loss: 3.7005\n",
      "[182/400][141/142]\tLoss_D: 0.8007\tLoss_G: 2.1417 \tMSE_loss: 4.4468 \tTime: 0.0565\n",
      "Validation \tLoss_D: 0.8639\tLoss_G: 2.1136 \tMSE_loss: 3.7413 \tBest_loss: 3.7005\n",
      "[183/400][141/142]\tLoss_D: 0.7109\tLoss_G: 2.4591 \tMSE_loss: 6.1261 \tTime: 0.0522\n",
      "Validation \tLoss_D: 0.9032\tLoss_G: 1.9373 \tMSE_loss: 3.6874 \tBest_loss: 3.6874\n",
      "[184/400][141/142]\tLoss_D: 0.8927\tLoss_G: 2.2175 \tMSE_loss: 3.4502 \tTime: 0.0593\n",
      "Validation \tLoss_D: 0.8778\tLoss_G: 2.0043 \tMSE_loss: 3.7357 \tBest_loss: 3.6874\n",
      "[185/400][141/142]\tLoss_D: 0.7490\tLoss_G: 2.2657 \tMSE_loss: 2.8649 \tTime: 0.0584\n",
      "Validation \tLoss_D: 0.9045\tLoss_G: 1.9534 \tMSE_loss: 3.7012 \tBest_loss: 3.6874\n",
      "[186/400][141/142]\tLoss_D: 0.6409\tLoss_G: 2.1177 \tMSE_loss: 3.3337 \tTime: 0.0538\n",
      "Validation \tLoss_D: 0.9021\tLoss_G: 2.0068 \tMSE_loss: 3.7285 \tBest_loss: 3.6874\n",
      "[187/400][141/142]\tLoss_D: 0.8424\tLoss_G: 2.1953 \tMSE_loss: 3.6756 \tTime: 0.0585\n",
      "Validation \tLoss_D: 0.9267\tLoss_G: 1.9433 \tMSE_loss: 3.7009 \tBest_loss: 3.6874\n",
      "[188/400][141/142]\tLoss_D: 0.6010\tLoss_G: 1.9958 \tMSE_loss: 3.4990 \tTime: 0.0590\n",
      "Validation \tLoss_D: 0.9443\tLoss_G: 1.8830 \tMSE_loss: 3.6909 \tBest_loss: 3.6874\n",
      "[189/400][141/142]\tLoss_D: 0.8931\tLoss_G: 1.8962 \tMSE_loss: 2.4780 \tTime: 0.0636\n",
      "Validation \tLoss_D: 0.9558\tLoss_G: 1.8932 \tMSE_loss: 3.6706 \tBest_loss: 3.6706\n",
      "[190/400][141/142]\tLoss_D: 0.5790\tLoss_G: 2.1359 \tMSE_loss: 3.7430 \tTime: 0.0591\n",
      "Validation \tLoss_D: 0.9834\tLoss_G: 1.8515 \tMSE_loss: 3.6735 \tBest_loss: 3.6706\n",
      "[191/400][141/142]\tLoss_D: 0.9620\tLoss_G: 2.2574 \tMSE_loss: 4.4391 \tTime: 0.0554\n",
      "Validation \tLoss_D: 0.9973\tLoss_G: 1.9650 \tMSE_loss: 3.6850 \tBest_loss: 3.6706\n",
      "[192/400][141/142]\tLoss_D: 0.5608\tLoss_G: 2.0993 \tMSE_loss: 3.3965 \tTime: 0.0564\n",
      "Validation \tLoss_D: 0.9741\tLoss_G: 1.8838 \tMSE_loss: 3.7094 \tBest_loss: 3.6706\n",
      "[193/400][141/142]\tLoss_D: 0.6787\tLoss_G: 2.1023 \tMSE_loss: 3.6854 \tTime: 0.0624\n",
      "Validation \tLoss_D: 0.9859\tLoss_G: 1.8910 \tMSE_loss: 3.7051 \tBest_loss: 3.6706\n",
      "[194/400][141/142]\tLoss_D: 0.7300\tLoss_G: 1.9617 \tMSE_loss: 3.2422 \tTime: 0.0639\n",
      "Validation \tLoss_D: 1.0216\tLoss_G: 1.8221 \tMSE_loss: 3.6906 \tBest_loss: 3.6706\n",
      "[195/400][141/142]\tLoss_D: 0.8178\tLoss_G: 2.4091 \tMSE_loss: 3.3892 \tTime: 0.0628\n",
      "Validation \tLoss_D: 1.0500\tLoss_G: 1.7754 \tMSE_loss: 3.6631 \tBest_loss: 3.6631\n",
      "[196/400][141/142]\tLoss_D: 0.9117\tLoss_G: 1.9738 \tMSE_loss: 5.1832 \tTime: 0.0574\n",
      "Validation \tLoss_D: 1.0120\tLoss_G: 1.9197 \tMSE_loss: 3.7075 \tBest_loss: 3.6631\n",
      "[197/400][141/142]\tLoss_D: 0.9936\tLoss_G: 1.9047 \tMSE_loss: 2.9719 \tTime: 0.0591\n",
      "Validation \tLoss_D: 1.0513\tLoss_G: 1.8220 \tMSE_loss: 3.6933 \tBest_loss: 3.6631\n",
      "[198/400][141/142]\tLoss_D: 0.8779\tLoss_G: 1.9986 \tMSE_loss: 4.2700 \tTime: 0.0574\n",
      "Validation \tLoss_D: 1.0437\tLoss_G: 1.8035 \tMSE_loss: 3.6855 \tBest_loss: 3.6631\n",
      "[199/400][141/142]\tLoss_D: 0.8034\tLoss_G: 2.4693 \tMSE_loss: 4.4491 \tTime: 0.0496\n",
      "Validation \tLoss_D: 1.0000\tLoss_G: 1.8585 \tMSE_loss: 3.7422 \tBest_loss: 3.6631\n",
      "[200/400][141/142]\tLoss_D: 0.7017\tLoss_G: 2.1184 \tMSE_loss: 4.4550 \tTime: 0.0609\n",
      "Validation \tLoss_D: 1.0616\tLoss_G: 1.7303 \tMSE_loss: 3.6686 \tBest_loss: 3.6631\n",
      "[201/400][141/142]\tLoss_D: 1.0545\tLoss_G: 1.7957 \tMSE_loss: 4.6471 \tTime: 0.0581\n",
      "Validation \tLoss_D: 1.0521\tLoss_G: 1.8316 \tMSE_loss: 3.7053 \tBest_loss: 3.6631\n",
      "[202/400][141/142]\tLoss_D: 0.6935\tLoss_G: 2.1612 \tMSE_loss: 4.2557 \tTime: 0.0597\n",
      "Validation \tLoss_D: 1.0665\tLoss_G: 1.8443 \tMSE_loss: 3.7001 \tBest_loss: 3.6631\n",
      "[203/400][141/142]\tLoss_D: 0.6054\tLoss_G: 2.3863 \tMSE_loss: 8.1225 \tTime: 0.0603\n",
      "Validation \tLoss_D: 1.0497\tLoss_G: 1.8108 \tMSE_loss: 3.7397 \tBest_loss: 3.6631\n",
      "[204/400][141/142]\tLoss_D: 0.8518\tLoss_G: 2.0687 \tMSE_loss: 2.8722 \tTime: 0.0491\n",
      "Validation \tLoss_D: 1.0497\tLoss_G: 1.7991 \tMSE_loss: 3.7415 \tBest_loss: 3.6631\n",
      "[205/400][141/142]\tLoss_D: 0.8360\tLoss_G: 1.8767 \tMSE_loss: 3.0813 \tTime: 0.0503\n",
      "Validation \tLoss_D: 1.0696\tLoss_G: 1.7600 \tMSE_loss: 3.7012 \tBest_loss: 3.6631\n",
      "[206/400][141/142]\tLoss_D: 0.9131\tLoss_G: 1.9050 \tMSE_loss: 3.4076 \tTime: 0.0554\n",
      "Validation \tLoss_D: 1.0629\tLoss_G: 1.8014 \tMSE_loss: 3.7147 \tBest_loss: 3.6631\n",
      "[207/400][141/142]\tLoss_D: 0.6497\tLoss_G: 2.1509 \tMSE_loss: 4.6661 \tTime: 0.0526\n",
      "Validation \tLoss_D: 1.1027\tLoss_G: 1.7145 \tMSE_loss: 3.6763 \tBest_loss: 3.6631\n",
      "[208/400][141/142]\tLoss_D: 0.6780\tLoss_G: 2.3134 \tMSE_loss: 5.7239 \tTime: 0.0587\n",
      "Validation \tLoss_D: 1.0685\tLoss_G: 1.7536 \tMSE_loss: 3.7307 \tBest_loss: 3.6631\n",
      "[209/400][141/142]\tLoss_D: 0.8649\tLoss_G: 2.0452 \tMSE_loss: 3.7656 \tTime: 0.0583\n",
      "Validation \tLoss_D: 1.1226\tLoss_G: 1.6853 \tMSE_loss: 3.6759 \tBest_loss: 3.6631\n",
      "[210/400][141/142]\tLoss_D: 0.7742\tLoss_G: 2.1450 \tMSE_loss: 4.6164 \tTime: 0.0595\n",
      "Validation \tLoss_D: 1.1090\tLoss_G: 1.7119 \tMSE_loss: 3.6789 \tBest_loss: 3.6631\n",
      "[211/400][141/142]\tLoss_D: 0.8151\tLoss_G: 2.3920 \tMSE_loss: 5.7905 \tTime: 0.0557\n",
      "Validation \tLoss_D: 1.0826\tLoss_G: 1.7245 \tMSE_loss: 3.7519 \tBest_loss: 3.6631\n",
      "[212/400][141/142]\tLoss_D: 0.8309\tLoss_G: 1.6366 \tMSE_loss: 3.7446 \tTime: 0.0528\n",
      "Validation \tLoss_D: 1.1147\tLoss_G: 1.6292 \tMSE_loss: 3.6888 \tBest_loss: 3.6631\n",
      "[213/400][141/142]\tLoss_D: 0.7817\tLoss_G: 2.0720 \tMSE_loss: 4.5397 \tTime: 0.0564\n",
      "Validation \tLoss_D: 1.1319\tLoss_G: 1.6880 \tMSE_loss: 3.6871 \tBest_loss: 3.6631\n",
      "[214/400][141/142]\tLoss_D: 0.7938\tLoss_G: 1.7777 \tMSE_loss: 2.6525 \tTime: 0.0583\n",
      "Validation \tLoss_D: 1.1364\tLoss_G: 1.6924 \tMSE_loss: 3.6855 \tBest_loss: 3.6631\n",
      "[215/400][141/142]\tLoss_D: 0.7338\tLoss_G: 1.8891 \tMSE_loss: 4.4969 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.1269\tLoss_G: 1.6455 \tMSE_loss: 3.6859 \tBest_loss: 3.6631\n",
      "[216/400][141/142]\tLoss_D: 0.9806\tLoss_G: 2.1672 \tMSE_loss: 3.2052 \tTime: 0.0563\n",
      "Validation \tLoss_D: 1.1351\tLoss_G: 1.7149 \tMSE_loss: 3.6913 \tBest_loss: 3.6631\n",
      "[217/400][141/142]\tLoss_D: 0.8835\tLoss_G: 1.8730 \tMSE_loss: 2.7409 \tTime: 0.0494\n",
      "Validation \tLoss_D: 1.1160\tLoss_G: 1.6736 \tMSE_loss: 3.7053 \tBest_loss: 3.6631\n",
      "[218/400][141/142]\tLoss_D: 0.8457\tLoss_G: 1.7448 \tMSE_loss: 4.0824 \tTime: 0.0606\n",
      "Validation \tLoss_D: 1.1249\tLoss_G: 1.6538 \tMSE_loss: 3.6965 \tBest_loss: 3.6631\n",
      "[219/400][141/142]\tLoss_D: 0.7773\tLoss_G: 2.3037 \tMSE_loss: 6.1615 \tTime: 0.0589\n",
      "Validation \tLoss_D: 1.1757\tLoss_G: 1.6641 \tMSE_loss: 3.6681 \tBest_loss: 3.6631\n",
      "[220/400][141/142]\tLoss_D: 0.8614\tLoss_G: 1.7810 \tMSE_loss: 4.5651 \tTime: 0.0539\n",
      "Validation \tLoss_D: 1.1585\tLoss_G: 1.6104 \tMSE_loss: 3.6958 \tBest_loss: 3.6631\n",
      "[221/400][141/142]\tLoss_D: 0.7200\tLoss_G: 1.8746 \tMSE_loss: 4.5372 \tTime: 0.0603\n",
      "Validation \tLoss_D: 1.2196\tLoss_G: 1.5393 \tMSE_loss: 3.6349 \tBest_loss: 3.6349\n",
      "[222/400][141/142]\tLoss_D: 1.0074\tLoss_G: 1.9122 \tMSE_loss: 3.2023 \tTime: 0.0486\n",
      "Validation \tLoss_D: 1.1816\tLoss_G: 1.6630 \tMSE_loss: 3.6868 \tBest_loss: 3.6349\n",
      "[223/400][141/142]\tLoss_D: 0.6698\tLoss_G: 1.9040 \tMSE_loss: 3.4634 \tTime: 0.0534\n",
      "Validation \tLoss_D: 1.1908\tLoss_G: 1.5979 \tMSE_loss: 3.6627 \tBest_loss: 3.6349\n",
      "[224/400][141/142]\tLoss_D: 0.6013\tLoss_G: 2.0980 \tMSE_loss: 3.8389 \tTime: 0.0589\n",
      "Validation \tLoss_D: 1.1544\tLoss_G: 1.6045 \tMSE_loss: 3.7151 \tBest_loss: 3.6349\n",
      "[225/400][141/142]\tLoss_D: 0.8022\tLoss_G: 1.8059 \tMSE_loss: 9.5304 \tTime: 0.0617\n",
      "Validation \tLoss_D: 1.1736\tLoss_G: 1.5305 \tMSE_loss: 3.6876 \tBest_loss: 3.6349\n",
      "[226/400][141/142]\tLoss_D: 0.8084\tLoss_G: 1.9264 \tMSE_loss: 6.4552 \tTime: 0.0494\n",
      "Validation \tLoss_D: 1.1766\tLoss_G: 1.6254 \tMSE_loss: 3.6999 \tBest_loss: 3.6349\n",
      "[227/400][141/142]\tLoss_D: 1.2247\tLoss_G: 1.6149 \tMSE_loss: 3.7993 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.2360\tLoss_G: 1.5269 \tMSE_loss: 3.6391 \tBest_loss: 3.6349\n",
      "[228/400][141/142]\tLoss_D: 0.7738\tLoss_G: 2.2669 \tMSE_loss: 3.6500 \tTime: 0.0631\n",
      "Validation \tLoss_D: 1.1993\tLoss_G: 1.5478 \tMSE_loss: 3.7028 \tBest_loss: 3.6349\n",
      "[229/400][141/142]\tLoss_D: 0.7561\tLoss_G: 2.1930 \tMSE_loss: 6.5878 \tTime: 0.0533\n",
      "Validation \tLoss_D: 1.1900\tLoss_G: 1.5574 \tMSE_loss: 3.6824 \tBest_loss: 3.6349\n",
      "[230/400][141/142]\tLoss_D: 0.9886\tLoss_G: 1.9871 \tMSE_loss: 5.6866 \tTime: 0.0614\n",
      "Validation \tLoss_D: 1.2355\tLoss_G: 1.5061 \tMSE_loss: 3.6622 \tBest_loss: 3.6349\n",
      "[231/400][141/142]\tLoss_D: 0.8718\tLoss_G: 1.8150 \tMSE_loss: 4.1773 \tTime: 0.0588\n",
      "Validation \tLoss_D: 1.2087\tLoss_G: 1.5766 \tMSE_loss: 3.6937 \tBest_loss: 3.6349\n",
      "[232/400][141/142]\tLoss_D: 1.0789\tLoss_G: 1.7133 \tMSE_loss: 4.9327 \tTime: 0.0598\n",
      "Validation \tLoss_D: 1.2254\tLoss_G: 1.5323 \tMSE_loss: 3.6707 \tBest_loss: 3.6349\n",
      "[233/400][141/142]\tLoss_D: 0.9945\tLoss_G: 1.7746 \tMSE_loss: 5.8576 \tTime: 0.0414\n",
      "Validation \tLoss_D: 1.2277\tLoss_G: 1.5167 \tMSE_loss: 3.6720 \tBest_loss: 3.6349\n",
      "[234/400][141/142]\tLoss_D: 0.9045\tLoss_G: 1.6071 \tMSE_loss: 3.5746 \tTime: 0.0567\n",
      "Validation \tLoss_D: 1.2411\tLoss_G: 1.4984 \tMSE_loss: 3.6677 \tBest_loss: 3.6349\n",
      "[235/400][141/142]\tLoss_D: 0.8387\tLoss_G: 1.7288 \tMSE_loss: 3.1362 \tTime: 0.0543\n",
      "Validation \tLoss_D: 1.1761\tLoss_G: 1.6117 \tMSE_loss: 3.7915 \tBest_loss: 3.6349\n",
      "[236/400][141/142]\tLoss_D: 1.0180\tLoss_G: 2.1157 \tMSE_loss: 3.6504 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.2467\tLoss_G: 1.5138 \tMSE_loss: 3.7124 \tBest_loss: 3.6349\n",
      "[237/400][141/142]\tLoss_D: 0.8196\tLoss_G: 2.3535 \tMSE_loss: 4.4764 \tTime: 0.0596\n",
      "Validation \tLoss_D: 1.2324\tLoss_G: 1.5522 \tMSE_loss: 3.6896 \tBest_loss: 3.6349\n",
      "[238/400][141/142]\tLoss_D: 0.9664\tLoss_G: 2.3874 \tMSE_loss: 4.2861 \tTime: 0.0605\n",
      "Validation \tLoss_D: 1.2462\tLoss_G: 1.5061 \tMSE_loss: 3.7087 \tBest_loss: 3.6349\n",
      "[239/400][141/142]\tLoss_D: 0.9011\tLoss_G: 2.0023 \tMSE_loss: 5.0840 \tTime: 0.0512\n",
      "Validation \tLoss_D: 1.1926\tLoss_G: 1.6133 \tMSE_loss: 3.7473 \tBest_loss: 3.6349\n",
      "[240/400][141/142]\tLoss_D: 0.8584\tLoss_G: 2.0308 \tMSE_loss: 4.5083 \tTime: 0.0498\n",
      "Validation \tLoss_D: 1.2676\tLoss_G: 1.4910 \tMSE_loss: 3.6818 \tBest_loss: 3.6349\n",
      "[241/400][141/142]\tLoss_D: 0.8484\tLoss_G: 1.8515 \tMSE_loss: 4.9364 \tTime: 0.0595\n",
      "Validation \tLoss_D: 1.2338\tLoss_G: 1.5614 \tMSE_loss: 3.7178 \tBest_loss: 3.6349\n",
      "[242/400][141/142]\tLoss_D: 0.9127\tLoss_G: 1.8368 \tMSE_loss: 5.2755 \tTime: 0.0626\n",
      "Validation \tLoss_D: 1.2565\tLoss_G: 1.5084 \tMSE_loss: 3.6837 \tBest_loss: 3.6349\n",
      "[243/400][141/142]\tLoss_D: 0.9389\tLoss_G: 1.8567 \tMSE_loss: 4.7544 \tTime: 0.0575\n",
      "Validation \tLoss_D: 1.2534\tLoss_G: 1.5237 \tMSE_loss: 3.6998 \tBest_loss: 3.6349\n",
      "[244/400][141/142]\tLoss_D: 0.7816\tLoss_G: 1.5181 \tMSE_loss: 4.0382 \tTime: 0.0609\n",
      "Validation \tLoss_D: 1.2587\tLoss_G: 1.5018 \tMSE_loss: 3.7038 \tBest_loss: 3.6349\n",
      "[245/400][141/142]\tLoss_D: 0.7547\tLoss_G: 2.1925 \tMSE_loss: 2.9064 \tTime: 0.0468\n",
      "Validation \tLoss_D: 1.3141\tLoss_G: 1.4310 \tMSE_loss: 3.6617 \tBest_loss: 3.6349\n",
      "[246/400][141/142]\tLoss_D: 1.0220\tLoss_G: 1.9403 \tMSE_loss: 3.9635 \tTime: 0.0548\n",
      "Validation \tLoss_D: 1.2943\tLoss_G: 1.5183 \tMSE_loss: 3.6773 \tBest_loss: 3.6349\n",
      "[247/400][141/142]\tLoss_D: 0.9085\tLoss_G: 1.8029 \tMSE_loss: 5.3313 \tTime: 0.0527\n",
      "Validation \tLoss_D: 1.2371\tLoss_G: 1.5570 \tMSE_loss: 3.7470 \tBest_loss: 3.6349\n",
      "[248/400][141/142]\tLoss_D: 0.6566\tLoss_G: 2.1694 \tMSE_loss: 5.1149 \tTime: 0.0555\n",
      "Validation \tLoss_D: 1.2855\tLoss_G: 1.5306 \tMSE_loss: 3.7099 \tBest_loss: 3.6349\n",
      "[249/400][141/142]\tLoss_D: 0.7509\tLoss_G: 2.1079 \tMSE_loss: 6.2539 \tTime: 0.0553\n",
      "Validation \tLoss_D: 1.2138\tLoss_G: 1.6784 \tMSE_loss: 3.8163 \tBest_loss: 3.6349\n",
      "[250/400][141/142]\tLoss_D: 0.9789\tLoss_G: 1.9753 \tMSE_loss: 5.0985 \tTime: 0.0534\n",
      "Validation \tLoss_D: 1.2749\tLoss_G: 1.5249 \tMSE_loss: 3.7289 \tBest_loss: 3.6349\n",
      "[251/400][141/142]\tLoss_D: 0.7856\tLoss_G: 1.8616 \tMSE_loss: 2.4341 \tTime: 0.0523\n",
      "Validation \tLoss_D: 1.2972\tLoss_G: 1.4515 \tMSE_loss: 3.6949 \tBest_loss: 3.6349\n",
      "[252/400][141/142]\tLoss_D: 0.7752\tLoss_G: 1.8228 \tMSE_loss: 5.6176 \tTime: 0.0638\n",
      "Validation \tLoss_D: 1.2604\tLoss_G: 1.6246 \tMSE_loss: 3.7537 \tBest_loss: 3.6349\n",
      "[253/400][141/142]\tLoss_D: 0.9873\tLoss_G: 1.8769 \tMSE_loss: 5.2774 \tTime: 0.0608\n",
      "Validation \tLoss_D: 1.2870\tLoss_G: 1.5217 \tMSE_loss: 3.7542 \tBest_loss: 3.6349\n",
      "[254/400][141/142]\tLoss_D: 0.6029\tLoss_G: 2.2749 \tMSE_loss: 3.1037 \tTime: 0.0597\n",
      "Validation \tLoss_D: 1.2499\tLoss_G: 1.6147 \tMSE_loss: 3.7481 \tBest_loss: 3.6349\n",
      "[255/400][141/142]\tLoss_D: 0.8778\tLoss_G: 1.9614 \tMSE_loss: 4.3087 \tTime: 0.0530\n",
      "Validation \tLoss_D: 1.3444\tLoss_G: 1.5041 \tMSE_loss: 3.6845 \tBest_loss: 3.6349\n",
      "[256/400][141/142]\tLoss_D: 0.8922\tLoss_G: 2.4998 \tMSE_loss: 4.7053 \tTime: 0.0538\n",
      "Validation \tLoss_D: 1.3052\tLoss_G: 1.5769 \tMSE_loss: 3.7072 \tBest_loss: 3.6349\n",
      "[257/400][141/142]\tLoss_D: 0.7075\tLoss_G: 2.3598 \tMSE_loss: 4.0419 \tTime: 0.0573\n",
      "Validation \tLoss_D: 1.3114\tLoss_G: 1.5532 \tMSE_loss: 3.7130 \tBest_loss: 3.6349\n",
      "[258/400][141/142]\tLoss_D: 0.7369\tLoss_G: 2.0694 \tMSE_loss: 3.7935 \tTime: 0.0607\n",
      "Validation \tLoss_D: 1.2991\tLoss_G: 1.5626 \tMSE_loss: 3.7250 \tBest_loss: 3.6349\n",
      "[259/400][141/142]\tLoss_D: 0.8722\tLoss_G: 2.2559 \tMSE_loss: 3.8333 \tTime: 0.0512\n",
      "Validation \tLoss_D: 1.2671\tLoss_G: 1.6328 \tMSE_loss: 3.7718 \tBest_loss: 3.6349\n",
      "[260/400][141/142]\tLoss_D: 0.8652\tLoss_G: 1.9447 \tMSE_loss: 4.4097 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.3651\tLoss_G: 1.5030 \tMSE_loss: 3.6983 \tBest_loss: 3.6349\n",
      "[261/400][141/142]\tLoss_D: 0.7277\tLoss_G: 1.9402 \tMSE_loss: 4.9785 \tTime: 0.0566\n",
      "Validation \tLoss_D: 1.2956\tLoss_G: 1.5728 \tMSE_loss: 3.7233 \tBest_loss: 3.6349\n",
      "[262/400][141/142]\tLoss_D: 0.6212\tLoss_G: 2.4611 \tMSE_loss: 8.1882 \tTime: 0.0620\n",
      "Validation \tLoss_D: 1.2662\tLoss_G: 1.6100 \tMSE_loss: 3.8317 \tBest_loss: 3.6349\n",
      "[263/400][141/142]\tLoss_D: 0.7936\tLoss_G: 2.1172 \tMSE_loss: 5.3080 \tTime: 0.0578\n",
      "Validation \tLoss_D: 1.3490\tLoss_G: 1.5742 \tMSE_loss: 3.7162 \tBest_loss: 3.6349\n",
      "[264/400][141/142]\tLoss_D: 0.8748\tLoss_G: 1.7199 \tMSE_loss: 4.7442 \tTime: 0.0565\n",
      "Validation \tLoss_D: 1.3393\tLoss_G: 1.4668 \tMSE_loss: 3.7188 \tBest_loss: 3.6349\n",
      "[265/400][141/142]\tLoss_D: 0.9487\tLoss_G: 2.4274 \tMSE_loss: 4.2962 \tTime: 0.0543\n",
      "Validation \tLoss_D: 1.3054\tLoss_G: 1.5398 \tMSE_loss: 3.7561 \tBest_loss: 3.6349\n",
      "[266/400][141/142]\tLoss_D: 0.8300\tLoss_G: 1.8698 \tMSE_loss: 3.8647 \tTime: 0.0581\n",
      "Validation \tLoss_D: 1.3367\tLoss_G: 1.5470 \tMSE_loss: 3.7647 \tBest_loss: 3.6349\n",
      "[267/400][141/142]\tLoss_D: 1.2248\tLoss_G: 1.8966 \tMSE_loss: 2.9083 \tTime: 0.0548\n",
      "Validation \tLoss_D: 1.3056\tLoss_G: 1.6356 \tMSE_loss: 3.7963 \tBest_loss: 3.6349\n",
      "[268/400][141/142]\tLoss_D: 0.7041\tLoss_G: 2.3811 \tMSE_loss: 3.9438 \tTime: 0.0559\n",
      "Validation \tLoss_D: 1.3351\tLoss_G: 1.5536 \tMSE_loss: 3.7719 \tBest_loss: 3.6349\n",
      "[269/400][141/142]\tLoss_D: 0.7377\tLoss_G: 2.1985 \tMSE_loss: 4.6640 \tTime: 0.0576\n",
      "Validation \tLoss_D: 1.3043\tLoss_G: 1.5503 \tMSE_loss: 3.7872 \tBest_loss: 3.6349\n",
      "[270/400][141/142]\tLoss_D: 0.9484\tLoss_G: 2.1811 \tMSE_loss: 3.4009 \tTime: 0.0627\n",
      "Validation \tLoss_D: 1.3550\tLoss_G: 1.5104 \tMSE_loss: 3.7428 \tBest_loss: 3.6349\n",
      "[271/400][141/142]\tLoss_D: 0.7219\tLoss_G: 2.0182 \tMSE_loss: 3.2947 \tTime: 0.0569\n",
      "Validation \tLoss_D: 1.2603\tLoss_G: 1.6444 \tMSE_loss: 3.8784 \tBest_loss: 3.6349\n",
      "[272/400][141/142]\tLoss_D: 0.6196\tLoss_G: 2.0787 \tMSE_loss: 3.3450 \tTime: 0.0650\n",
      "Validation \tLoss_D: 1.3334\tLoss_G: 1.5648 \tMSE_loss: 3.7939 \tBest_loss: 3.6349\n",
      "[273/400][141/142]\tLoss_D: 0.7959\tLoss_G: 1.8009 \tMSE_loss: 3.3084 \tTime: 0.0531\n",
      "Validation \tLoss_D: 1.3297\tLoss_G: 1.5337 \tMSE_loss: 3.7923 \tBest_loss: 3.6349\n",
      "[274/400][141/142]\tLoss_D: 0.8427\tLoss_G: 1.8825 \tMSE_loss: 3.0840 \tTime: 0.0570\n",
      "Validation \tLoss_D: 1.3020\tLoss_G: 1.6148 \tMSE_loss: 3.7949 \tBest_loss: 3.6349\n",
      "[275/400][141/142]\tLoss_D: 0.9005\tLoss_G: 1.8650 \tMSE_loss: 5.1492 \tTime: 0.0587\n",
      "Validation \tLoss_D: 1.3253\tLoss_G: 1.6499 \tMSE_loss: 3.7939 \tBest_loss: 3.6349\n",
      "[276/400][141/142]\tLoss_D: 0.8323\tLoss_G: 2.6057 \tMSE_loss: 4.4513 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.3373\tLoss_G: 1.5369 \tMSE_loss: 3.8088 \tBest_loss: 3.6349\n",
      "[277/400][141/142]\tLoss_D: 0.7787\tLoss_G: 2.4862 \tMSE_loss: 7.2031 \tTime: 0.0544\n",
      "Validation \tLoss_D: 1.2626\tLoss_G: 1.8007 \tMSE_loss: 3.8806 \tBest_loss: 3.6349\n",
      "[278/400][141/142]\tLoss_D: 0.7747\tLoss_G: 2.1939 \tMSE_loss: 6.5412 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.2896\tLoss_G: 1.6635 \tMSE_loss: 3.8485 \tBest_loss: 3.6349\n",
      "[279/400][141/142]\tLoss_D: 0.8800\tLoss_G: 1.5982 \tMSE_loss: 4.7287 \tTime: 0.0661\n",
      "Validation \tLoss_D: 1.3344\tLoss_G: 1.6230 \tMSE_loss: 3.8028 \tBest_loss: 3.6349\n",
      "[280/400][141/142]\tLoss_D: 0.7841\tLoss_G: 1.6908 \tMSE_loss: 4.5639 \tTime: 0.0478\n",
      "Validation \tLoss_D: 1.3047\tLoss_G: 1.6553 \tMSE_loss: 3.8310 \tBest_loss: 3.6349\n",
      "[281/400][141/142]\tLoss_D: 0.6625\tLoss_G: 2.0665 \tMSE_loss: 4.4468 \tTime: 0.0558\n",
      "Validation \tLoss_D: 1.3048\tLoss_G: 1.6363 \tMSE_loss: 3.8461 \tBest_loss: 3.6349\n",
      "[282/400][141/142]\tLoss_D: 0.6782\tLoss_G: 2.1928 \tMSE_loss: 3.1097 \tTime: 0.0607\n",
      "Validation \tLoss_D: 1.3329\tLoss_G: 1.5863 \tMSE_loss: 3.8145 \tBest_loss: 3.6349\n",
      "[283/400][141/142]\tLoss_D: 0.8873\tLoss_G: 2.2984 \tMSE_loss: 3.6434 \tTime: 0.0566\n",
      "Validation \tLoss_D: 1.3142\tLoss_G: 1.6290 \tMSE_loss: 3.8374 \tBest_loss: 3.6349\n",
      "[284/400][141/142]\tLoss_D: 0.6234\tLoss_G: 1.8234 \tMSE_loss: 3.6366 \tTime: 0.0492\n",
      "Validation \tLoss_D: 1.3333\tLoss_G: 1.5759 \tMSE_loss: 3.8299 \tBest_loss: 3.6349\n",
      "[285/400][141/142]\tLoss_D: 0.8029\tLoss_G: 2.4743 \tMSE_loss: 5.8303 \tTime: 0.0628\n",
      "Validation \tLoss_D: 1.3205\tLoss_G: 1.6785 \tMSE_loss: 3.8307 \tBest_loss: 3.6349\n",
      "[286/400][141/142]\tLoss_D: 0.5224\tLoss_G: 2.6179 \tMSE_loss: 7.0685 \tTime: 0.0603\n",
      "Validation \tLoss_D: 1.3610\tLoss_G: 1.6605 \tMSE_loss: 3.8066 \tBest_loss: 3.6349\n",
      "[287/400][141/142]\tLoss_D: 0.6981\tLoss_G: 2.2546 \tMSE_loss: 5.2635 \tTime: 0.0556\n",
      "Validation \tLoss_D: 1.3139\tLoss_G: 1.6015 \tMSE_loss: 3.8511 \tBest_loss: 3.6349\n",
      "[288/400][141/142]\tLoss_D: 0.5631\tLoss_G: 2.0989 \tMSE_loss: 6.5295 \tTime: 0.0512\n",
      "Validation \tLoss_D: 1.3251\tLoss_G: 1.7355 \tMSE_loss: 3.8461 \tBest_loss: 3.6349\n",
      "[289/400][141/142]\tLoss_D: 0.7948\tLoss_G: 2.0382 \tMSE_loss: 4.0729 \tTime: 0.0619\n",
      "Validation \tLoss_D: 1.3370\tLoss_G: 1.6684 \tMSE_loss: 3.8359 \tBest_loss: 3.6349\n",
      "[290/400][141/142]\tLoss_D: 0.9174\tLoss_G: 2.1037 \tMSE_loss: 3.9195 \tTime: 0.0584\n",
      "Validation \tLoss_D: 1.3008\tLoss_G: 1.7688 \tMSE_loss: 3.9017 \tBest_loss: 3.6349\n",
      "[291/400][141/142]\tLoss_D: 0.8298\tLoss_G: 2.0387 \tMSE_loss: 4.9878 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.3072\tLoss_G: 1.6697 \tMSE_loss: 3.8722 \tBest_loss: 3.6349\n",
      "[292/400][141/142]\tLoss_D: 0.7419\tLoss_G: 2.4480 \tMSE_loss: 3.7388 \tTime: 0.0564\n",
      "Validation \tLoss_D: 1.3104\tLoss_G: 1.7212 \tMSE_loss: 3.8907 \tBest_loss: 3.6349\n",
      "[293/400][141/142]\tLoss_D: 0.6834\tLoss_G: 3.0731 \tMSE_loss: 5.0446 \tTime: 0.0526\n",
      "Validation \tLoss_D: 1.2779\tLoss_G: 1.7754 \tMSE_loss: 3.8749 \tBest_loss: 3.6349\n",
      "[294/400][141/142]\tLoss_D: 0.8226\tLoss_G: 2.3280 \tMSE_loss: 5.6452 \tTime: 0.0588\n",
      "Validation \tLoss_D: 1.3129\tLoss_G: 1.6814 \tMSE_loss: 3.8683 \tBest_loss: 3.6349\n",
      "[295/400][141/142]\tLoss_D: 0.6381\tLoss_G: 2.9879 \tMSE_loss: 4.3979 \tTime: 0.0524\n",
      "Validation \tLoss_D: 1.3009\tLoss_G: 1.7351 \tMSE_loss: 3.9055 \tBest_loss: 3.6349\n",
      "[296/400][141/142]\tLoss_D: 0.5550\tLoss_G: 1.7641 \tMSE_loss: 8.4603 \tTime: 0.0576\n",
      "Validation \tLoss_D: 1.3435\tLoss_G: 1.6865 \tMSE_loss: 3.8481 \tBest_loss: 3.6349\n",
      "[297/400][141/142]\tLoss_D: 0.8096\tLoss_G: 2.3395 \tMSE_loss: 3.2016 \tTime: 0.0541\n",
      "Validation \tLoss_D: 1.3459\tLoss_G: 1.7141 \tMSE_loss: 3.8533 \tBest_loss: 3.6349\n",
      "[298/400][141/142]\tLoss_D: 1.1610\tLoss_G: 1.6332 \tMSE_loss: 3.2763 \tTime: 0.0566\n",
      "Validation \tLoss_D: 1.3163\tLoss_G: 1.6864 \tMSE_loss: 3.9099 \tBest_loss: 3.6349\n",
      "[299/400][141/142]\tLoss_D: 0.6956\tLoss_G: 2.1768 \tMSE_loss: 5.9818 \tTime: 0.0602\n",
      "Validation \tLoss_D: 1.3465\tLoss_G: 1.6082 \tMSE_loss: 3.8582 \tBest_loss: 3.6349\n",
      "[300/400][141/142]\tLoss_D: 0.6979\tLoss_G: 1.9949 \tMSE_loss: 4.9729 \tTime: 0.0564\n",
      "Validation \tLoss_D: 1.3384\tLoss_G: 1.6984 \tMSE_loss: 3.8735 \tBest_loss: 3.6349\n",
      "[301/400][141/142]\tLoss_D: 0.6980\tLoss_G: 2.1845 \tMSE_loss: 3.9088 \tTime: 0.0557\n",
      "Validation \tLoss_D: 1.3401\tLoss_G: 1.6988 \tMSE_loss: 3.8673 \tBest_loss: 3.6349\n",
      "[302/400][141/142]\tLoss_D: 0.7535\tLoss_G: 2.4382 \tMSE_loss: 4.2908 \tTime: 0.0526\n",
      "Validation \tLoss_D: 1.3669\tLoss_G: 1.6899 \tMSE_loss: 3.8274 \tBest_loss: 3.6349\n",
      "[303/400][141/142]\tLoss_D: 0.7682\tLoss_G: 2.1899 \tMSE_loss: 3.3607 \tTime: 0.0494\n",
      "Validation \tLoss_D: 1.3491\tLoss_G: 1.6658 \tMSE_loss: 3.8773 \tBest_loss: 3.6349\n",
      "[304/400][141/142]\tLoss_D: 0.6176\tLoss_G: 2.6772 \tMSE_loss: 3.0192 \tTime: 0.0572\n",
      "Validation \tLoss_D: 1.3537\tLoss_G: 1.6862 \tMSE_loss: 3.8520 \tBest_loss: 3.6349\n",
      "[305/400][141/142]\tLoss_D: 0.5786\tLoss_G: 2.1385 \tMSE_loss: 4.3601 \tTime: 0.0512\n",
      "Validation \tLoss_D: 1.3280\tLoss_G: 1.7963 \tMSE_loss: 3.8911 \tBest_loss: 3.6349\n",
      "[306/400][141/142]\tLoss_D: 0.6694\tLoss_G: 2.8683 \tMSE_loss: 4.7087 \tTime: 0.0509\n",
      "Validation \tLoss_D: 1.3090\tLoss_G: 1.8856 \tMSE_loss: 3.9055 \tBest_loss: 3.6349\n",
      "[307/400][141/142]\tLoss_D: 0.6429\tLoss_G: 2.5657 \tMSE_loss: 4.3212 \tTime: 0.0613\n",
      "Validation \tLoss_D: 1.3364\tLoss_G: 1.7491 \tMSE_loss: 3.8975 \tBest_loss: 3.6349\n",
      "[308/400][141/142]\tLoss_D: 0.5796\tLoss_G: 2.6505 \tMSE_loss: 5.2358 \tTime: 0.0482\n",
      "Validation \tLoss_D: 1.2971\tLoss_G: 1.8212 \tMSE_loss: 3.9471 \tBest_loss: 3.6349\n",
      "[309/400][141/142]\tLoss_D: 0.7603\tLoss_G: 2.0548 \tMSE_loss: 3.8610 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.3387\tLoss_G: 1.7269 \tMSE_loss: 3.9052 \tBest_loss: 3.6349\n",
      "[310/400][141/142]\tLoss_D: 0.7546\tLoss_G: 2.9188 \tMSE_loss: 4.1679 \tTime: 0.0550\n",
      "Validation \tLoss_D: 1.3766\tLoss_G: 1.6803 \tMSE_loss: 3.8713 \tBest_loss: 3.6349\n",
      "[311/400][141/142]\tLoss_D: 0.6022\tLoss_G: 2.1196 \tMSE_loss: 5.1591 \tTime: 0.0635\n",
      "Validation \tLoss_D: 1.3569\tLoss_G: 1.7528 \tMSE_loss: 3.8859 \tBest_loss: 3.6349\n",
      "[312/400][141/142]\tLoss_D: 0.5810\tLoss_G: 2.4056 \tMSE_loss: 3.8310 \tTime: 0.0564\n",
      "Validation \tLoss_D: 1.3920\tLoss_G: 1.6782 \tMSE_loss: 3.8807 \tBest_loss: 3.6349\n",
      "[313/400][141/142]\tLoss_D: 0.6520\tLoss_G: 2.1196 \tMSE_loss: 4.7479 \tTime: 0.0495\n",
      "Validation \tLoss_D: 1.3608\tLoss_G: 1.6760 \tMSE_loss: 3.8994 \tBest_loss: 3.6349\n",
      "[314/400][141/142]\tLoss_D: 0.6495\tLoss_G: 2.3428 \tMSE_loss: 5.6107 \tTime: 0.0540\n",
      "Validation \tLoss_D: 1.3387\tLoss_G: 1.7818 \tMSE_loss: 3.9389 \tBest_loss: 3.6349\n",
      "[315/400][141/142]\tLoss_D: 0.5829\tLoss_G: 2.2473 \tMSE_loss: 3.4924 \tTime: 0.0569\n",
      "Validation \tLoss_D: 1.3144\tLoss_G: 1.8253 \tMSE_loss: 3.9370 \tBest_loss: 3.6349\n",
      "[316/400][141/142]\tLoss_D: 0.7110\tLoss_G: 2.4086 \tMSE_loss: 4.4824 \tTime: 0.0508\n",
      "Validation \tLoss_D: 1.3502\tLoss_G: 1.8984 \tMSE_loss: 3.9431 \tBest_loss: 3.6349\n",
      "[317/400][141/142]\tLoss_D: 0.8669\tLoss_G: 2.2905 \tMSE_loss: 4.3303 \tTime: 0.0505\n",
      "Validation \tLoss_D: 1.3589\tLoss_G: 1.7925 \tMSE_loss: 3.9139 \tBest_loss: 3.6349\n",
      "[318/400][141/142]\tLoss_D: 0.7301\tLoss_G: 2.6804 \tMSE_loss: 5.7773 \tTime: 0.0542\n",
      "Validation \tLoss_D: 1.3456\tLoss_G: 1.8435 \tMSE_loss: 3.9043 \tBest_loss: 3.6349\n",
      "[319/400][141/142]\tLoss_D: 0.7300\tLoss_G: 2.4824 \tMSE_loss: 5.7646 \tTime: 0.0566\n",
      "Validation \tLoss_D: 1.3408\tLoss_G: 1.8023 \tMSE_loss: 3.9628 \tBest_loss: 3.6349\n",
      "[320/400][141/142]\tLoss_D: 0.6603\tLoss_G: 2.4350 \tMSE_loss: 8.7348 \tTime: 0.0504\n",
      "Validation \tLoss_D: 1.3348\tLoss_G: 1.8815 \tMSE_loss: 3.9870 \tBest_loss: 3.6349\n",
      "[321/400][141/142]\tLoss_D: 0.7205\tLoss_G: 2.5720 \tMSE_loss: 5.0989 \tTime: 0.0520\n",
      "Validation \tLoss_D: 1.3290\tLoss_G: 1.7932 \tMSE_loss: 3.9935 \tBest_loss: 3.6349\n",
      "[322/400][141/142]\tLoss_D: 0.7896\tLoss_G: 2.3851 \tMSE_loss: 3.9207 \tTime: 0.0618\n",
      "Validation \tLoss_D: 1.4268\tLoss_G: 1.8068 \tMSE_loss: 3.8693 \tBest_loss: 3.6349\n",
      "[323/400][141/142]\tLoss_D: 0.8333\tLoss_G: 2.3012 \tMSE_loss: 4.8473 \tTime: 0.0552\n",
      "Validation \tLoss_D: 1.3630\tLoss_G: 1.8682 \tMSE_loss: 3.9678 \tBest_loss: 3.6349\n",
      "[324/400][141/142]\tLoss_D: 0.6401\tLoss_G: 2.4919 \tMSE_loss: 4.5034 \tTime: 0.0595\n",
      "Validation \tLoss_D: 1.3774\tLoss_G: 1.7739 \tMSE_loss: 3.9330 \tBest_loss: 3.6349\n",
      "[325/400][141/142]\tLoss_D: 0.8492\tLoss_G: 2.3379 \tMSE_loss: 3.2439 \tTime: 0.0615\n",
      "Validation \tLoss_D: 1.3747\tLoss_G: 1.8348 \tMSE_loss: 3.9564 \tBest_loss: 3.6349\n",
      "[326/400][141/142]\tLoss_D: 0.8299\tLoss_G: 2.3570 \tMSE_loss: 4.2792 \tTime: 0.0590\n",
      "Validation \tLoss_D: 1.4067\tLoss_G: 1.7582 \tMSE_loss: 3.9219 \tBest_loss: 3.6349\n",
      "[327/400][141/142]\tLoss_D: 0.9968\tLoss_G: 2.3509 \tMSE_loss: 5.2585 \tTime: 0.0584\n",
      "Validation \tLoss_D: 1.3924\tLoss_G: 1.7870 \tMSE_loss: 3.9472 \tBest_loss: 3.6349\n",
      "[328/400][141/142]\tLoss_D: 0.6343\tLoss_G: 2.0192 \tMSE_loss: 4.7124 \tTime: 0.0495\n",
      "Validation \tLoss_D: 1.3751\tLoss_G: 1.8178 \tMSE_loss: 3.9305 \tBest_loss: 3.6349\n",
      "[329/400][141/142]\tLoss_D: 0.5360\tLoss_G: 2.5168 \tMSE_loss: 4.3352 \tTime: 0.0598\n",
      "Validation \tLoss_D: 1.4147\tLoss_G: 1.7409 \tMSE_loss: 3.9279 \tBest_loss: 3.6349\n",
      "[330/400][141/142]\tLoss_D: 0.7736\tLoss_G: 2.5644 \tMSE_loss: 5.1774 \tTime: 0.0539\n",
      "Validation \tLoss_D: 1.3777\tLoss_G: 1.8261 \tMSE_loss: 3.9758 \tBest_loss: 3.6349\n",
      "[331/400][141/142]\tLoss_D: 0.5710\tLoss_G: 1.7167 \tMSE_loss: 2.6392 \tTime: 0.0547\n",
      "Validation \tLoss_D: 1.4269\tLoss_G: 1.8021 \tMSE_loss: 3.9103 \tBest_loss: 3.6349\n",
      "[332/400][141/142]\tLoss_D: 0.8606\tLoss_G: 2.9068 \tMSE_loss: 4.3997 \tTime: 0.0546\n",
      "Validation \tLoss_D: 1.3881\tLoss_G: 1.8454 \tMSE_loss: 3.9730 \tBest_loss: 3.6349\n",
      "[333/400][141/142]\tLoss_D: 0.6997\tLoss_G: 2.6987 \tMSE_loss: 4.0467 \tTime: 0.0547\n",
      "Validation \tLoss_D: 1.4149\tLoss_G: 1.7895 \tMSE_loss: 3.9170 \tBest_loss: 3.6349\n",
      "[334/400][141/142]\tLoss_D: 0.8786\tLoss_G: 1.8946 \tMSE_loss: 3.5753 \tTime: 0.0586\n",
      "Validation \tLoss_D: 1.4428\tLoss_G: 1.9282 \tMSE_loss: 3.9107 \tBest_loss: 3.6349\n",
      "[335/400][141/142]\tLoss_D: 0.7951\tLoss_G: 2.8035 \tMSE_loss: 5.2066 \tTime: 0.0631\n",
      "Validation \tLoss_D: 1.3682\tLoss_G: 1.9955 \tMSE_loss: 4.0486 \tBest_loss: 3.6349\n",
      "[336/400][141/142]\tLoss_D: 0.7042\tLoss_G: 3.3737 \tMSE_loss: 4.4647 \tTime: 0.0553\n",
      "Validation \tLoss_D: 1.4325\tLoss_G: 1.8636 \tMSE_loss: 3.9015 \tBest_loss: 3.6349\n",
      "[337/400][141/142]\tLoss_D: 0.6883\tLoss_G: 2.5645 \tMSE_loss: 4.7342 \tTime: 0.0577\n",
      "Validation \tLoss_D: 1.4108\tLoss_G: 1.8064 \tMSE_loss: 3.9683 \tBest_loss: 3.6349\n",
      "[338/400][141/142]\tLoss_D: 0.8521\tLoss_G: 2.5161 \tMSE_loss: 3.3590 \tTime: 0.0577\n",
      "Validation \tLoss_D: 1.4299\tLoss_G: 1.8132 \tMSE_loss: 3.9323 \tBest_loss: 3.6349\n",
      "[339/400][141/142]\tLoss_D: 0.5294\tLoss_G: 3.2694 \tMSE_loss: 7.8195 \tTime: 0.0567\n",
      "Validation \tLoss_D: 1.4285\tLoss_G: 1.8236 \tMSE_loss: 3.9199 \tBest_loss: 3.6349\n",
      "[340/400][141/142]\tLoss_D: 0.6607\tLoss_G: 2.9053 \tMSE_loss: 4.7981 \tTime: 0.0525\n",
      "Validation \tLoss_D: 1.3734\tLoss_G: 2.0059 \tMSE_loss: 4.0674 \tBest_loss: 3.6349\n",
      "[341/400][141/142]\tLoss_D: 0.5163\tLoss_G: 2.8817 \tMSE_loss: 6.4487 \tTime: 0.0473\n",
      "Validation \tLoss_D: 1.3827\tLoss_G: 1.9132 \tMSE_loss: 3.9915 \tBest_loss: 3.6349\n",
      "[342/400][141/142]\tLoss_D: 0.6077\tLoss_G: 2.6769 \tMSE_loss: 4.0248 \tTime: 0.0576\n",
      "Validation \tLoss_D: 1.3842\tLoss_G: 1.9915 \tMSE_loss: 3.9809 \tBest_loss: 3.6349\n",
      "[343/400][141/142]\tLoss_D: 0.6084\tLoss_G: 2.9479 \tMSE_loss: 6.6338 \tTime: 0.0606\n",
      "Validation \tLoss_D: 1.3548\tLoss_G: 1.9943 \tMSE_loss: 4.0529 \tBest_loss: 3.6349\n",
      "[344/400][141/142]\tLoss_D: 0.6489\tLoss_G: 2.8944 \tMSE_loss: 3.3508 \tTime: 0.0548\n",
      "Validation \tLoss_D: 1.4354\tLoss_G: 1.7268 \tMSE_loss: 3.9818 \tBest_loss: 3.6349\n",
      "[345/400][141/142]\tLoss_D: 0.6540\tLoss_G: 2.8874 \tMSE_loss: 8.4559 \tTime: 0.0591\n",
      "Validation \tLoss_D: 1.4043\tLoss_G: 1.9514 \tMSE_loss: 3.9838 \tBest_loss: 3.6349\n",
      "[346/400][141/142]\tLoss_D: 0.5688\tLoss_G: 2.9310 \tMSE_loss: 3.2589 \tTime: 0.0595\n",
      "Validation \tLoss_D: 1.4431\tLoss_G: 1.9359 \tMSE_loss: 3.9460 \tBest_loss: 3.6349\n",
      "[347/400][141/142]\tLoss_D: 0.6876\tLoss_G: 2.9518 \tMSE_loss: 4.2338 \tTime: 0.0562\n",
      "Validation \tLoss_D: 1.3973\tLoss_G: 1.9921 \tMSE_loss: 4.0228 \tBest_loss: 3.6349\n",
      "[348/400][141/142]\tLoss_D: 0.5864\tLoss_G: 2.5654 \tMSE_loss: 2.3292 \tTime: 0.0579\n",
      "Validation \tLoss_D: 1.4409\tLoss_G: 1.8297 \tMSE_loss: 3.9568 \tBest_loss: 3.6349\n",
      "[349/400][141/142]\tLoss_D: 0.5910\tLoss_G: 2.6490 \tMSE_loss: 4.7813 \tTime: 0.0546\n",
      "Validation \tLoss_D: 1.4021\tLoss_G: 1.9816 \tMSE_loss: 4.0083 \tBest_loss: 3.6349\n",
      "[350/400][141/142]\tLoss_D: 0.7796\tLoss_G: 2.9888 \tMSE_loss: 3.8824 \tTime: 0.0544\n",
      "Validation \tLoss_D: 1.4438\tLoss_G: 1.9558 \tMSE_loss: 3.9603 \tBest_loss: 3.6349\n",
      "[351/400][141/142]\tLoss_D: 0.5977\tLoss_G: 2.6619 \tMSE_loss: 4.2915 \tTime: 0.0555\n",
      "Validation \tLoss_D: 1.4375\tLoss_G: 1.9171 \tMSE_loss: 4.0083 \tBest_loss: 3.6349\n",
      "[352/400][141/142]\tLoss_D: 0.6012\tLoss_G: 2.3146 \tMSE_loss: 6.8136 \tTime: 0.0505\n",
      "Validation \tLoss_D: 1.4509\tLoss_G: 1.8824 \tMSE_loss: 3.9978 \tBest_loss: 3.6349\n",
      "[353/400][141/142]\tLoss_D: 0.6478\tLoss_G: 2.2169 \tMSE_loss: 3.7062 \tTime: 0.0544\n",
      "Validation \tLoss_D: 1.4720\tLoss_G: 1.7265 \tMSE_loss: 3.9492 \tBest_loss: 3.6349\n",
      "[354/400][141/142]\tLoss_D: 0.8247\tLoss_G: 2.5942 \tMSE_loss: 4.2669 \tTime: 0.0572\n",
      "Validation \tLoss_D: 1.4603\tLoss_G: 1.8469 \tMSE_loss: 3.9403 \tBest_loss: 3.6349\n",
      "[355/400][141/142]\tLoss_D: 0.6053\tLoss_G: 3.2844 \tMSE_loss: 5.0417 \tTime: 0.0525\n",
      "Validation \tLoss_D: 1.4141\tLoss_G: 2.1000 \tMSE_loss: 4.0177 \tBest_loss: 3.6349\n",
      "[356/400][141/142]\tLoss_D: 0.8149\tLoss_G: 2.6714 \tMSE_loss: 3.4880 \tTime: 0.0523\n",
      "Validation \tLoss_D: 1.4543\tLoss_G: 1.9091 \tMSE_loss: 3.9704 \tBest_loss: 3.6349\n",
      "[357/400][141/142]\tLoss_D: 0.5155\tLoss_G: 2.2796 \tMSE_loss: 4.1240 \tTime: 0.0561\n",
      "Validation \tLoss_D: 1.4419\tLoss_G: 2.0228 \tMSE_loss: 4.0330 \tBest_loss: 3.6349\n",
      "[358/400][141/142]\tLoss_D: 0.5307\tLoss_G: 2.2104 \tMSE_loss: 4.4930 \tTime: 0.0540\n",
      "Validation \tLoss_D: 1.4487\tLoss_G: 1.9079 \tMSE_loss: 4.0026 \tBest_loss: 3.6349\n",
      "[359/400][141/142]\tLoss_D: 0.5319\tLoss_G: 2.3645 \tMSE_loss: 2.9903 \tTime: 0.0566\n",
      "Validation \tLoss_D: 1.4463\tLoss_G: 1.9010 \tMSE_loss: 4.0039 \tBest_loss: 3.6349\n",
      "[360/400][141/142]\tLoss_D: 0.7813\tLoss_G: 3.0282 \tMSE_loss: 3.8459 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.4595\tLoss_G: 1.9780 \tMSE_loss: 3.9749 \tBest_loss: 3.6349\n",
      "[361/400][141/142]\tLoss_D: 0.8470\tLoss_G: 2.4246 \tMSE_loss: 3.6350 \tTime: 0.0638\n",
      "Validation \tLoss_D: 1.4268\tLoss_G: 2.0035 \tMSE_loss: 4.0479 \tBest_loss: 3.6349\n",
      "[362/400][141/142]\tLoss_D: 0.8122\tLoss_G: 3.0291 \tMSE_loss: 5.7033 \tTime: 0.0645\n",
      "Validation \tLoss_D: 1.4668\tLoss_G: 2.0038 \tMSE_loss: 3.9581 \tBest_loss: 3.6349\n",
      "[363/400][141/142]\tLoss_D: 0.6524\tLoss_G: 2.4541 \tMSE_loss: 3.9220 \tTime: 0.0594\n",
      "Validation \tLoss_D: 1.4600\tLoss_G: 1.8295 \tMSE_loss: 4.0133 \tBest_loss: 3.6349\n",
      "[364/400][141/142]\tLoss_D: 0.8915\tLoss_G: 3.2491 \tMSE_loss: 6.1922 \tTime: 0.0601\n",
      "Validation \tLoss_D: 1.4784\tLoss_G: 1.8945 \tMSE_loss: 3.9673 \tBest_loss: 3.6349\n",
      "[365/400][141/142]\tLoss_D: 0.5577\tLoss_G: 2.5905 \tMSE_loss: 5.6580 \tTime: 0.0563\n",
      "Validation \tLoss_D: 1.4477\tLoss_G: 1.9444 \tMSE_loss: 4.0310 \tBest_loss: 3.6349\n",
      "[366/400][141/142]\tLoss_D: 0.5630\tLoss_G: 2.2982 \tMSE_loss: 3.4487 \tTime: 0.0505\n",
      "Validation \tLoss_D: 1.4504\tLoss_G: 1.8869 \tMSE_loss: 3.9953 \tBest_loss: 3.6349\n",
      "[367/400][141/142]\tLoss_D: 0.8256\tLoss_G: 2.4882 \tMSE_loss: 3.4036 \tTime: 0.0574\n",
      "Validation \tLoss_D: 1.4812\tLoss_G: 2.0019 \tMSE_loss: 3.9711 \tBest_loss: 3.6349\n",
      "[368/400][141/142]\tLoss_D: 0.7281\tLoss_G: 2.1977 \tMSE_loss: 5.0959 \tTime: 0.0534\n",
      "Validation \tLoss_D: 1.4536\tLoss_G: 1.9578 \tMSE_loss: 4.0110 \tBest_loss: 3.6349\n",
      "[369/400][141/142]\tLoss_D: 0.7570\tLoss_G: 2.6299 \tMSE_loss: 3.8680 \tTime: 0.0507\n",
      "Validation \tLoss_D: 1.5184\tLoss_G: 1.8705 \tMSE_loss: 3.9627 \tBest_loss: 3.6349\n",
      "[370/400][141/142]\tLoss_D: 0.5691\tLoss_G: 3.0964 \tMSE_loss: 4.9675 \tTime: 0.0537\n",
      "Validation \tLoss_D: 1.4822\tLoss_G: 1.9745 \tMSE_loss: 4.0073 \tBest_loss: 3.6349\n",
      "[371/400][141/142]\tLoss_D: 0.6877\tLoss_G: 2.9479 \tMSE_loss: 4.6766 \tTime: 0.0574\n",
      "Validation \tLoss_D: 1.4769\tLoss_G: 2.0014 \tMSE_loss: 4.0124 \tBest_loss: 3.6349\n",
      "[372/400][141/142]\tLoss_D: 0.6558\tLoss_G: 2.5635 \tMSE_loss: 4.1041 \tTime: 0.0493\n",
      "Validation \tLoss_D: 1.4464\tLoss_G: 2.0135 \tMSE_loss: 4.0223 \tBest_loss: 3.6349\n",
      "[373/400][141/142]\tLoss_D: 0.6266\tLoss_G: 2.0564 \tMSE_loss: 4.6883 \tTime: 0.0567\n",
      "Validation \tLoss_D: 1.4662\tLoss_G: 2.0641 \tMSE_loss: 4.0473 \tBest_loss: 3.6349\n",
      "[374/400][141/142]\tLoss_D: 0.7462\tLoss_G: 2.1977 \tMSE_loss: 3.3390 \tTime: 0.0513\n",
      "Validation \tLoss_D: 1.4874\tLoss_G: 2.1030 \tMSE_loss: 4.0539 \tBest_loss: 3.6349\n",
      "[375/400][141/142]\tLoss_D: 0.6775\tLoss_G: 2.3358 \tMSE_loss: 5.6179 \tTime: 0.0554\n",
      "Validation \tLoss_D: 1.5356\tLoss_G: 1.9610 \tMSE_loss: 3.9395 \tBest_loss: 3.6349\n",
      "[376/400][141/142]\tLoss_D: 0.5458\tLoss_G: 2.4628 \tMSE_loss: 3.4087 \tTime: 0.0532\n",
      "Validation \tLoss_D: 1.4997\tLoss_G: 1.8650 \tMSE_loss: 4.0049 \tBest_loss: 3.6349\n",
      "[377/400][141/142]\tLoss_D: 0.4685\tLoss_G: 2.4002 \tMSE_loss: 3.2771 \tTime: 0.0526\n",
      "Validation \tLoss_D: 1.4951\tLoss_G: 1.9337 \tMSE_loss: 4.0062 \tBest_loss: 3.6349\n",
      "[378/400][141/142]\tLoss_D: 0.5265\tLoss_G: 3.1570 \tMSE_loss: 4.7979 \tTime: 0.0530\n",
      "Validation \tLoss_D: 1.5181\tLoss_G: 2.0355 \tMSE_loss: 3.9903 \tBest_loss: 3.6349\n",
      "[379/400][141/142]\tLoss_D: 0.7358\tLoss_G: 2.8704 \tMSE_loss: 3.8892 \tTime: 0.0504\n",
      "Validation \tLoss_D: 1.5033\tLoss_G: 2.0786 \tMSE_loss: 4.0079 \tBest_loss: 3.6349\n",
      "[380/400][141/142]\tLoss_D: 0.6139\tLoss_G: 2.5137 \tMSE_loss: 2.9995 \tTime: 0.0640\n",
      "Validation \tLoss_D: 1.5376\tLoss_G: 1.9967 \tMSE_loss: 3.9840 \tBest_loss: 3.6349\n",
      "[381/400][141/142]\tLoss_D: 0.6997\tLoss_G: 2.1306 \tMSE_loss: 5.2689 \tTime: 0.0514\n",
      "Validation \tLoss_D: 1.5296\tLoss_G: 1.9206 \tMSE_loss: 3.9733 \tBest_loss: 3.6349\n",
      "[382/400][141/142]\tLoss_D: 0.5215\tLoss_G: 3.1080 \tMSE_loss: 4.9417 \tTime: 0.0568\n",
      "Validation \tLoss_D: 1.5385\tLoss_G: 1.8868 \tMSE_loss: 3.9825 \tBest_loss: 3.6349\n",
      "[383/400][141/142]\tLoss_D: 0.5886\tLoss_G: 3.4717 \tMSE_loss: 5.4169 \tTime: 0.0518\n",
      "Validation \tLoss_D: 1.5166\tLoss_G: 2.0854 \tMSE_loss: 4.0324 \tBest_loss: 3.6349\n",
      "[384/400][141/142]\tLoss_D: 0.6953\tLoss_G: 2.5058 \tMSE_loss: 4.9792 \tTime: 0.0642\n",
      "Validation \tLoss_D: 1.5349\tLoss_G: 2.0690 \tMSE_loss: 3.9910 \tBest_loss: 3.6349\n",
      "[385/400][141/142]\tLoss_D: 0.4963\tLoss_G: 2.8976 \tMSE_loss: 5.1941 \tTime: 0.0525\n",
      "Validation \tLoss_D: 1.5197\tLoss_G: 2.0716 \tMSE_loss: 4.0087 \tBest_loss: 3.6349\n",
      "[386/400][141/142]\tLoss_D: 0.4788\tLoss_G: 1.9669 \tMSE_loss: 3.7964 \tTime: 0.0505\n",
      "Validation \tLoss_D: 1.5116\tLoss_G: 1.9060 \tMSE_loss: 4.0087 \tBest_loss: 3.6349\n",
      "[387/400][141/142]\tLoss_D: 0.8299\tLoss_G: 3.4664 \tMSE_loss: 5.2420 \tTime: 0.0573\n",
      "Validation \tLoss_D: 1.5191\tLoss_G: 2.0848 \tMSE_loss: 4.0037 \tBest_loss: 3.6349\n",
      "[388/400][141/142]\tLoss_D: 0.5456\tLoss_G: 3.3465 \tMSE_loss: 4.8516 \tTime: 0.0570\n",
      "Validation \tLoss_D: 1.5192\tLoss_G: 2.0595 \tMSE_loss: 4.0074 \tBest_loss: 3.6349\n",
      "[389/400][141/142]\tLoss_D: 0.5227\tLoss_G: 2.6377 \tMSE_loss: 7.0744 \tTime: 0.0557\n",
      "Validation \tLoss_D: 1.5289\tLoss_G: 1.9867 \tMSE_loss: 4.0048 \tBest_loss: 3.6349\n",
      "[390/400][141/142]\tLoss_D: 0.8768\tLoss_G: 3.0420 \tMSE_loss: 3.9996 \tTime: 0.0571\n",
      "Validation \tLoss_D: 1.5349\tLoss_G: 2.1929 \tMSE_loss: 4.0315 \tBest_loss: 3.6349\n",
      "[391/400][141/142]\tLoss_D: 0.4972\tLoss_G: 2.7530 \tMSE_loss: 5.6369 \tTime: 0.0563\n",
      "Validation \tLoss_D: 1.5395\tLoss_G: 2.0834 \tMSE_loss: 3.9845 \tBest_loss: 3.6349\n",
      "[392/400][141/142]\tLoss_D: 0.5667\tLoss_G: 2.9319 \tMSE_loss: 5.6295 \tTime: 0.0586\n",
      "Validation \tLoss_D: 1.5681\tLoss_G: 1.9957 \tMSE_loss: 3.9755 \tBest_loss: 3.6349\n",
      "[393/400][141/142]\tLoss_D: 0.8389\tLoss_G: 2.1783 \tMSE_loss: 3.5276 \tTime: 0.0592\n",
      "Validation \tLoss_D: 1.5563\tLoss_G: 2.0819 \tMSE_loss: 3.9915 \tBest_loss: 3.6349\n",
      "[394/400][141/142]\tLoss_D: 0.6656\tLoss_G: 2.9050 \tMSE_loss: 4.8680 \tTime: 0.0514\n",
      "Validation \tLoss_D: 1.5660\tLoss_G: 2.0155 \tMSE_loss: 4.0284 \tBest_loss: 3.6349\n",
      "[395/400][141/142]\tLoss_D: 0.6826\tLoss_G: 2.4381 \tMSE_loss: 3.1855 \tTime: 0.0615\n",
      "Validation \tLoss_D: 1.5752\tLoss_G: 2.1010 \tMSE_loss: 3.9722 \tBest_loss: 3.6349\n",
      "[396/400][141/142]\tLoss_D: 0.5778\tLoss_G: 3.1872 \tMSE_loss: 4.1881 \tTime: 0.0554\n",
      "Validation \tLoss_D: 1.5699\tLoss_G: 1.9840 \tMSE_loss: 3.9951 \tBest_loss: 3.6349\n",
      "[397/400][141/142]\tLoss_D: 0.6933\tLoss_G: 3.1438 \tMSE_loss: 3.0832 \tTime: 0.0599\n",
      "Validation \tLoss_D: 1.5838\tLoss_G: 1.9725 \tMSE_loss: 4.0156 \tBest_loss: 3.6349\n",
      "[398/400][141/142]\tLoss_D: 0.6845\tLoss_G: 2.6709 \tMSE_loss: 3.3804 \tTime: 0.0534\n",
      "Validation \tLoss_D: 1.5727\tLoss_G: 2.1347 \tMSE_loss: 4.0177 \tBest_loss: 3.6349\n",
      "[399/400][141/142]\tLoss_D: 0.6021\tLoss_G: 3.1707 \tMSE_loss: 4.8086 \tTime: 0.0584\n",
      "Validation \tLoss_D: 1.5848\tLoss_G: 2.0290 \tMSE_loss: 4.0032 \tBest_loss: 3.6349\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "torch.manual_seed(8)\n",
    "\n",
    "def train_GAN(G, D, optim_G, optim_D, loss_f, train_loader, test_loader, num_epochs, device):\n",
    "    test_size = len(test_loader)\n",
    "    best = np.inf \n",
    "    for epoch in range(num_epochs):\n",
    "        for i,data in enumerate(train_loader):\n",
    "            if i<140:\n",
    "                generator.train()\n",
    "                discriminator.train()   \n",
    "                starting_time = time.time()\n",
    "                sequence , target = data\n",
    "                sequence = sequence.to(device)\n",
    "                target = target.to(device)\n",
    "                generator_fake = G(sequence)\n",
    "                true_seq = torch.concat((sequence,target.reshape(-1,1,7)),dim=1)\n",
    "                fake_seq = torch.concat((sequence,generator_fake),dim=1)\n",
    "                # ========================\n",
    "                #   Train Discriminator\n",
    "                # ========================\n",
    "                # train with real data\n",
    "                \n",
    "                prediction = D(true_seq)\n",
    "\n",
    "                # train with fake data\n",
    "                \n",
    "                fake_predection = D(fake_seq)\n",
    "                d_loss = descriminator_loss(prediction, fake_predection)\n",
    "                # update D\n",
    "                \n",
    "                D.zero_grad()\n",
    "                d_loss.backward()\n",
    "                optim_D.step()\n",
    "\n",
    "                # ========================\n",
    "                #   Train Generator\n",
    "                # ========================\n",
    "                # train with fake data  \n",
    "                        \n",
    "                sequence , target = data\n",
    "                sequence = sequence.to(device)\n",
    "                target = target.to(device)\n",
    "                generator_fake = G(sequence)\n",
    "                fake_seq = torch.concat((sequence,generator_fake),dim=1)\n",
    "                fake_predection = D(fake_seq)\n",
    "                g_loss, mse_loss = generator_loss(generator_fake,target,fake_predection)\n",
    "                # update G\n",
    "                G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                optim_G.step()   \n",
    "        print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f \\tMSE_loss: %.4f \\tTime: %.4f'% (epoch, num_epochs, i, len(train_loader), d_loss.item(), g_loss.item(),mse_loss.item(),time.time()-starting_time))\n",
    "        #evaluate \n",
    "        dis_loss = 0\n",
    "        gen_loss= 0\n",
    "        mse_loss = 0\n",
    "        diss_losses = []\n",
    "        gen_losses = []\n",
    "        mse_losses = []\n",
    "\n",
    "        for i,data in enumerate(test_loader):\n",
    "            generator.eval()\n",
    "            discriminator.eval()\n",
    "            with torch.no_grad():\n",
    "                sequence , target = data\n",
    "                sequence = sequence.to(device)\n",
    "                target = target.to(device)\n",
    "                generator_fake = G(sequence)\n",
    "                fake_seq = torch.concat((sequence,generator_fake),dim=1)\n",
    "                true_seq = torch.concat((sequence,target.reshape(-1,1,7)),dim=1)\n",
    "                fake_predection = D(fake_seq)\n",
    "                g_loss, mse = generator_loss(generator_fake,target,fake_predection)\n",
    "                prediction = D(true_seq)\n",
    "                d_loss = descriminator_loss(prediction, fake_predection)\n",
    "                dis_loss += d_loss.item()/test_size\n",
    "                gen_loss += g_loss.item()/test_size\n",
    "                mse_loss += mse.item()/test_size\n",
    "        diss_losses.append(dis_loss)\n",
    "        gen_losses.append(gen_loss)\n",
    "        mse_losses.append(mse_loss)\n",
    "\n",
    "        if mse_loss < best:\n",
    "            best = mse_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': G.state_dict(),\n",
    "                'optimizer_state_dict': optim_G.state_dict(),\n",
    "            }, 'Kan_gan.pth') \n",
    "        print('Validation \\tLoss_D: %.4f\\tLoss_G: %.4f \\tMSE_loss: %.4f \\tBest_loss: %.4f'% (dis_loss, gen_loss,mse_loss,best))\n",
    "    return diss_losses, gen_losses, mse_losses\n",
    "\n",
    "\n",
    "    \n",
    "loss_fn = nn.BCELoss()\n",
    "mse_fn = nn.MSELoss()\n",
    "\n",
    "a1 = 0.01\n",
    "def descriminator_loss(real_output, fake_output):\n",
    "    real_loss = loss_fn(real_output, torch.ones_like(real_output))\n",
    "    fake_loss = loss_fn(fake_output, torch.zeros_like(fake_output))\n",
    "    return real_loss + fake_loss\n",
    "def generator_loss(x,y,fake_output):\n",
    "    loss = loss_fn(fake_output, torch.ones_like(fake_output))\n",
    "    mse_loss = mse_fn(x,y.reshape(-1,1,7))\n",
    "    return a1*mse_loss + (1-a1)*loss , mse_loss\n",
    "\n",
    "epochs = 400\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = GeneratorModel(n_sequence, n_features).to(torch.float64)\n",
    "discriminator = KAN_discriminator(n_sequence,n_features).to(torch.float64)\n",
    "generator , discriminator = generator.to(device), discriminator.to(device)\n",
    "\n",
    "learning_rate1 = 0.00003\n",
    "learning_rate2 = 0.00003\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate1, betas=(0.5, 0.999))\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate2, betas=(0.5, 0.999))\n",
    "checkpoint_path = \"./train_checkpoints\"\n",
    "\n",
    "result = train_GAN(generator, discriminator, generator_optimizer, discriminator_optimizer, loss_fn, data_gen_train, data_gen_test, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f663d50c-ac2b-4af6-825f-0d045ec5043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE =  tensor(2.85211189, device='cuda:0', dtype=torch.float64)\n",
      "RMSE =  tensor(2.00518118, device='cuda:0', dtype=torch.float64)\n",
      "MAE =  tensor(1.31837179, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "generator.load_state_dict(torch.load('Kan_gan.pth')['model_state_dict'])\n",
    "data = dataframe.drop(columns='Date').to_numpy()\n",
    "targets = data\n",
    "n_samples = data.shape[0]\n",
    "train_test_split=int(n_samples*0.9)\n",
    "train_data = data[:train_test_split]\n",
    "test_data = data[train_test_split:]\n",
    "train_target = targets[:train_test_split]\n",
    "test_target = targets[train_test_split:]\n",
    "test_data=Standarized_TimeseriesGenerator(test_data, test_target, length=n_sequence, stride=1)\n",
    "\n",
    "mape = 0\n",
    "rmse = 0\n",
    "mae = 0\n",
    "\n",
    "for i in range(0,len(test_data)-1,2):\n",
    "    with torch.no_grad():\n",
    "        seq = torch.concat((test_data[i][0].reshape(1,5,7),test_data[i+1][0].reshape(1,5,7)),dim=0)\n",
    "        targets = torch.concat((test_data[i][1].reshape(1,1,7),test_data[i+1][1].reshape(1,1,7)),dim=0).to(device)\n",
    "        pred = generator(seq.to(device))\n",
    "        mape += torch.sum(torch.abs(targets[:,:,3] - pred[:,:,3] /targets[:,:,3]) )\n",
    "        rmse += torch.sum((targets[:,:,3]  - pred[:,:,3] )**2)\n",
    "        mae += torch.sum(torch.abs(targets[:,:,3] - pred[:,:,3] ))\n",
    "        \n",
    "print(\"MAPE = \",mape/len(test_data))\n",
    "print(\"RMSE = \",(rmse/len(test_data))**0.5)\n",
    "print(\"MAE = \",mae/len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62439f72-f3ee-4952-9a4e-7cc668752ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
